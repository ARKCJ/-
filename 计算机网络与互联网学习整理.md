# 计算机网络与互联网学习整理





**简介：** 跟听哈尔滨工业大学的计算机网络课程所做的学习整理，其中大量示例为原哈尔滨工业大学的计算机网络			课程PPT上的示例。对该课程感兴趣的小伙伴可以收藏作为学习参考。（多图预警！！！）





**<a href="#第一章">计算机网络概述</a>**

**<a href="#第二章">网络应用层</a>**

**<a href="#第三章">网络传输层</a>**

**<a href="#第四章">网络层服务</a>**

**<a href="#第五章">数据链路层服务</a>**















## <a name="第一章">第一章：计算机网络概述</a>

### 1、什么是计算机网络：

**定义：**计算机网络就是<font color = "red">互联的</font>，<font color = "red">自治的</font>计算机集合。它是通信技术与计算机技术紧密结合的产物，本质上就是一种通信网络。计算机与计算机之间直接或通过交换节点（路由器或交换机）进行物理上的相连，形成计算机网络。



**什么是Internet:**	Internet从组成角度考虑可以看作是一种**网络的网络**，它由各种大大小小的子网络（比如局域网、广域网）构成，为连接到Internet的设备提供统一的服务协议（TCP/IP），各个接入Internet上的设备根据统一的协议可以向其他接入的设备交换信息。

### 2、什么是网络协议：

在Internet上，不仅需要各种硬件的支持（主机，路由器，通信链路等）同时也需要一定的<font color = "red">规则</font>（协议）来保证网络中的信息能够按照统一的<font color = "red">格式、意义、顺序和对接受或发送的动作</font>来进行交换。如同公路上的交通指挥系统一样，必须都制定统一的规则，才能够保证整个系统的正常运行。

**网络协议：**简称协议，是为进行网络中的数据交换而建立的规则，标准或约定。协议规定了通信实体之间所交换的消息的格式、意义、顺序以及针对收到信息或发生的事件所采取的"动作"。

**协议的三要素：**

- 语法：
  - 数据与控制信息的结构或格式
  - 信号电平
- 语义：
  - 需要发出何种控制信息
  - 完成何种动作以及做出何种相应
  - 差错控制
- 时序：
  - 事件顺序（考虑用何种顺序完成一个信息的发送或接受）
  - 速度匹配（发送方相对接受方的速度差不能够过大）

### 3、计算机网络结构：

计算机网络分为三个部分构成：网络边缘、接入网络，物理介质、网络核心

#### 网络边缘：

- 包括主机（端系统，比如我们日常使用的手机，电脑），这些主机运行网络应用程序，网络的作用正是让这些主机交换信息。
  - 目前网络边缘之间交换信息的方式有两种：
    - 客户/服务器（client/server）应用模型：客户端向服务器发送请求，服务器对客户端进行响应后，客户端接收服务器相应。如：web应用，文件传输FTP应用。
    - 对等（peer-peer，P2P）引用模型：网络边缘设备不再依赖专门的服务器，主机既可以充当“服务器”的角色发送数据，也可以充当“客户端”的角色进行请求数据。这样的通信在<font color = "red">对等实体</font>之间进行。（QQ，BT都是典型的P2P应用）

#### 接入网络，物理介质：

网络边缘需要物理介质来实现主机之间的互连才能够达到相互传输信息的目的，由于网络中连接的主机可能数目相当庞大，不可能每个主机都达到直接两两互联，这就需要将物理介质接入到网络核心（路由器，交换机）中，让每个主机与一个网络核心直接相连，最终让网络核心实现信息的转发。一般我们关注接入网络的两个属性分别为：带宽（单位时间内传输数据的比特量）和该接入网络是共享还是独占的。

**几个具有代表性的接入网络：**

- 数字用户线路（DSL）：数字用户线路实际上采用的是一种多路复用技术，使家庭中的电话线同时连接到电话网络与计算机网络。使用已有的DSLAM（呼数字用户线路接入复用器，因为是已有的，因此用户接入网络时可以减少大量的开销）进行电话网络信号与计算机网络信号的复用，通过分离器将同一根线路上两种不同的信号进行分离，最终通过DSL调制解调器（也就是大家口中的猫）将电话线中的模拟信号转换为数字信号供主机使用。其使用的是一种频分复用技术（FDM）部分频率用于上行，部分频率用于下行（上行下行的速率不同，因此也称之为非对称数字用户线路），部分频率用于传统电话。该网络是**独占网络**。

  <a href="https://sm.ms/image/m41xDA67TnyEV3Y" target="_blank"><img src="https://i.loli.net/2020/05/22/m41xDA67TnyEV3Y.png" width = 500px ></a>

- 电缆网络（Cable Modem）：和上一种非常相似，也是利用已有的技术进行扩展达到节省开销的目的。它利用有线电视网络进行多路复用。采用的同样也是频分多路复用技术（FDM），有线电视网络本身就是一种频分多路复用的网络（我们跳台，就是通过让电视机接受不同频率的信号来实现的，和收音机差不多一个原理）。该网络**不是独占网络**（网络连接到电缆头段为止是光纤，而连接到用户的是同轴电缆），如图可见，各个设备共享这段同轴电缆。

  <a href="https://sm.ms/image/lRU5XbZGx9JTo7c" target="_blank"><img src="https://i.loli.net/2020/05/22/lRU5XbZGx9JTo7c.png" width = 500px  ></a>

- 典型家庭的网络接入原理

  我们通过DSL或电缆调制解调器接入电话线或是有线电视电缆，将其转换为数字信号后传送给路由器，路由器通过相应的协议为直接连接到它的主机进行信息的转发。

  <a href="https://sm.ms/image/jYQxEuWfzJOmINR" target="_blank"><img src="https://i.loli.net/2020/05/22/jYQxEuWfzJOmINR.png" width = 500px  ></a>

- 以太网（Ethernet）：该网络是目前在机构（企业）应用最广泛的一种网络。各个主机与以太网交换机构成局域网，这些局域网连接到机构路由器，机构路由器直接接入到Internet中。

  <a href="https://sm.ms/image/hH6DOqgwGEK84Mp" target="_blank"><img src="https://i.loli.net/2020/05/22/hH6DOqgwGEK84Mp.png" width = 500px  ></a>

- 无线接入网络：通过共享的无线接入网络（也称之为基站或接入点，比如WIFI或者信号塔）连接**端系统**与**路由器**，路由器再连接internet。其目前最广泛的两种应用为：

  - 无线局域网（LANs）：典型的家庭网络，各个设备连接到支持802.11的WIFI上，WIFI连接路由器再接入到Internet。
  - 广域无线接入：通过电信运行商的基站（蜂窝网，可接入范围可达几十公里）接入到Internet中。广域无线是现代无线移动互联网的基础。

#### 网络核心：

像Internet的网络核心，就是由一些互联的路由器构成的。网络核心的关键功能为：**路由**+**转发**，当某台主机希望发送数据到另一台接入Internet的主机上时，发送的数据会自带目的地址信息，路由器需要知道如何将该数据正确的传送到目的地，那么它就需要知道如何路由和转发。

- **路由：**对于各种路由器，这些路由器之间需要有共同的协议来确定数据分组从源到目的的传输路径，这些传输路径由路由器的路由算法决定，路由算法计算完成后会在路由器中存有一张转发表，当接受到分组数据时路由器会根据本地转发表所对应的分组数据的目的地址来选择下一跳应输出的链路。

- **转发：**当路由器决定好要发送的分组应该送往哪条链路后，转发要做的是将分组从路由器的输入端口交换至正确的输出端口。

  <a href="https://sm.ms/image/FOz3AVk2CvpBuXU" target="_blank"><img src="https://i.loli.net/2020/05/22/FOz3AVk2CvpBuXU.png" width = 500px></a>

- **网络核心解决的基本问题：** 如何实现数据从源主机通过网络核心送达目的主机。

### 4、Internet结构：

我们称Internet为网络之网络的原因正是因为Internet本身就是由各个网络组合而成的。我们知道端系统通过接入ISP（access ISPs）后连接到Internet的，接入到Internet后ISP仍需要进一步互联（这样任意两个主机才可以互相发送分组），但是接入Internet的ISP数目必定相当庞大，直接互连显然是不现实的，这就使得我们必须构建更大的ISP，使这些更大的ISP进行互连（这也是称为网络之网络的原因）。但是Internet是一种商业性质的网络，显然构建上面所说的更大的ISP（比如国家级别或是全球级别的ISP）会引起利益冲突，因此不同的运营商可有自己的ISP，再加上不同运营商的ISP需要也互连或者一些区域性网络的诞生，这些因素都使得Internet变得急剧庞大且复杂。

- 国家或全球ISP：这是一种能够将大量局域网连接起来的策略，但是刨除了很多现实存在的复杂因素

  <img src="https://i.loli.net/2020/05/22/y8hdTcD9QvoWp6k.png" alt="Q3_EWFHM8I15`V0S_E`_6_B.png" width = 500px />

- 从商业角度考虑的连接方法：

  <a href="https://sm.ms/image/PIRhmDrQLutGkXO" target="_blank"><img src="https://i.loli.net/2020/05/22/PIRhmDrQLutGkXO.png" width = 500px  ></a>

  属于不同运营商之间的ISP也必须互联：

  <img src="C:\Users\蒋峻辰\AppData\Roaming\Typora\typora-user-images\image-20200522203613565.png" alt="image-20200522203613565" width = 500px />

- 有时会出现区域网络，这些区域网络也要接入运营商：

  <a href="https://sm.ms/image/NYh3T8dk5ofCzM2" target="_blank"><img src="https://i.loli.net/2020/05/22/NYh3T8dk5ofCzM2.png" width = 500px ></a>

- 还会有内容提供商的网络，可能运行自己的网络，并就近为端用户提供服务、内容（Google、Microsoft）

  <a href="https://sm.ms/image/Pc1k7iozZE3UmCH" target="_blank"><img src="https://i.loli.net/2020/05/22/Pc1k7iozZE3UmCH.png" width = 500px ></a>

- **Internet结构总结：**

  - 一级ISP：商业ISP为国家或国际提供网络覆盖（如：网通、电信、AT&T）
  - 内容提供商网络：私有网络，连接其数据中心与Internet，通常会绕过一级ISP和区域ISPS

  <a href="https://sm.ms/image/HAbaZ7NIYCy3zQP" target="_blank"><img src="https://i.loli.net/2020/05/22/HAbaZ7NIYCy3zQP.png" width = 500px ></a>

### 5、数据交换：

我们已经知道，互联网主要是由许许多多的网络核心组成，而网络核心的作用就是帮助源主机将数据传送给目的主机。因此这些网络核心构成的网络也被称为交换网络，交换网络中的网络核心根据统一的协议来实现动态的转接并分配传输资源（某些网络核心的连接不是刚建立就用就固定的，可能涉及到硬件的维护或其他各种原因需要更改连接，路由器之间的协议就可以做到这一点）。

#### 多路复用：

在通信过程中，用户不应该一直独占某一信道，否则在该用户失去对该信道的控制权之前，本应经过该信道的任何数据都应该进行等待，这显然是现代通信中不愿意遇到的。因此解决信道共享问题，产生了**多路复用**的概念。

**多路复用：**简称为复用，它是通信技术中的基本概念。多路复用的基本思想为：将链路/网络资源（如带宽）划分为各种大小的“资源片”，当该链路存在多个“呼叫请求”时（就是某一主机请求建立连接时，会占用这条链路）多路复用技术会将资源片分配它们，各路呼叫**独占**分配到的资源片进行通信。

**典型的多路复用方法：**

- 频分多路复用（FDM）：已知通信过程中产生的信号多为模拟信号（高频是1，低频是0），这些信号会有一个频率范围（以错开与其他频率的信号）。同样的对于通信链路也可以运用同一种方法，为连接到该链路上不同的用户分配一个小于通信链路的总频率带宽的频率带宽（单位：Hz），用户在分配到一定的带宽后，在通信过程中一直都会占用这个频带。

  <a href="https://sm.ms/image/L8CouKHVFvkgWB9" target="_blank"><img src="https://i.loli.net/2020/05/23/L8CouKHVFvkgWB9.png" width = 500px ></a>

- 时分多路复用（TDM）：时分复用则是将时间划分为一段段等长的**时分复用帧**（TDM帧），每个用户在每个TDM帧中占用固定序号的时隙，每个用户所占用的时隙是周期出现的（其周期就是TDM帧的长度）。时分复用的所有用户是在不同的时间占用相同的频带宽度。

  <a href="https://sm.ms/image/oiBTHLzU5rPtRC4" target="_blank"><img src="https://i.loli.net/2020/05/23/oiBTHLzU5rPtRC4.png" width = 500px></a>

- 波分多路复用（WDM）：根据光的物理性质，不同波长的光遇到玻璃后的折射率不同，，产生了波分路复用技术。可以看作为是光的“频分多路复用”。

  <a href="https://sm.ms/image/YvmbTgsJ5KLSZ2p" target="_blank"><img src="https://i.loli.net/2020/05/23/YvmbTgsJ5KLSZ2p.png" width = 500px  ></a>

  <a href="https://sm.ms/image/jB1PkRUn3HCXs4y" target="_blank"><img src="https://i.loli.net/2020/05/23/jB1PkRUn3HCXs4y.png" width = 500px  ></a>

- 码分多路复用（CDM）：码分多路复用如今广泛应用于无线链路共享（蜂窝网,卫星通信等）。码分多路复用需要分配，加码和解码的三个过程。

  - **分配：**首先会为每个用户分配一个唯一的m比特**码片序列**（例如S站的码片序列为-1，-1，-1，+1，+1，-1，+1，+1；这里的-1表示0，+1表示1，目的是为了方便加码与解码的计算）,为了能够顺利的解码，我们需要保证各个用户码片序列相互正交（任意两个不同用户相乘（**向量相乘**）结果为0）。
  - **加码：**各个用户使用相同频率的载波，并利用各自码片编码数据（编码信号 = (原始数据)*(码片序列)，如果要发送比特1，那么发送自己的比特序列，如果要发送0，那么要发送自己比特序列的反码）。比如用户分配到了（1，1，1，-1，1，-1，-1，-1）这样的码片序列，那么如果用户要发送0就需要发送（-1，-1，-1，1，-1，1，1，1），如果要发送1那么就要发送（1，1，1，-1，1，-1，-1，-1）
  - **解码：**由于各个用户使用的是同一频率的载波，那么不同用户发送的数据必定会加载在一起，我们称之为叠加向量。基站收到这样的叠加向量后需要进行这样一个运算：该叠加向量与某一用户分配的码片序列做点乘后再除该点乘的摩的绝对值（这样最终结果如果是+1或-1那么对应着1和0，否则结果若是0，那么该设备没有参与发送信号）

  <a href="https://sm.ms/image/IrSom5Wa23QX7Mg" target="_blank"><img src="https://i.loli.net/2020/05/23/IrSom5Wa23QX7Mg.png" width = 500px  ></a>

  <a href="https://sm.ms/image/74w9xnTGML12qKl" target="_blank"><img src="https://i.loli.net/2020/05/23/74w9xnTGML12qKl.png" width = 500px  ></a>

- 分组复用：目前最常用的复用技术，是一种能够按需分配充分利用资源的复用，会在下面的**分组交换**讲解。

#### 数据交换的类型：

- **电路交换：**电路交换中最典型的应用就是电话网络。电路交换需要经历三个阶段：1、建立连接（呼叫/电路建立）; 2、通信；3、释放连接（拆除电路）；最早的电路交换都是独占类型的，随着用户的增加，使用了多路复用技术解决了电路交换网络共享中继线的问题。

  <a href="https://sm.ms/image/YeizutD5oQRvFTr" target="_blank"><img src="https://i.loli.net/2020/05/23/YeizutD5oQRvFTr.png" width = 500px ></a>

  

- **报文交换、分组交换：**

  - **报文交换：**源主机将一个信息一次整体发送完毕。

    <a href="https://sm.ms/image/OwxEpo8AckXHuBS" target="_blank"><img src="https://i.loli.net/2020/05/23/OwxEpo8AckXHuBS.png" width = 500px  ></a>

  - **分组交换：**源主机将报文分拆为一系列较小的数据包（数据包包括头和数据本体，头包括各种信息，如目的地址、源地址、校验信息、使用协议等，这些数据包也被称为分组），这些数据包再被视为一个整体一份一份的发送出去，经过网络核心进行路由转发后到达目的主机，目的主机再根据分组的头来重新组合成一个完整报文。需要注意的是属于同一报文的分组到达目的的路径可能会有所不同，并且这是一种按需分配的共享链路方式（谁发的多，谁占用的就多）

    <a href="https://sm.ms/image/MH1bofNp2ns3YT8" target="_blank"><img src="https://i.loli.net/2020/05/23/MH1bofNp2ns3YT8.png" width = 500px  ></a>

  - 对比：

    - 报文交换与分组交换均采用**存储-转发**交换方式，报文交换是以完整的报文进行“存储-转发”，分组交换是以较小的分组进行“存储-转发”。

    - 分组交换相对于报文交换来说对网络核心的要求更低（报文交换必须要求一个报文全部发送到一个网络核心后才能由该网络核心转发到另一个网络核心，这就要求网络核心的缓存要满足最大报文的长度）。

    - 分组交换的交付速度会高于报文（途径路径经过的路由器越多越明显，对于分组来说，减少了必须等待完整报文全部传送完毕才能够转发到下一个路由器的忙等时间）

      报文：M bits  链路带宽（传输速率）：R bps  分组长度：L bits  跳步数：h  路由器数：n

      - 对于报文交换：T = h*（M/R）

      - 对于分组交换：T = M/R +（h-1）L/R = M/R + nL/R

        <a href="https://sm.ms/image/45eAcjlyKbIhtGE" target="_blank"><img src="https://i.loli.net/2020/05/23/45eAcjlyKbIhtGE.png" width = 500px  ></a>

      - 分组交换允许更多用户同时使用网络，网络资源充分共享。

  - **分组交换的共享性：**分组交换适用于<font color = "red">突发</font>数据传输网络,其相对电路交换有着资源能够<font color = "red">充分共享、简单无需呼叫建立</font>的优点，但可能会产生<font color = "red">拥塞</font>(分组延迟和丢失，需要协议处理可靠数据传输和拥塞控制)，还必须能够保证对于要求高带宽的应用的正常使用（比如视频）。

### 6、计算机网络性能：

#### 速率：

速率即**数据率**也称为**数据传输速率**或**比特率**（这和物理上以m/s的速率不同）

- 速率的指标：单位时间传输信息（比特）的量；单位：（b/s）、（kb/s）、（Mb/s）、（Gb/s）、（Tb/s）；
- 数率往往是指**额定速率**或**标称速率**

#### 带宽：

“带宽”原本是指信号具有的频带宽度，即某一信号最高频率与最低频率之差，单位是Hz；

网络中的“带宽”通常是指数字信道能够传送的“最高数据率”，单位同上面的速率

#### 延迟/时延（delay或latency）：

**什么是丢包**：当一个路由器中的缓存能够承载的分组过多时，再发送进来的分组就会被丢弃，这就叫丢包。

**什么是延迟：**分组到达的速率超出了输出链路容量时，分组会在路由器的缓存中排队，等待输出链路再次空闲。因此延迟过高就会导致丢包。

<a href="https://sm.ms/image/yBFb5nqlZxXYaKS" target="_blank"><img src="https://i.loli.net/2020/05/23/yBFb5nqlZxXYaKS.png" width = 400px  ></a>

**四种分组延迟：**我们从这四种延迟中也可以清楚一个分组发送到目的主机要经历的过程。总延迟 = 结点处理延迟+排队延迟+传输延迟+传播延迟

- 结点处理延迟：其中包括差错检测、确定输出链路。（这部分往往很小）

- 排队延迟：当链路带宽被占满时，分组会在路由器的缓存中排队等待输出链路可用。（这部分取决于现在的拥塞程度）

  - R：链路带宽、L：分组长度 、 a：平均分组到达速率

    我们用流量强度La/R来代表拥塞程度，当La/R接近0，平均排队延迟很小；当La/R接近1，平均排队言辞很大；当La/R大于1，当前请求超出链路的服务能力，延迟无限大。

- 传输延迟：和传输链路的带宽有关，时间为分组长度/链路带宽。

- 传播延迟：物理上的概念，取决于物理链路的长度与信号在该物理链路介质上传播的速度。

#### 时延带宽积：

时延带宽积时网络指标中一个非常重要的概念，对判断目前链路是否达标有着非常重要的意义（比如判断你办了百兆带宽能否享受到该有的待遇，当然要和发送主机的窗口大小比对，小于窗口大小就代表达标，这些概念后续会提）。**时延带宽积 = 传播时延*带宽**，代表特定时间该网络上的最大数据量--已发送但尚未确认的数据。

#### 分组丢失（丢包）：

当一个路由器中的缓存能够承载的分组过多时，再发送进来的分组就会被丢弃，这就叫丢包。

对于丢弃分组，可能由前序节点或源主机重发（也可能不重发，取决于当前的传输协议）

丢包率 = 丢包数/已发分组总数

#### 吞吐量：

吞吐量表示在发送端与接收端之间传送数据速率（b/s），每秒成功发送的数据量

即时吞吐量：给定时刻的速率

平均吞吐量：一段时间的平均速率

瓶颈链路：端到端的路径上，限制端到端吞吐量的链路。

<a href="https://sm.ms/image/XIiBkKFPx4Redrp" target="_blank"><img src="https://i.loli.net/2020/05/23/XIiBkKFPx4Redrp.png" width = 500px  ></a>

### 7、计算机网络体系结构：

计算机网络是一个非常复杂的系统，涉及到很多的组成部分（主机、路由器、各种链路、应用、协议、硬件、软件、...）。这就使得我们最好能够简化这个系统用符合逻辑的方式对这些组成部分分组，使得每个组中的组成部分有着共同的目标，并且组与组之间能够联系，最终构成一个功能完整的体系。

类比航空旅行的服务结构，其每层完成一种（类）特定的服务/功能，每层依赖低层提供的服务，通过层间动作完成相应的功能。各个层次自己发生变化不会影响到其他层次的实现逻辑（换言之，某一层次不用在乎其他层次是如何实现的）

<a href="https://sm.ms/image/JZvPiIcrAlu3pnY" target="_blank"><img src="https://i.loli.net/2020/05/23/JZvPiIcrAlu3pnY.png" width = 500px  ></a>

**什么是计算机网络体系结构：**

- 网络体系结构是从<font color = "red">功能上</font>描述计算机网络机构的，<font color = "red">计算机网络体系机构</font>是计算机网络的各层及其协议的集合。
- 计算机网络结构简称网络体系结构
- 每层都遵循某些<font color = "red">网络协议</font>完成本层功能
- 体系结构是一个计算机网络的功能层次以及其关系的定义，体系结构是<font color = "red">抽象的</font>，如此定义并不能代表该体系结构就是如此实现的。

**分层网络体系结构基本概念：**

<a href="https://sm.ms/image/tJhMCgEU8OoZVSv" target="_blank"><img src="https://i.loli.net/2020/05/23/tJhMCgEU8OoZVSv.png" width = 500px  ></a>

- 实体表示任何可发送或接收信息的硬件或软件进程（同时也说明了分层概念只是抽象概念，和具体实现不同）。
- 协议是控制<font color = "red">两个对等实体</font>进行通信规则的集合，协议是“<font color = "red">水平的</font>”。
- 任一实体需要使用<font color = "red">下层</font>服务，遵循本层协议，实现本层服务，向<font color = "red">上层</font>提供服务，服务是“<font color = "red">垂直的</font>”。
- 下层协议的实现对上层的服务用户是<font color = "red">不可见</font>的。
- 同系统的相邻实体间通过<font color = "red">接口</font>进行交互，通过<font color = "red">服务访问点SAP（Service Access Point）</font>交换原语，指定请求的特定服务。
- 协议是“<font color = "red">水平的</font>”并不代表两个对等的实体之间是可以直接通信的，仍要经过低层的实体之间进行通信后再交付给高层的实体才能够完成协议。

#### OSI（开放互连）参考模型：

OSI参考模型是由国际标准化组织(ISO）在1984年提出的分层网络体系结构模型，目的是支持异构网络系统的互联互通。其包含七层功能，每层完成特定的网络功能，是理解网络通信的最佳学习工具（一种理论模型，市场失败）。

其包含七个层次（从上至下）：应用层（Application）、表示层（Presentation）、会话层（Session）、传输层（Transport）、网络层（Network）、数据链路层（Data link）、物理层（Physical）；

**OSI通信过程：**发送端由上层到下层（一层一层的对分组进行数据封装），接收端由下层到上层（一层一层的根据对分组封装的头数据进行协议的实现并还原成该层应使用的数据）

<a href="https://sm.ms/image/MVapyNotk46iuZD" target="_blank"><img src="https://i.loli.net/2020/05/23/MVapyNotk46iuZD.png" width = 700px  ></a>

<a href="https://sm.ms/image/s18YuakKfnlv4br" target="_blank"><img src="https://i.loli.net/2020/05/23/s18YuakKfnlv4br.png" width = 700px ></a>

面对上图的OSI模型的通信过程，我们不得不考虑一个问题：为什么数据从上层到上层要进行数据封装？

- 增加<font color = "red">控制信息</font>，构造协议数据单元(PDU)
  - 控制信息主要包括：
    - <font color = "red">地址（Address）</font>：标识发送端/接收端
    - <font color = "red">差错检测编码</font>：用于差错检测或纠正
    - <font color = "red">协议控制</font>：实现协议功能的附加信息

#### 各层次功能：

- **应用层功能：**为用户提供用户代理（浏览器就是其中的一种）或网络接口使用网络服务；用户通过应用层来使用网络服务（各种应用层的协议也都是为了网络应用能够正确的使用和运行）。

  - 典型的应用层服务：
    - 文件传输（FTP）
    - 电子邮件（SMTP）
    - Web（HTTP）
    - ...

  <a href="https://sm.ms/image/s18YuakKfnlv4br" target="_blank"><img src="https://i.loli.net/2020/05/23/Rgyiq6oHhuXIA3k.png" width = 600px ></a>

- **表示层功能：**处理两个系统间交换信息的<font color = "red">语法和语义</font>问题。主要包括：数据表示转化（转化为主机独立的编码）、加密/解密、压缩/解压缩。

  <a href="https://sm.ms/image/clp2rLM5KHxBGij" target="_blank"><img src="https://i.loli.net/2020/05/23/clp2rLM5KHxBGij.png" width = 600px></a>

- **会话层功能：**使应用建立和维持会话，并能使会话获得同步。会话层使用校验点可使通信会话在通信失效时从校验点继续恢复通信。

  会话层控制的主要动作：**建立**（A、B两台网络设备之间要通信，要建立一条会话供他们使用，在建立会话的过程中可能会有身份验证，权限鉴定等环节）、**维护**（通信会话建立后，通信双方开始传递数据，当数据传递完成后，OSI会话层不一定会立刻将两者这条通信会话断开，它会根据应用程序和应用层的设置对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输局）、**断开**（当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。或者A、B重启、关机、手动执行断开连接的操作时，OSI会话层也会将A、B之间的会话断开）、**同步**（对来自表示层的数据插入“同步点”，保证会话意外断开后，下次会话不用从头开始，目的主机告知源主机上一次断开的同步点在哪里，源主机通过这个告知只发送这个同步点以后的信息）

  <a href="https://sm.ms/image/DB5HWJw9ymL2upj" target="_blank"><img src="https://i.loli.net/2020/05/23/DB5HWJw9ymL2upj.png" width = 600px  ></a>

- **传输层功能：**传输层需要保证一个报文能够完整并正确的传输到目的主机上的某一<font color = "red">进程</font>上，要保证分组能够在<font color = "red">端—端</font>（所谓的端到端实际上就是传输层连接的端点，也叫套接字（由IP地址+进程号组成））上正确传输。其需要进行：**分段与重组**（就是上面一直说的对报文进行分组，并附加各种信息）、**SAP寻址**（附加的部分信息包括目的进程和原进程，传输层需要保证正确的分组能够完整的传输给正确的进程）、**连接控制**（传输层需要保证与目的主机能够建立连接，进行源源不断的数据传送。如TCP的三次握手与四次挥手）、**流量控制**（当网络链路过于拥阻，传输层需要有一个检测机制并同时做出一些应对措施，如：减少上传的分组直到链路不在繁忙）、**差错控制**（传输层要保证源主机所发送的分组在传送的过程中没有损失或是篡改）。

  <a href="https://sm.ms/image/dEnMXi3YAkKo81u" target="_blank"><img src="https://i.loli.net/2020/05/23/dEnMXi3YAkKo81u.png" width = 600px  ></a>

  <a href="https://sm.ms/image/5Vyp4WfKdQDU1NI" target="_blank"><img src="https://i.loli.net/2020/05/23/5Vyp4WfKdQDU1NI.png" width = 600px  ></a>

- **网络层功能：**负责<font color = "red">源主机到目的主机</font>数据分组交付，其目的在于如何将分组从庞大的网络核心中通过节点的跳跃到达正确的目的主机。是一种<font color = "red">主机—主机</font>的传输。其要做的动作为：**逻辑寻址**（在Internet网络中所有接入的主机都有一个唯一的IP地址，网络层需要确保数据能够正确送到拥有这个IP地址的主机上）、**路由**（路由器互连形成路由网络，并路由分组最终到达目的主机）、**分组转发**（对于每个路由器来说，要有一个本地路由表，当收到分组后，根据分组的目的IP地址来选择从路由器所连接的哪条线路转发出到下一个路由器上）。

  <a href="https://sm.ms/image/vg2stzNKB5y9oZc" target="_blank"><img src="https://i.loli.net/2020/05/23/vg2stzNKB5y9oZc.png" width = 600px  ></a>

  <a href="https://sm.ms/image/eL869MItXgD7SGj" target="_blank"><img src="https://i.loli.net/2020/05/23/eL869MItXgD7SGj.png" width = 600px  ></a>

  - **数据链路层功能：**负责<font color = "red">结点—结点</font>数据传输（对于网络层是寻找IP地址，IP地址对于每台主机并不是一直不变的，对于主机来说唯一不变的是它自带的那张网卡！！网卡上带有物理地址，当主机接入Internet后，路由器会为它分配一个IP地址（如果是IPv4，由于IPv4地址的耗尽，路由器会通过路由器的端口来区分连入其中的主机并未它们传输数据），因此网卡上的物理地址与IP地址会有一个动态的映射关系）。链路层的动作：**组帧**（为每由传输层传送过来的分组设置开始与结束标志组成一个一个的帧，与其他帧分开）、**物理寻址**（在帧头中增加发送端或/接收端的物理地址标识数据帧的发送端/或接收端，当一个路由器收到一个分组后通过该分组关于网络层的协议找到下一个应该跳往的IP地址，再根据这个IP地址找到所属路由器/或主机的物理地址后发送到物理层进行转发）、**流量控制**（避免淹没接收端，避免传送的数据过大，超出接收端的执行范围，吞吐量就是对其测试的一个标准）、**访问（接入）控制**（在任一时刻决定哪个设备拥有链路（物理介质）控制的使用权）

    <a href="https://sm.ms/image/xl3TDVhPRwZQ9A6" target="_blank"><img src="https://i.loli.net/2020/05/23/xl3TDVhPRwZQ9A6.png" width = 600px  ></a>

    <a href="https://sm.ms/image/bAdRH4KUluZScIv" target="_blank"><img src="https://i.loli.net/2020/05/23/bAdRH4KUluZScIv.png" width = 600px></a>

- **物理层功能：**关注链路的物理特性

  - 接口特性：机械特性、电气特性、功能特性、规格特性
  - 比特编码：将数据链路层的信息表示为01编码
  - 数据率：数率，关注该链路中数据的速度（b/s）
  - 比特同步：时钟同步
  - 传输模式：单工（要么只能发不能收，要么只能收不能发）、半双工（一条链路能发能收，但不能同时）、全双工（能发能收，可以同时进行）

#### TCP/IP参考模型：

**TCP/IP参考模型**事实上是对于OSI参考模型的一种简化，其包含：应用层、运输层、网际层、网络接口层

<a href="https://sm.ms/image/yELWkbntYsqZAK4" target="_blank"><img src="https://i.loli.net/2020/05/23/yELWkbntYsqZAK4.png" width = 500px  ></a>

但是其过于化简，特别是网络接口层包含了过多的要素，使得该层次不好理解。

#### 5层参考模型：

5层参考模型总和了OSI和TCP/IP的优点，其包含五个层次：

- 应用层：支持各种网络应用：FTP,SMTP,HTTP,...
- 传输层：进程—进程的数据传输：TCP,IP
- 网络层：源主机到目的主机的数据分组路由和转发：IP协议、路由协议等
- 链路层：相邻网络元素（主机、交换机、路由器等）的数据传输
- 物理层：比特传输

<a href="https://sm.ms/image/4EF39zok6VvqLSW" target="_blank"><img src="https://i.loli.net/2020/05/23/4EF39zok6VvqLSW.png" width = 400px  ></a>

## <a name="第二章">第二章：网络应用层</a>

### 1、网络应用体系结构：

在计算机网络体系结构中应用层算得上是距离我们的日常生活是最近的了，我们常用的网络应用包括：百度、QQ、微信、Email、支付宝等。这些应用都应该遵循一定的体系结构来方便使用或是维护。

#### 网络应用体系结构的种类：

- **客户机/服务器结构（Client-Server，C/S）：**

  客户机/服务器结构中最典型也是最常见的应用就是web，web通过HTTP协议实现客户机与服务器之间的通信。客户机/服务器结构硬件上分为两部分：客户机与服务器。

  - 服务器：服务器一般都会提供全年无休的服务，7*24小时不停的运行，并随时准备为来自客户机的请求提供响应。一般我们访问网站都会输入它的域名或IP地址，服务器会保证它的域名和IP地址是永久性的。服务器还需要保证其硬件素质高，能够处理大量的请求，并且需要能够与其他的服务器相互协助提供可扩展性。
  - 客户机：客户机需要与服务器进行通信，并且使用服务器提供的服务（比如典型的web应用，客户机只负责建立连接、请求内容并图形化的显示收到的内容，其余复杂的算法与数据处理都是由服务器自身进行处理的）。客户机不会像服务器一样一直接入网络中，为了节约网络资源，客户机只会在需要内容时再接入网络并与服务器保持连接。由于客户机（比如移动端主机）所处的位置和接入的路由器可能会不固定，因此客户机可能会使用动态的IP地址。而且客户机一般不会与其他客户机进行直接通信，若要建立通信一般都会先经历服务器所提供的相应转接服务。

  <a href="https://sm.ms/image/8izkSK4DRtG7ZJx" target="_blank"><img src="https://i.loli.net/2020/05/24/8izkSK4DRtG7ZJx.png" width = 400px  ></a>

- **点对点结构（Peer-to-peer，P2P）：**P2P结构相对与C/S结构，P2P中，任意的端系统/节点之间可以直接通讯。P2P中没有永远在线的服务器，各个端系统也没有一直不变的IP地址。其有着<font color = "red">高度可伸缩性</font>，同时也<font color = "red">难于管理</font>。相对于C/S结构，其传输文件有着一定的优势（对于C/S结构，客户机不与客户机直接相连。客户机要先将文件上传到服务器上，另一客户机再从服务器上下载。P2P就是两台机器建立连接，直接传送文件，省去了再次下载的步骤）

  <a href="https://sm.ms/image/OnyMVJ6j7c4AldH" target="_blank"><img src="https://i.loli.net/2020/05/24/OnyMVJ6j7c4AldH.png" width = 300px  ></a>

  

- **混合结构（Hybrid）：**综合C/S结构与P2P两者的特性，一般的应用方式为：用户间文件传输使用P2P结构，而用户在文件搜索时采用C/S结构（当某节点想要分享文件，只需要向服务器登记自己所有的内容，以及文件的下载地址。某节点想要获取内容时，向服务器查询是否有该内容，若有该节点与持有该内容的节点直接建立连接并传输）。

  <a href="https://sm.ms/image/897JAD5ZiU6cboR" target="_blank"><img src="https://i.loli.net/2020/05/24/897JAD5ZiU6cboR.png" width = 300px  ></a>

### 2、网络应用进程通信：

对于网络应用来说，应用实际上就是在主机上运行的一个个进程。对于本地主机上的进程之间要利用<font color = "red">操作系统提供的进程间通信机制</font>来完成本地主机中的进程通信。对于不同主机中的应用（进程）进行通信就要通过网络来传输信息了（<font color = "red">消息交换</font>）。

**应用层协议：**为了方便下面理解，这里简单叙述下应用层次协议。

- 应用层协议分为，公开协议和私有协议。公开协议是由RFC（Request For Comments）组织定义的也是我们日常使用最多的。所有网络应用应该遵循应用层的协议，如我们要使用web应用，那么web应用应该使用HTTP协议，我们要使用传输文件的应用，那么传输文件应用应该使用FTP协议。这些协议促使通信的两端主机上运行的进程可以由于遵循了同一种通信格式，产生了应有的”动作”。
- 应用层协议得内容：
  - 消息的类型：这是一个请求消息，还是一个响应消息。（请求消息的内容包含发送方所期望的内容，响应消息一般是对请求消息的回应）
  - 消息语法/格式：包括该消息中有哪些字段，每个字段的描述方式。
  - 字段的语义：该字段中信息的含义。
  - 规则：进程何时发送/响应消息。

<a href="https://sm.ms/image/C3W4GHd1n7OYJs8" target="_blank"><img src="https://i.loli.net/2020/05/24/C3W4GHd1n7OYJs8.png" width = 300px  ></a>

**如何寻址进程：**由于进程与进程之间也要相互遵循协议，不同进程之间的协议可能会不同，这就意味着如果信息发送给了错误的进程，该进程可能会因为协议问题无法处理发送进来的消息，又或者是不应该是该进程应该处理的消息。对于<font color = "red">消息交换</font>来说，最终目的是要将应用进程处理好的数据传输给正确的目的主机的应用进程。那么就意味着，各个主机的IP地址不仅仅需要唯一，各个运行在主机中的进程也需要有一个区分标准，主机会为每个需要通信的进程分配一个端口号（在该主机中是唯一的），通过**IP地址+端口号**的方式唯一的表示通信进程。一般主机上的通信进程要发送信息时，就会将信息打包到**套接字**（包含IP地址+端口号，以及要使用的传输协议）中，送往低层的传输层去。

**套接字（Socket）：**Socket是为了解决应用进程的并发问题，源主机的各个应用进程传递信息时需要传递给目的主机上为这些进程提供服务的进程上，因此我们不仅仅需要目的主机号，同时也需要指定目的主机的应用进程号。

也就是说由于不同的应用进程传输的信息要通过同一个TCP协议端口（传输层的概念，以后会说）传输数据，为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP／IP协议交互提供了称为套接字 (Socket)的接口，区分不同应用程序进程间的网络通信和连接。

**Socket包含三个参数：**通信的目的地址、使用的传输协议（TCP还是UDP，不同的应用对传输层的协议要求也不同）、使用端口号。

Socket可以看成在两个程序进行通讯连接中的一个端点，一个程序将一段信息写入Socket中，该Socket将这段信息发送给另外一个Socket中，使这段信息能传送到其他程序中。

<a href="https://sm.ms/image/PN4Hd6xWmBAfGua" target="_blank"><img src="https://i.loli.net/2020/05/24/PN4Hd6xWmBAfGua.png" width = 300px  ></a>



### 3、网络应用对传输服务的需求：

目前在Internet上，传输层主要提供两种服务（协议）：TCP服务、UDP服务。两者各有各自的特点与应用的方面：

- TCP服务：
  - 面向连接：客户机/服务器进程在传输数据之前，需要建立连接。
  - 可靠的传输：TCP会提供校验一直来确保接收到的各个分组没有错误，并且最终能够重组为一个整体的报文。
  - 流量控制：发送方不会发送速度过快，超过接收方的处理能力。
  - 拥塞控制：当网络负载过重时能够限制发送方的发送速度，否则丢包率严重并且造成网络资源的浪费。
  - 不提供时间/延迟保障：这与传输的链路有关，单单一个主机无法保证链路的具体情况。
  - 不提供最小带宽保障：同上。
- UDP服务：
  - UDP可以视为简化的TCP服务，UDP不会去建立连接，也不会去检验收到的数据是否有错误。但正因为这些简化使得UDP的传输数率快于TCP，广泛应用到一些比如视频，网络电话可容错高但是要求速度的应用上。
  - 无连接
  - 不可靠的数据传输
  - 不提供：可靠性保障、流量控制、拥塞控制、延迟保障、带宽保障。

**网络应用对传输服务的需求：**由上面介绍的两种传输服务，网络应用需要针对自己所服务的内容来选取相应的传输服务。比如：网络电视、网络游戏等对数据丢失有一定的容忍，但对延时要求高的应用应该选取UDP服务，并且网络带宽应该达到应用要求的最低值。文件、Email这类对延时要求不高，但对数据的正确性要求高的应用应该选择TCP服务。

<a href="https://sm.ms/image/S76QrmMBenHA452" target="_blank"><img src="https://i.loli.net/2020/05/24/S76QrmMBenHA452.png" width = 500px  ></a>

### 4、特定网络应用及协议：

#### Web应用：

Web也成为万维网，我们平常所说的网页或是前端就是Web应用。Web应用是典型的C/S结构，通过网页来显示人们能看懂的内容，网页与网页之间相互链接，方便阅读。我们通过浏览器来显示网页，通过网页中对对象的寻址并发送对文件的请求，服务器接收请求后回应请求，返回给客户机信息。

**一个网页中包含多个对象**：

- 对象：HTML文件、JPEG图片、视频文件、动态脚本等
- 基本HTML文件：包含对其他对象引用的链接

作为客户机，我们起码要知道网站（服务器）的链接（IP地址）才可以访问，这就涉及到了<font color = "red">对象的寻址</font>。

**对象的寻址（addressing）：**

- URL（Uniform Resoure Locator）：统一资源定位器，它是万维网服务程序上用于指定信息位置的表示方法，Web浏览器通过URL从Web服务器请求页面。 域名可以由字母构成（www.baidu.com，英文字母显然更好记忆）也可以用IP地址构成（119.75.217.109，域名与IP地址会有一个一对一的映射）
- **URL的格式：**以 http://www.runoob.com/html/html-tutorial.html 为例
  - scheme://host.domain:port/path/filename
    - scheme ： 定义因特网服务的类型。最常见的类型是 HTTP（超文本传输协议）
    - host ： 定义域主机（http 的默认主机是 www）
    - domain ： 定义因特网域名，比如 runoob.com
    - port ： 定义主机上的端口号（http 的默认端口号是 80）
    - path ： 定义服务器上的路径（如果省略，则文档必须位于网站的根目录中）。
    - filename ： 定义文档/资源的名称
    - 常见的URL scheme：
      - http：超文本传输协议，用于访问以http开头的普通网页。不加密。
      - https：安全超文本传输协议。安全网页，加密所有信息交换。
      - ftp：文本传输协议。用于文件上传，下载至服务器。
      - file：本地主机上的文件

#### HTTP协议：

HTTP协议（超文本传输协议）是一种详细规定了浏览器和万维网(WWW = World Wide Web)服务器之间互相通信的规则，通过因特网传送万维网文档的数据传送协议。它也是一个<font color = "red">无状态的协议</font>（每次的请求都是独立的，它的执行情况和结果与前面的请求和之后的请求是**无直接关系**的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况，服务器中没有保存客户端的状态，客户端必须每次带上自己的状态去请求服务器）

其利用低层的TCP传输服务，工作流程为：

​					1、服务器在80端口（http协议的默认端口）等待客户的请求

​					2、浏览器发起到服务器的TCP连接（通过创建套接字Socket）

​					3、服务器接受来自浏览器的TCP连接

​					4、浏览器（HTTP客户端）与Web服务器（HTTP服务器）交换HTTP消息

​					5、传输完毕后，传输返回的消息通过浏览器显示，并且浏览器与Web服务器断开连接

HTTP协议使C/S结构中的客户机与服务器都有自己的职责：

- 客户机浏览器：请求、接受、展示Web对象，必要时也可采用本地浏览器所支持的Session或Cookie来记录当前网页的状态（因为HTTP是一种无状态的协议，服务器一次性发送客户机所要的请求后，就断开连接，如果客户想要重新访问服务器，就需要再次建立新的连接，因此当前网页所处的状态就得由本地缓存来维护（比如下次再次访问该网站不需要输入密码、购物车也不需要重新装填））

<a href="https://sm.ms/image/IwmJQUsziv9MPlN" target="_blank"><img src="https://i.loli.net/2020/05/24/IwmJQUsziv9MPlN.png" width = 300px  ></a>

**HTTP连接：**HTTP协议分为两种连接方式，非持久性连接（每个TCP连接最多允许传输一个对象，HTTP1.0版本使用非持久性连接）、持久性连接（每个TCP连接允许传输多个对象，HTTP1.1默认使用持久性连接）

- 响应时间分析与建模：在对比持久与非持久性连接之前我们需要知道几个基本概念方便下面的比对。

  - RTT（Round Trip Time）：从客户端发送一个很小的数据包到服务器并返回所经历的时间。
  - 响应时间：
    - 发起、建立TCP连接（这需要一个RTT）
    - 发送HTTP消息氢气消息到HTTP响应消息的前几个字节到达（这也需要一个RTT）
    - 响应消息中所包含的文件/对象传输时间（未知）
  - 传输一个对象总共用时：2RTT + 文件发送时间

  <a href="https://sm.ms/image/SpGHt1nmRUq4TEo" target="_blank"><img src="https://i.loli.net/2020/05/24/SpGHt1nmRUq4TEo.png" width = 300px  ></a>

- 非持久性连接：假设我们在浏览器中输入某个URL请求一个文件，该文件包含文本信息以及10个jpeg图片的连接。以下是非持久性连接的过程与分析

  ​	1、客户端动作：HTTP客户端向该地址的服务器上的HTTP服务器进程（端口为80）发起TCP连接请求。

  ​	2、服务器动作：HTTP服务器在端口80等待TCP连接请求，接受连接并通知客户端。

  ​	3、客户端动作：HTTP客户端将HTTP请求消息（包含URL地址）通过TCP连接的套接字发出，消息中包含		  的URL表名客户端需要对象

  ​	4、服务器动作：HTTP服务器收到请求消息，解析，产生包含所需要对象的响应消息，并通过套接字发送给   	      客户端。

  ​	5、服务器动作：服务器将该对象发送完毕后关闭TCP连接。

  ​	6、客户端动作：HTTP客户端收到响应消息，解析html文件，显示该html文件，发送现有10个指向jepg对		  象的超连接。

  ​	7、关于5个jepg文件重复以上动作

  ​	

  1与2至少需要一个RTT，3与4至少需要一个RTT，因此每个对象至少需要2个RTT。此外操作系统需要为每个TCP的连接开销资源，并且这样不断地连接和断开会影响网页的反应速度。如果仍要建立在非持久性的HTTP并要求网页的反应速度的话，浏览器开启多个并发的TCP连接，同时请求多个对象是一个解决的方法，但造成的问题也是相当的明显的，如这样的用户数目过于庞大会超出服务器的处理能力。

- 持久性连接：发送响应后，服务器保持TCP连接的打开，后续的HTTP消息可还以通过这个连接发送。

  - 无流水的持久性连接：
    - 客户端只有收到前一个响应才发送新的请求
    - 每个被引用的对象耗时一个RTT
  - <a name="流水线机制">带有流水机制的持久性连接</a>
    - HTTP1.1的默认选项
    - 客户端只要需要一个引用对象就尽快发出请求
    - 理想情况下(服务器响应的足够快，在处理下一个请求之前就已经将上一个请求发送出去)，收到所有的引用对象只需耗时2个RTT（包含一个建立连接的RTT与其余对象的请求与传输的一个RTT）


**HTTP消息格式：**HTTP协议有两类消息：请求消息和响应消息。

- **请求消息：**

  ```
  <method> <request-URL> <version>    //方法 请求URL  HTTP版本，也叫请求行
  <headers>                           //HTTP请求头
                                      //空行, 标志着请求头结束，请求正文（请求体）的开始
  <entity-body>                       //数据
  ```

  <a href="https://sm.ms/image/hyuwqrB3z6ZCoD4" target="_blank"><img src="https://i.loli.net/2020/05/25/hyuwqrB3z6ZCoD4.png" width = 300px  ></a>

  如：

  ```http
  GET /somedir/page.html HTTP/1.1
  Host: www.someschool.edu
  User-aget: Mozilla/4.0
  Connection: close
  Accept_language:fr
  
  请求正文
  ```

  - **请求方法：**在 HTTP 协议中，HTTP 请求可以使用多种请求方法，这些方法指明了要以何种方式来访问 Request-URI 所标识的资源。在HTTP/1.1中包括：GET,POST,HEAD（ 请求获取由 Request-URI 所标识的资源的响应消息报头）,PUT（将消息体中的文件上传到URL字段所指定的路径）,DELEDTE（删除URL字段所指定的文件）。这里主要介绍POST和GET方法。

    - **GET：**请求获取由 Request-URI（request行的URL字段后面的参数，如www.somesite.com/animalsearch?monkeys&banana ;animalsearch?monkeys&banana 该字段就是 Request-URI）所标识的资源 请求参数在 请求行中。

      GET 方法用于获取（对于客户机是上传）由 Request-URI 所标识的资源的信息，常见的形式是：

      ​																														GET Request-URI HTTP/1.1

      我们可以使用GET方法来提交表单数据，用GET方法提交的表单数据只经过了简单的编码，同时它将作为URL的一部分向服务器发送，因此，如果使用GET方法来提交表单数据就存在着安全隐患上。

      因为浏览器对url的长度有限制，因此GET方法提交的数据是作为URL请求的一部分所以提交的数据量不能太大。

    - **POST：**请求服务器接收在请求中封装的实体，并将其作为由 Request-Line 中的 Request-URI 所标识的资源的一部分请求参数在请求体中

       POST方法克服了GET方法的一些缺点。通过POST方法提交表单数据时，数据不是作为URL请求的一部分而是作为标准数据（在请求消息的消息体中上传客户端的输入）传送给Web服务器，这就克服了GET方法中的信息无法保密和数据量太小的缺点。因此，出于安全的考虑以及对用户隐私的尊重，通常表单提交时采用POST方法。

  - **请求头（headers）：**每个头域由一个域名，冒号（:）和域值三部分组成。域名是大小写无关的，域值前可以添加任何数量的空格符，头域可以被扩展为多行，在每行开始处，使用至少一个空格或制表符。

    其可以包括这些头域（每个头域的参数都有着一定的意义，这些头域中包括了一些服务必须要知道的信息，如应该返回的语言，请求的浏览器版本是否保持连接、指定被请求资源的Internet主机和端口号（一般会自动从输入的URL中提取出来）等等。想深入了解请自己百度）：Transport 头域、Client 头域、Cookie/Login 头域、Entity头域、Miscellaneous 头域、Cache 头域。

- **响应消息：**

  ```
  <version> <status> <reason-phrase>             //HTTP版本 响应码  响应结果解释，也叫响应行
  <headers>                                      //HTTP响应头
                                                 //空行
  <entity-body>                                  //数据
  ```

  如：

  ```http
  HTTP/1.1 200 OK
  Connection: close
  Date:Thu,06 Aug 1998 12:00:15 GMT
  Server:Apache/1.3.0(Unix)
  Last-Modified:Mon,22 Jun 1998
  Content-Length:6821
  Content-Type:text/html
  
  data data data data data data ...
  ```

  - **状态行：**状态行由协议版本、数字形式的状态代码，及相应的状态描述组成，格式如下：

    <HTTP版本>  <响应码>  <响应结果解释> 

    - 状态代码由 3 位数字组成， 表示请求是否被理解或被满足，以及当前的状态：
      - 1xx：指示信息——表示请求已经接受，继续处理
      - 2xx：成功——表示请求已经被成功接收、理解、接受。（如 200 OK）
      - 3xx：重定向——表示当前搜索的服务器的IP地址被更换，要完成请求必须进行更进一步的操作。（如 301 Moved Permanently）
      - 4xx：客户端错误——请求有语法错误或请求无法实现（典型的404 Not Found）。
      - 5xx：服务器端错误——服务器未能实现合法的请求（如505 HTTP Version Not Supported）。

  - **响应头信息：**和上面的请求头信息的功能是一样的，感兴趣自己查吧。

  - **相应正文：**响应正文就是服务器返回的资源的内容，响应头后的空行代表响应头接受，下面是正文。

**Cookie技术：**Cookie是指在HTTP协议下，服务器或脚本可以维护客户端计算机上信息的一种方式 。通俗地说，Cookie是一种能够让网站Web服务器把少量数据储存到客户端的硬盘或内存里，或是从客户端的硬盘里读取数据的一种技术。 

- 为什么要有Cookie：HTTP协议是一种无状态的协议，这就意味着两次客户端对同一Web服务器进行请求访问，Web服务器是无法辨别出该两次请求是来自同一客户端的。

  我们用购物车举例子，对于各大购物网站的购物车，一般我们会认为当我们选择商品后，购物车的商品会立刻送往服务器的数据库中进行维护。但事实并不是这样的，服务器与客户端一直建立连接是十分消耗资源的行为（每次我们对购物车增加删除都会使服务器需要立刻维持数据库的更新，这样的连接数据库会非常的耗费资源），并且这其中甚至还有客户端与服务器因为连接问题导致的不同步问题，这就使得客户端与服务器一直建立连接并不现实。那么如何有一个方案能够解决无状态连接带来的问题呢？解决问题的方式就是由浏览器建立一个本地缓存，当我们每次访问网页（Cookie可以判断本地主机是否浏览的是同一网站）时，这样的缓存都会记录一部分信息，下次再次访问同一网站时，浏览器将缓存中记录的已有信息同请求的信息一起打包交给服务器去处理，服务器根据这样的缓存中的记录来对自己的数据库进行相应的操作并返回应有状态下的信息，这样做到既能够维护同步问题又能够解决网络资源的问题。这样的技术就叫做Cookie技术，但是于此同时Cookie技术也为用户隐私的问题造成了一定的麻烦。

- Cookie的组件：

  - HTTP响应消息的cookie头部行
  - HTTP请求消息的cookie头部行
  - 保存在客户端主机上的cookie文件，由浏览器管理
  - Web服务器端的后台数据库（根据客户端传入的Cookie来记录状态或查询状态并为客户端响应该状态下的信息）

- Cookie的原理：其实和上的例子差不多，下面的图片能够更加直观的展示

  <a href="https://sm.ms/image/kfbtBmXVqgxS94T" target="_blank"><img src="https://i.loli.net/2020/05/25/kfbtBmXVqgxS94T.png" width = 400px  ></a>

### 5、Web缓存/代理服务器技术：

**功能：**在不访问服务器的前提下满足客户端的HTTP请求。该技术是一种能够缩短客户请求的响应时间、减少机构/组织的流量或在大范围内实现有效的内容分发的技术。

**其技术的核心组成为：**

- Web缓存/代理服务器：一种中间代理的服务器，用户若要访问需要先设定浏览器通过缓存进行Web访问。客户端请求资源发发出HTTP请求时向缓存/的代理服务器发送，而并不会直接向原始服务器发送请求。

  - 如果请求对象在缓存中，缓存返回对象。
  - 否则，缓存服务器向原始服务器发送HTTP请求，获取该对象，然后返回给客户端并保存。

- 客户端：客户端上的浏览器进行HTTP请求时直接与原始服务器发送请求或向缓存服务器联系。

- 服务器：原始服务器，存放着大量资源。

  <a href="https://sm.ms/image/2XJFgvwMjnVpqf1" target="_blank"><img src="https://i.loli.net/2020/05/25/2XJFgvwMjnVpqf1.png" width = 300px  ></a>

**为什么要发明这种技术：**该技术是一种能够缩短客户请求的响应时间、减少机构/组织的流量或在大范围内实现有效的内容分发的技术。下面我会举例子来证明该技术的有效性。

- 不使用Web缓存/代理服务器技术示例：假定一个组织内有若干客户机，这些若干的客户机构成一个带宽为10Mbps的局域网。该机构只有一条与外网（Internet）连接的线路，并且该链路带宽为1.5Mbps。该机构网络中的浏览器平均每秒有15个到原始服务器的请求，并且这些对象的平均大小为100000比特，从机构路由器到原始服务器的往返延迟为2秒。

  该机构网络性能分析：

  局域网利用率：0.1（M）\*15（次/s）/10Mbps = 15%；

  接入互联网的链路利用率 ：0.1（M）\*15（次/s）/1.5Mbps = 100%；对于该数值，网络指标解释过接近一的             												延时为很大，大于1为无限大。

  总延时：互联网上的延时+访问延时+局域网延时 = 2秒 + 几分钟 + 几微秒

  可知，直接访问原始服务器还是相当耗时的，并且利用提高接入外网的带宽的方式也是相当耗费资金的。

  <a href="https://sm.ms/image/oUqaynA8uQtzXKx" target="_blank"><img src="https://i.loli.net/2020/05/25/oUqaynA8uQtzXKx.png" width = 300px  ></a>

- 使用Web缓存/代理服务器技术示例：情况同上，但安装了一个请求资源命中成功率为0.4的Web缓存服务器。

  该机构网络性能分析：

  40%的请求能够立刻得到满足

  60%的请求通过原始服务器满足

  接入到互联网的链路的利用率下降到60%，从而其延迟可以忽略不计，可能几微秒而已

  总延时：互联网上的延时+访问延时+局域网延时 = 0.6\*（2+几微秒） +0.4\*n微秒 < 1.4微秒 

**Web缓存/代理服务器技术的同步问题：**

由于使用Web缓存/代理服务器，客户机不会直接访问原始主机，因此Web缓存/代理服务器要对自己持有的版本是否为最新的（与原始主机应该保持一致）要有一定的审查方法。

Web缓存/代理服务器会在当前资源被请求时发送一个很小的HTTP请求消息（if-modified-since：\<date>

）询问原始主机自己的版本是否是最新版本,如果当前是最新版本，原始服务器会发送一个回应消息表示当前版本是最新的否则会发送被询问的对象。

<a href="https://sm.ms/image/SjJ45PCEzlHOWna" target="_blank"><img src="https://i.loli.net/2020/05/25/SjJ45PCEzlHOWna.png" width = 300px    ></a>

### 6、Email应用：

**Email应用的构成组件：**邮件客户端、邮件服务器、SMTP（Simple Mail Transfer Protocol）协议。

- 邮件客户端：负责读、写Email消息，与服务器交互，收，发Email消息，可以用Web作为客户端。

- 邮件服务器：存储发送给该用户的Email，它为每一个用户分配一个“邮箱”。当客户端关闭的时候，它能够保证其他人在这时仍然能够为我们发送邮件，并保存在“邮箱”中。该种服务器种包含一个待发送消息队列，它能够代替客户端确保要发送的邮件能够发送到指定的地点。它能够保证7\*24小时不断在线，并且能够使得邮件异步传输。

- SMTP协议：简单邮件传输协议，它是邮件服务器之间传输消息所使用的协议。在SMTP协议中，**客户端**是指要发送消息的服务器，**服务器**是指要接受消息的服务器。

  <a href="https://sm.ms/image/HZyPX7epBSlbTdu" target="_blank"><img src="https://i.loli.net/2020/05/25/HZyPX7epBSlbTdu.png" width = 200px    ></a>

  下图为Email实现过程的示例：Alice利用客户端发送到了属于自己的Email服务器，Email服务器会将该信件置入到发送队列中，Alice的邮件服务器将该邮件发送给属于Bob的Email服务器的信箱中，最后Bob在某一时刻利用邮件客户端查看该信箱并收到来自Alice的来信。由此可知Email是一个典型的**异步应用**。

  <a href="https://sm.ms/image/N6ExVDyOFJP8HwK" target="_blank"><img src="https://i.loli.net/2020/05/25/N6ExVDyOFJP8HwK.png" width = 500px    ></a>

#### SMTP协议：

SMTP协议使用传输层的TCP协议来保证Email消息的可靠传输，其默认端口为25。它的交互模式为**命令/响应**的交互模式。通常Email消息中只能包含七位ASCII码。

SMTP交互示例：S代表Server（指要接受消息的服务器），C代表Client（指要发送消息的服务器）

```
S： 220 hamburger.edu 		//两者建立TCP连接之后，你好我是hamburger.edu域的邮件服务器
C： HELO crepes.fr			//HELLO我是crepes.fr域的邮件服务器
S： 250 Hello crepes.fr, pleased to meet you //当接受邮件的服务器接受上一条消息后会发250表示连接没											  //问题，250表示正确的确认
C： MAIL FROM:<alice@crepes.fr>	//发送服务器向接收服务器表示自己有一封邮件想要发送过去
S： 250 alice@crepes.fr... Sender ok  //接收服务器表示可以发送过来
C： RCPT TO:<bob@hamburger.edu>		//发送服务器向接受服务器表示这封邮件要发送给谁
S： 250 bob@hamburger.edu ... Recipient ok //接受服务器表示自己能够发送给这个用户
C： DATA			//发送服务器向接收服务器表示自己要发送数据了
S：354 Enter mail,end with "." on a line by itselt //接收服务器表示请发送email用一个.来表示结束												   //发送
C：Do you like ketchup?		//C发送的内容				
C:How about pickles?		 //C发送的内容
C：.							 //C表示自己发送完毕
S：250 Message accepted for delivery //S表示接收成功
C：QUIT       //C表示可以断开连接了
S：221 hambuger.edu closing connection //s发送完这条消息后就断开连接
```

**SMTP的特点并与HTTP的对比：**SMTP使用持久性的连接（知道一整个邮件发完才会结束连接），要求消息必须由7位SCII码构成，利用“回车+.+回车”来确认消息的结束。

HTTP是一种拉式（浏览器要将Web服务器中的网页拉回到本地）的网络应用。

SMTP是一种推式（要将发送方的消息推送到接收方）的网络应用。

它们都采用命令/响应的交互模式

命令和状态代码都是ASCII码

HTTP：每个对象封装在独立的响应消息中

SMTP：多个对象在由多个部分构成的消息中发送（下面关于SMTP格式会讲解）

#### Email消息格式与POP3协议：

**SMTP协议中Email消息的基本格式：**

- 头部行（header）：To（发给谁）、From（由谁发送）、Subject（主题）。（这与SMTP命令的交互是有所不同的，两个东西别搞混了，一个是格式一个是行为过程）

- 消息体（body）：包含消息本身，只能是ASCII字符。

  <a href="https://sm.ms/image/Np7YnXER1K8cmFH" target="_blank"><img src="https://i.loli.net/2020/05/25/Np7YnXER1K8cmFH.png" width = 300px    ></a>

**SMTP协议中多媒体扩展Email消息的格式：**

在原格式的基础上在头部增加了额外的行来声明MIME的内容类型

```
From: alice@crepes.fr
To: bob@hambuger.edu
Subject: picture of yummy crepe.
MIME-Version: 1.0				 //MIME版本	
Content-Transfer-Encoding: base64//数据编码方法
Content-Type: image/jpeg		 //多媒体数据的类型，子类型以及参数声明

base64 encoded data..............//编码后的数据
.................................
..............base64 encoded data 
```



**邮件访问协议：**从服务器获取邮件，有以下几种协议：

- POP(Post Office Protocol):在客户端与服务器之间通过认证授权后进行下载。是一种脱机模型的电子邮件协议（允许用户将邮件下载到本机，但是在本机的任何操作都不会影响到服务器）。
- IMAP(Internet Mail Access Protocol): IMAP可以看作是在POP协议基础上的改进与增加功能，比如能够操纵服务器上的存储的消息（创建或更改文件夹或邮箱），支持连机和脱机（可以将客户端的操作反映给服务器）。
- HTTP：通过WEB页面来访问邮箱，上面两种协议也同样可以由WEB访问（就是可以图形化的代替）。

**POP协议：**POP协议对于获取邮件的过程共分为，认证阶段和事物阶段。

POP协议命令交互示意：

```
										//下面是认证阶段
S: +OK POP3 server ready				//代表连接建立成功
C: user bob								//客户端进行用户名输入
S: +OK									//代表服务器收到来自客户端输入的用户名
C: pass hungry							//客户端进行密码输入
S: +OK user successfully logged on		//代表客户端收到来自客户端输入的密码，并且通过验证
										//下面是事物阶段
C: list									//客户端进行罗列收到的邮件
S: 1 498								//服务器为客户端罗列收到的邮件编号与大小
S: 2 912
S: . 									//服务器对邮件罗列完毕
C: retr 1								//客户端按编号下载邮件内容，将服务器上的内容下载到客户端
S: <message 1 contents>					//服务器根据用户的要求邮件具体内容
S: .									//内容展示完毕后以“.”作为结束符
C: dele 1								//用户查看完毕后可销毁该邮件，销毁本地的邮件
C: retr 2s
S: <message 2 contents>
S: .
C: dele 2
C: quit									 //客户端处理完毕后可命令与服务器进行连接断开
S: +OK POP3 server signing off			 //服务器表示收到断开命令，即将断开连接
```

POP协议分为“下载并删除”和“下载并保持”两种模式。

“下载并删除”，用户下载完邮件后，服务器上的邮件删除，但这样不同客户端就不能够重复的读取一份邮件了。

“下载并保持”，下载完毕后，邮件服务器不删除，但这样会十分占用邮箱服务器。

POP3是一种**无状态协议**。

### 7、DNS（域名解析系统）：

已知，源主机要将信息发送到目的主机去起码要知道目的主机的IP地址，通过网络层服务寻找到到达目的的线路。

这就意味着我们使用WEB服务时，要知道每个WEB网站的IP地址，才可以进行主机间的通信，但我们通常访问网站并不会使用IP地址，因为IP地址显然难以记忆也难以阅读和分辨，这时候我们进行访问时往往时通过**域名**来实现的。DNS的作用就是将域名**映射**为IP地址，再让网络层通过该IP地址完成链路的选择并通过传输层与另一台主机建立连接。

 **域名解析系统**负责将域名翻译为IP地址。由于网络边界的复杂性，可能有几十亿台接入互联网的主机，域名解析系统要7*24小时的为这些域名翻译为IP地址。它是由多层命名服务器构成的**分布式数据库**，其本身也是一种应用层协议，是互联网的核心功能。除了翻译工作之外，DNS也可以提供，主机别名（将一个不好记的名字改为好记的名字）、负载均衡（很多服务提供商会有非常多的服务器（服务器农场），这些服务器可能提供的服务都是一样的，也就是说它们的域名相同，但是IP地址不同，DNS可以根据情况将来自不同客户端对同一域名的请求安排在不同的服务器上（将同一个域名翻译成不同的IP地址，确保任务能够平均分配到服务器上，而不是集中在某个服务器上））

因此DNS是互联网的核心功能，当我们在浏览器种输入域名时，在获得服务器提供真正的服务之前，我们都需要先通过域名服务器来获取该域名的IP地址，然后才能被服务。

**为什么不使用集中式的DNS：**

单点失败问题：一旦DNS的服务点损坏，那么整个互联网就会瘫痪。

流量问题：互联网上连接的主机数目是巨大的，几十亿台主机同时向一处请求DNS查询，流量是巨大的，要考虑网络链路的可靠性。

距离问题：距离DNS服务器较远位置的主机的传播延迟会很高。

维护性问题

**分布式层次数据库：**

DNS采用一种分布式（不仅仅在一个地区，而是分布在全世界）层次式（第一层为根DNS服务器，第二层为顶级域DNS服务器，第三层为顶级域下所创建的各级域统称为子域（也可以叫权威DNS服务器），各个组织或用户可以自由申请注册自己的域名）的数据库。

例，假如我们要查询www.amazon.com的IP地址，首先客户端查询根服务器，找到com域名解析服务器，然后客户端查询com域名解析服务器，找到amazon.com域名解析服务器，最后客户端查询amazon.com域名解析服务器，获得www.amazon.com的IP地址。

<a href="https://sm.ms/image/MEjXOVCpdBY1GDR" target="_blank"><img src="https://i.loli.net/2020/05/25/MEjXOVCpdBY1GDR.png" width = 600px    ></a>

- **DNS根域名服务器：**当**本地域名服务器**（每个ISP都有一个本地域名服务器）无法解析域名时，客户端会访问根域名服务器。根域名服务器会根据该域名对下层的DNS域名服务器进行逐层查询，知道找到该域名的映射为止。
- **TLD域名服务器：**顶级域名服务器，负责com、org、net、edu等顶级域名和国家级顶级域名，如cn、uk、fr等。
- **权威域名服务器：**组织的域名解析服务器，提供组织内部服务器的解析服务。由服务提供商自行维护。
- **本地域名解析服务器：**严格讲不属于层次体系，每个ISP（网络服务提供商）有一个本地域名服务器，它也是浏览器的默认域名解析服务器。每个主机进行DNS查询时，查询都被送到本地域名服务器中，本地域名服务器作为代理将查询转发给层次级域名解析服务器系统（当然本地域名器要有，就不必了）。本地域名服务器一般会缓存顶级域名服务器的映射（缓存：只要域名解析服务器获得域名到IP的映射，那么久缓存这一映射）。

**DNS查询示例：**<font color = "red">该部分简述了层次级域名解析服务器系统对与域名的解析过程</font>

- 迭代查询：被查询服务器返回域名解析服务器的名字，可以理解为“我不认识这个域名，但是你可以问这台服务器”。图片更好理解，如下图：

  <a href="https://sm.ms/image/VFp9v6NAfGogSyE" target="_blank"><img src="https://i.loli.net/2020/05/25/VFp9v6NAfGogSyE.png" width = 300px    ></a>

- 递归查询：将域名解析的任务交给所联系的服务器。

  如下图：

  <a href="https://sm.ms/image/HdmkU31LwFzuN48" target="_blank"><img src="https://i.loli.net/2020/05/25/HdmkU31LwFzuN48.png" width = 300px    ></a>



**DNS记录：**DNS记录实际上就是记录在数据库中的记录，格式也是数据库的格式。资源记录（RR,resource records），尽量简单的了解下数据库的查询方式吧，要不不好理解。

对于RR  format，其格式为（name，value，type，ttl）

- Type = A
  - Name：主机域名
  - Value：IP地址
- Type = NS
  - Name：域（edu.cn）
  - Value：改域权威域名解析服务器的主机域名
- Type = CNAME
  - Name：某一真实域名的别名。如www.ibm.com——servereast.backup2.ibm.com
  - Value：真实域名
- Type = MX
  - Value是与name相对应的邮件服务器

因此，由上可知，当我们想要注册假如公司为“Network Utopia”的域名。我们需要向域名管理机构提供我们的权威域名解析服务器的名字与IP地址，域名管理机构向com顶级域名解析服务器中插入两条记录：                                   (networkutopia.com,dns1.networkutopia.com,NS)和(dns1.networkutopia.com,212.212.212.1,A)并且在权威域名解析服务器中为www.networkuptopia.com加入Type为A的记录，并为networkuptopia.com加入Type为MX的记录。

**DNS协议格式：**DNS协议是一种**查询/回复**方式的协议，两种消息的格式相同。

<a href="https://sm.ms/image/uyXelbaw3dvKL9Q" target="_blank"><img src="https://i.loli.net/2020/05/25/uyXelbaw3dvKL9Q.png" width = 600px    ></a>

更加详细权威的回答请点击：https://jocent.me/2017/06/18/dns-protocol-principle.html#_label1

与https://www.cnblogs.com/davidwang456/articles/10660051.html👍

### 8、P2P应用：

**P2P结构：**P2P中，任意的端系统/节点之间可以直接通讯。P2P中没有永远在线的服务器，各个端系统也没有一直不变的IP地址。其有着<font color = "red">高度可伸缩性</font>，同时也<font color = "red">难于管理</font>。相对于C/S结构，其传输文件有着一定的优势（对于C/S结构，客户机不与客户机直接相连。客户机要先将文件上传到服务器上，另一客户机再从服务器上下载。P2P就是两台机器建立连接，直接传送文件，省去了再次下载的步骤）

<a href="https://sm.ms/image/OnyMVJ6j7c4AldH" target="_blank"><img src="https://i.loli.net/2020/05/24/OnyMVJ6j7c4AldH.png" width = 300px    ></a>

#### P2P中的文件分发：

在P2P的应用中，文件分发是一个典型的示例。

**文件分发中，P2P与C/S结构的比较：**

- C/S结构：假设客户端与服务器连接中的网络有着充足的带宽，一个文件的大小为F，服务器上传的带宽为us，节点i的上传带宽为ui，节点i的下载带宽为di。问从一个服务器向N个节点分发一个文件需要多长时间。

  分析：

  服务器串行发送N个副本

  - 时间：NF/us
  - 客户机i需要F/di时间下载
  - 传输完成共需要：max{NF/us，F/min（di）}

- P2P结构：和上面问题一样，对于P2P结构来说，只要任意一个节点持有某个文件，就可以对连接的主机直接进行分享。

  分析：

  服务器必须要发送一个原始副本

  - 时间：F/us
  - 客户机i需要F/di时间下载
  - 对于n个节点全部获取副本总共需要下载NF比特
  - 最快的可能上传速率：us+Σui，假设所有节点都开始上传
  - 传输完成共需要：max{F/us，F/min（di），NF/（us+Σui）}

- 下图我们可以看到当传输节点足够多时，P2P的优势非常明显。

  <a href="https://sm.ms/image/p3XICOf4cdRlKni" target="_blank"><img src="https://i.loli.net/2020/05/25/p3XICOf4cdRlKni.png" width = 400px    ></a>

#### BitTorrent协议:

BitTorrent本质上是分布式系统的P2P（点对点）传输文件协议，它和普通HTTP协议相比优势在于，同时下载一个文件的下载者在下载同时不断互相上传数据，使文件源可以在很有限的负载增加的情况下支持大量下载者同时下载。其特点就是“下载的人越多，速度越快 ”。对于BitTorrent来说，BitTorrent也存在着一个中央服务器（Tracker），其功能是当有节点加入该下载中时，它来协调各个节点之间的协作。Tracker服务器只是管理连接，对发布的文件内容并不关心，也不传输文件内容，因此Tracker可以用很少的带宽就可以支持大量的用户。

<a href="https://sm.ms/image/7wFEJbutsovVj1r" target="_blank"><img src="https://i.loli.net/2020/05/26/7wFEJbutsovVj1r.png" width = 600px    ></a>

**BitTorrent下载过程：**

我们以上图的Alice的主机为主角进行简述：

开始时，在某一主机的一个完整文件被划分为了几个chunk（将一个文件进行大小划分，假如划分为了A，B，C，D四个部分，其余节点若要下载该内容，可能会被随机分配到A，B，C，D中的某一块，当然这些主机要获得资源也不一定非要从这台主机上获取）。

其他节点想要下载该文件，加入该Torrent中，需要首先向tracker注册以获得节点清单（其中包含哪些节点持有文件的哪些块）。

随着节点加入的增加，在某一时刻加入该torrrent的节点持有该文件不同的chunk子集。

我们的主角Alice假如目前持有该文件的B,C两部分，她现在需要文件的A,D两部分，那么她应该查询tracker看看有哪些邻居节点目前持有A或D的部分（如果D在记录中更加稀缺，那么Alice会优先下载D部分）。假如Alice从tracker中获知了Bob的主机中含有D部分，那么Alice尝试能否与Bob建立连接，并下载Bob所持有的D部分。关于下载A部分的数据，步骤都是同样的。

当Alice下载chunk的同时也应该为其他节点提供chunk的上传，Alice会向向她请求下载的主机中优先选出4个上传速率最快的节点，为他们提供chunk，并且Alice会每过10秒重新评估这样的“top4”，每过30秒会随机选择一个其他节点，向其发送chunk。

Alice在下载完成后可以选择退出torrent或留在其中继续参与提供资源的一方。

**P2P的索引问题：**索引，信息到节点的位置，也就是网络应用进程通信中的寻址问题：IP地址+端口号；

节点获取目的节点的方式：

- 集中式索引：

  - P2P中，节点加入时，通知中央服务器自己的IP地址与所持有的内容。其余节点需要获知其它节点的信息时需要先查询中央处理器。
  - 集中式索引面临，单点失效、性能瓶颈以及版权等问题。

- 泛洪式节点：

  - 泛洪式查询中，每个节点只对它共享的文件进行索引。当X与Y之间有TCP连接，那么两个节点之间构成一个边（虚拟边，方便理解才这么说的），所有活动节点与边构成覆盖网络。查询消息通过已有的TCP连接发送，各个节点转发查询消息，直到查询命中时利用反向路径发回查询节点。

    <a href="https://sm.ms/image/wYSIuGaZKtxBsJW" target="_blank"><img src="https://i.loli.net/2020/05/26/wYSIuGaZKtxBsJW.png" width = 300px    ></a>

- 层次式覆盖网络：综合了集中式索引与泛洪式节点的方法，每个节点或者是一个超级节点，或者被分配一个超级节点。节点和超级节点之间维持TCP连接，某些超级节点之间维持TCP连接。超级节点负责跟踪子节点的内容。

  如Skype就采用层次式覆盖网络来进行索引

  <a href="https://sm.ms/image/f4OmL2oDWyUAIiT" target="_blank"><img src="https://i.loli.net/2020/05/26/f4OmL2oDWyUAIiT.png" width = 300px    ></a>

### 9、Socket编程：

**应用编程接口API：**其实就是应用进程的控制权和操作系统的控制权进行转接的一个系统调用接口。

<a href="https://sm.ms/image/YgBAGKR64LVSXln" target="_blank"><img src="https://i.loli.net/2020/05/26/YgBAGKR64LVSXln.png" width = 600px    ></a>

#### **Socket API：**

Socket API是Internet网络应用最典型的API接口，其服务C/S结构，解决跨主机应用进程间的通信，面向TCP/IP协议与大多数操作系统。

**利用Socket通信：**

首先服务器的应用进程要创建套接字，客户端的应用进程也要创建一个套接字。Socket为服务器与客户机提供如同“插座（服务器应用进程的套接字）与插头（客户机应用进程的套接字）”的服务来使得“插座”被动等待“插头”的主动插入，实现客户机与服务器的联系。

对于主机而言，主机上运行着各种不同的进程，每一个能够网络通信进程的进程都应该有一个套接字。因此客户端进程的套接字应该表明要连接的套接字所绑定的地址信息（IP地址+端口号），服务器进程上的套接字也应该绑定自己的地址信息（该主机上该进程的端口号）。

套接字对于**外部**通信将唯一的标识是通过IP地址+端口号。

套接字对于**内部**操作系统而言是使用套接字描述符（小整数）表示。当应用进程创建套接字时，操作系统分配一个数据结构存储该套接字的相关信息，并返回该套接字的描述符。操作系统会维护一个套接字描述符表，并且该表中的每个元素会有一个指针指向它代表的Socket数据结构。

<a href="https://sm.ms/image/n4GjMBquotUSeOp" target="_blank"><img src="https://i.loli.net/2020/05/26/n4GjMBquotUSeOp.png" width = 400px    ></a>

因此在Socket中最重要的是表名自己的地址信息和要联系的目的主机上的进程地址信息，而Socket API一般会为我们提供将这些信息写入其中的函数。

**面向TCP服务的Socket编程：**对于面向TCP编程，传输数据的特点是可靠、面向连接、通过字节流传输、点对点的。

<a href="https://sm.ms/image/7yH1kL9Fux8ZBqo" target="_blank"><img src="https://i.loli.net/2020/05/26/7yH1kL9Fux8ZBqo.png" width = 600px    ></a>

**Socket API函数：**这里我是用Java中socket的TCP编程作为示例：

下面是一个面向TCP通信的Socket的DEMO，该DEMO是一个最简单的例子，该服务器一次只能够处理一个请求，并且对客户端没有返回值。

服务器的Socket编程：

```java
package internet.socket;


import java.io.InputStream;
import java.net.ServerSocket;
import java.net.Socket;
 
public class SocketNormalServer {
  public static void main(String[] args) throws Exception {
    // 监听指定的端口
    int port = 55533;
    ServerSocket server = new ServerSocket(port);
    // server将一直等待连接的到来,在客户端连接请求到来之前，一直在这里阻塞
    System.out.println("server将一直等待连接的到来");
    Socket socket = server.accept();
    // 建立好连接后，从socket中获取输入流，并建立缓冲区进行读取，输入流获得完整的数据之前，线程会一直被阻塞
    InputStream inputStream = socket.getInputStream();
    byte[] bytes = new byte[1024];
    int len;
    StringBuilder sb = new StringBuilder();
    while ((len = inputStream.read(bytes)) != -1) {
      //注意指定编码格式，发送方和接收方一定要统一，建议使用UTF-8
      sb.append(new String(bytes, 0, len,"UTF-8"));
    }
    System.out.println("get message from client: " + sb);
    inputStream.close();
    socket.close();
    server.close();
  }
}
```

客户端的Socket编程：

```java
package internet.socket;

import java.io.OutputStream;
import java.net.Socket;
 
public class SocketNormalClient {
  public static void main(String args[]) throws Exception {
    // 要连接的服务端IP地址和端口
    String host = "127.0.0.1"; 
    int port = 55533;
    // 与服务端建立连接
    Socket socket = new Socket(host, port);
    // 建立连接后获得输出流
    OutputStream outputStream = socket.getOutputStream();
    String message="你好";
    socket.getOutputStream().write(message.getBytes("UTF-8"));
    outputStream.close();
    socket.close();
  }
}
```

PS：正常的套接字创作流程可以有很多种，比如先创建空的未绑定地址的new Socket(),然后使用connect函数与服务端进行通信。

如：

```java
Socket socket = new Socket();
SocketAddress endPoint = new InetSocketAddress("127.0.0.1",55533);
socket.connect(endPoint);
```



下面是一个服务器对客户端有返回值的DEMO，但是该DEMO同样只能同时处理一条连接请求，是单线程的

有返回值的服务器：

```java
package internet.socket;

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.ServerSocket;
import java.net.Socket;

public class SocketDoubleCommunicationServer {
	public static void main(String[] args) throws IOException {
		// 监听指定的端口
	    int port = 55533;
	    ServerSocket server = new ServerSocket(port);
	    
	    // server将一直等待连接的到来
	    System.out.println("server将一直等待连接的到来");
	    Socket socket = server.accept();
	    // 建立好连接后，从socket中获取输入流，并建立缓冲区进行读取
	    InputStream inputStream=socket.getInputStream();
	    byte[] bytes = new byte[1024];
	    int len;
	    StringBuilder sb = new StringBuilder();
	    while ((len = inputStream.read(bytes)) != -1) {
	        // 注意指定编码格式，发送方和接收方一定要统一，建议使用UTF-8
	        sb.append(new String(bytes, 0, len, "UTF-8"));
	      }
	    System.out.println("get message from client: " + sb);
	    OutputStream outputStream=socket.getOutputStream();
	    outputStream.write("Hello Client,I get the message.".getBytes("UTF-8"));
	    inputStream.close();
	    outputStream.close();
	    socket.close();
	    server.close();
	}
}

```

显示返回值的客户端：

```java
package internet.socket;

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.Socket;
import java.net.UnknownHostException;
import java.util.Date;

public class SocketDoubleCommunicationClient {
	public static void main(String[] args) throws UnknownHostException, IOException {
		// 要连接的服务端IP地址和端口
	    String host = "127.0.0.1";
	    int port = 55533;
	    // 与服务端建立连接
	    Socket socket=new Socket(host,port);
	    // 建立连接后获得输出流
	    OutputStream outputStream=socket.getOutputStream();
	    String message=new Date()+ ": hello world";
	    socket.getOutputStream().write(message.getBytes("UTF-8"));
	   //通过shutdownOutput高速服务器已经发送完数据，后续只能接受数据
	    socket.shutdownOutput();
	    //调用此函数，再socket的输入流获得完整的数据之前，线程会一直被阻塞
	    InputStream inputStream=socket.getInputStream();
	    byte[] bytes=new byte[1024];
	    int len;
	    StringBuilder sb = new StringBuilder();
	    while ((len = inputStream.read(bytes)) != -1) {
	        //注意指定编码格式，发送方和接收方一定要统一，建议使用UTF-8
	        sb.append(new String(bytes, 0, len,"UTF-8"));
	      }
	      System.out.println("get message from server: " + sb);
	      
	      inputStream.close();
	      outputStream.close();
	      socket.close();
	}
}

```



下面是服务器实现多线程连接的DEMO

能够同时处理多个请求的服务器

```java
package model.bio;

import java.io.IOException;
import java.io.InputStream;
import java.net.ServerSocket;
import java.net.Socket;

public class IOServer {
	public static void main(String[] args) throws Exception{
		ServerSocket serverSocket=new ServerSocket(3333);
		while(true) {		
			Socket socket=serverSocket.accept();
			//每当接收到一个连接，就建立一个新的线程来处理这个连接
			new Thread(
				()->{
					InputStream in = null;
					try {
						in = socket.getInputStream();
					} catch (IOException e1) {
						e1.printStackTrace();
					}
					int len;
					byte[] data=new byte[1024];
					try {
						while((len=in.read(data))!=-1) {
							System.out.println(new String(data, 0, len));
						}
					} catch (IOException e) {
						e.printStackTrace();
					}							
				}).start();						
		}
	}
}
```

客户端：

```java
package model.bio;

import java.io.IOException;
import java.io.InputStream;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.Date;
import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;


public class IOClient {
	public static void main(String[] args) {
			try {
				Socket socket=new Socket("127.0.0.1",3333);//模拟客户端
				while(true) {
					try {
						socket.getOutputStream().write((new Date()+": hello world").getBytes());
						Thread.sleep(1000);
					}catch(InterruptedException|IOException e) {
						e.printStackTrace();
					}
				}
			}catch(Exception e) {
				e.printStackTrace();
			}
	}
}

```

**面向UDP服务的Socket编程：** 对于面向UDP便曾，传输数据的特点是不可靠、无连接、同过数据报传输的。

UDPServer的demo：

```java
package internet.UDP.socket;

import java.io.IOException;
import java.net.DatagramPacket;
import java.net.DatagramSocket;
import java.net.InetAddress;

public class UDPServer {
	public static void main(String[] args) throws InterruptedException {
			try {
				UDPServer();
			} catch (IOException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
	}
	public static void UDPServer() throws IOException {
		//1.创建DatagramSocket，指定端口号
		DatagramSocket socket = new DatagramSocket(3349);
		DatagramPacket packet = null;
		byte[] data = null;
		int count = 0;
		System.out.println("***服务器端启动，等待发送数据***");
		while(true) {
			data = new byte[1024];
			packet = new DatagramPacket(data, data.length);
			socket.receive(packet);//此方法在接收到数据报之前会一直阻塞
			new Thread(new ServerThread(socket, packet)).start();
			count++;
            System.out.println("服务器端被连接过的次数：" + count);
            InetAddress address = packet.getAddress();
            System.out.println("当前客户端的IP为：" + address.getHostAddress());
		}
	}
}
class ServerThread implements Runnable{
	DatagramSocket socket = null;
    DatagramPacket packet = null;

    public ServerThread(DatagramSocket socket, DatagramPacket packet) {
        this.socket = socket;
        this.packet = packet;
    }
    @Override
	public void run() {
    	String info = null;
		InetAddress address = null;
		int port = 3349;
		byte[] data2 = null;
		DatagramPacket packet2 = null;
		try {
			info = new String(packet.getData(), 0, packet.getLength());
			 System.out.println("我是服务器，客户端说：" + info);
			 
			 address = packet.getAddress();
			 port = packet.getPort();
			 data2 = "我在响应你！".getBytes();
	         packet2 = new DatagramPacket(data2, data2.length, address, port);
	         socket.send(packet2);
	        }catch (IOException e) {
                e.printStackTrace();
            }
    }
}

```

UPDClient的demo：

```java
package internet.UDP.socket;

import java.io.IOException;
import java.net.DatagramPacket;
import java.net.DatagramSocket;
import java.net.InetAddress;

public class UDPClient {
	public static void main(String[] args) throws InterruptedException {
			try {
				UDPClient();
			} catch (IOException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
	}
	public static void UDPClient() throws IOException {
		//1、定义服务器的地址，端口号，数据
		InetAddress address = InetAddress.getByName("localhost");
		int port = 3349;
		byte[] data = "用户名：admin;密码：12345".getBytes();
		//2、创建DatagramPacket，包含将要发送的信息
		DatagramPacket packet = new DatagramPacket(data, data.length, address, port);
		//3、创建DatagramSocket，实现数据发送和接收
		DatagramSocket socket = new DatagramSocket();
		//4、向服务器端发送数据报
		socket.send(packet);
		
		//接收服务器响应数据
		byte[] data2 = new byte[1024];
		DatagramPacket packet2 = new DatagramPacket(data2, data2.length);
		socket.receive(packet2);
		String info = new String(data2, 0, packet2.getLength());
		System.out.println("我是客户端，服务器说：" + info);
        socket.close();
	}
}
```

想了解更多关于Java的Socket编程请链接：https://blog.csdn.net/huanyuminhao/article/details/81477278👍

## <a name="第三章">第三章：网络传输层</a>

### 1、传输层服务和协议：

传输层提供应用进程之间（端—端）的逻辑通信机制，**发送方**将应用层递交的消息分为一个或多个组，并向下传递给网络层，**接受方**将这些接收到的组重新组装成消息并上交给应用层。传输层为应用提供多种协议，如Internet上的TCP和Internet上的UDP。同时传输层服务协议是基于Internet IP协议之上的，网络层只负责对数据进行路由和转发，并不关心数据是否有误或丢失，因此对于数据的可靠性传输上也是传输层应该考虑的。

### 2、复用和解复用：

#### 多路复用/分用：

**为什么要进行多路复用/分用：**在传输层中，传输层的某一个协议往往对应应用层的多个协议或进程，这就要求传输层能够不混乱的将来自上层不同进程的消息进行分组、封装交给下一层进行处理。

接收端进行**多路分用**：传输层根据头部信息将收到的段（Segment）交给正确的Socket，即不同的进程。

发送端进行**多路复用**：传输层从多个Socket接受数据，并封装上头部信息，生成Segement，交给网络层。

<a href="https://sm.ms/image/qNInZYd2eiS81zg" target="_blank"><img src="https://i.loli.net/2020/05/28/qNInZYd2eiS81zg.png" width = 600px    ></a>

**分用的原理：**主机会在网络层接收到IP数据报（datagram），该IP数据报包括源主机的网络层为来自传输层的Segment附加的头部信息（源IP地址和目的IP地址）与来自传输层的Segment本身。网络层将该数据报进行去头并还原为Segment交给传输层。由于每个段携带源端口号和目的端口号，传输层协议能够提取其端口号信息并将Segment导入到响应的Socket（**以上都是针对UDP协议说明的**，TCP相比UDP会有更多的处理步骤）。

<a href="https://sm.ms/image/76kixveUA2yRfGP" target="_blank"><img src="https://i.loli.net/2020/05/28/76kixveUA2yRfGP.png" width = 300px    ></a>

**无连接分用：**UDP的Socket用二元组来表识（本机IP地址，服务进程端口号。对于如何分辨发送方的IP地址与进程端口，UDPSocket收到的数据报会包含发送方的IP地址与进程端口号，具体可以查看上面Socket的示例），主机在收到UDP段后，根据段中的目的端口号将UDP段导向绑定在该端口号的Socket，同时来自不同源IP地址或源端口号的数据包都会被导向同一个Socket。

UDP是根据UDP段来发送数据的，这与TCP基于连接后通过流传输是不同的，因此TCP每次接收到不同的IP地址与端口号的连接，都要利用多线程来建立一个与其连接的Socket，当然虽然UDP都公用一个Socket，但是UDP为了针对不同客户端进行相应的动作也同样的要利用多线程，只不过这次是对接收到的数据包来多线程处理。可以查看上面bio模型demo和UDP的demo来自己理解。

<a href="https://sm.ms/image/tHBKyXsa9YIVDLf" target="_blank"><img src="https://i.loli.net/2020/05/28/tHBKyXsa9YIVDLf.png" width = 600px    ></a>

**面向连接的分用：**TCP的Socket用四元组进行表示（源IP地址、源端口号、本机IP地址、本机端口号。这与UDP不是同的，UDP只会标明本机IP地址、本机端口号），接收端利用所有的四个值将Segement导向合适的Socket（通过辨别Socket上的四元组），服务器会为每个客户端开设一个专门的Socket针对此次连接，并通过连接的数据流来进行数据的传输。

<a href="https://sm.ms/image/MmUgFCWAwrHbNSZ" target="_blank"><img src="https://i.loli.net/2020/05/28/MmUgFCWAwrHbNSZ.png" width = 600px    ></a>

### 3、UDP（User Datagram Protocol）：

UDP（用户数据报协议）是一种基于Internet IP的协议，也一种无连接的传输层协议，并且UDP是通过报文进行传输的（对应用层发送的数据不进行分组，而是将一整个全部丢在网络层上，因此使用UDP的应用程序应谨慎的选择数据报的大小）。UDP发送时只需要将来自Socket的数据进行计算校验和与封装，并交给网络层处理，在接收时只需要对数据进行简单的校验并去掉源UDP封装的头部，交给应用层上对应的Socket。

- 能够保证传输层的复用/分用和一些简单的错误校验。
- UDP发送方和接受方之间不需要进行连接。
- 每个UDP段的处理独立于其他段。
- 不能够对来自上层的数据进行分组/重组。
- 无法得知发送的数据是否安全完整到达。
- 无法保证发送的数据能够按照发送顺序到达。
- 没有拥塞控制。
- 数据传输的可靠性要由应用层来提供。

UDP应用于容忍丢失但对速率敏感的应用（如流媒体等适合于一次传输少量数据的应用（即使某一信息丢失，但是在几秒后就会有一个新的信息替代它）），或可以保障可靠性的应用（如，DNS、TFTP、SNMP等）。UDP应用对于网络链路的要求也比较高，偶尔丢失一两个数据包几乎对这类应用不会有太大影响，但是丢失过多的数据包会非常影响应用的正常使用。

<a href="https://sm.ms/image/57fUuEyv4TPG8zk" target="_blank"><img src="https://i.loli.net/2020/05/28/57fUuEyv4TPG8zk.png" width = 400px    ></a>

如上图，为UDP段格式，其中length是代表整个段的长度（数据与UDP头部长度）

**UDP校验和：**UDP会采用一种简单的校验机制，对校验错误的数据包进行丢弃，对正确的进行传输给应用层。

对于**下图**，在原始UDP段会添加一个12字节（一字节=8bit）的UDP伪首部，其目的是让UDP二次校验数据是否已经正确到达目的地（IP接受地址是本主机的数据报），填充字节的目的是使UDP段加上UDP伪首部后的长度应该是16的整倍数。伪首部出现的16位UDP长度为原UDP段加上填充字节后的长度，第二个UDP长度为原UDP段的长度，两次计算UDP长度的目的是，检验完毕后将填充字节分离。

<a href="https://sm.ms/image/pYmUDtAufNFxHBQ" target="_blank"><img src="https://i.loli.net/2020/05/28/pYmUDtAufNFxHBQ.png" width = 500px    ></a>

- 发送方：

  - 先将UDP伪首部与UDP首部（除校验和位，校验和先用0代替）全部填充上正确的信息。
  - 将段的内容视为16-bit的整数（这里的段指代的是UDP伪首部加UDP首部加数据加填充字节，并不是严格意义上的UDP段，下面的段都这样代指）
  - 校验和的计算：计算所有这样的整数的和，如果出现进位（长度大于16），那么这样的进位就加在和的后面，将最终得到的值按位取反，并将取反的结果置入到UDP检验和中。

- 接收方：

  - 计算收到段的校验合（该段每16bit视为一个整数，全部计算），得出的结果（这次不取反）若为全1，那么该段正确，如果不全1，该段不正确，UDP进行丢弃。

- 示例：

  ```
      1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0
  +   1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1
  = 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1
  =   1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 + 1 //进位加到低位
  =   1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 	
  =   0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1  //取反
  ```

  我们可以自己弄一个示例来验证这一过程，比如我们将2bit视为一个整数

  ```
  1 1
  1 1
  0 0			//假设改行为初始校验位，全0代替
  1 0
  接下来我们使用上面的放来来计算这个校验位应该填入什么
  1 1
  +
  1 1
  =
  1 1 0  //多出来一位
  接下来进位加到低位
  1 0
  +
  1
  =
  1 1
  接下来继续相加
  1 1 
  +
  0 0
  =
  1 1
  继续相加
  1 1 
  +
  1 0
  =
  1 0 1 //多出来一位
  接下来进位加到低位
  0 1
  +
  0 1
  =
  1 0  //结果
  取反
  0 1
  此时应该为
  1 1
  1 1
  0 1  //该位是校验位			
  1 0
  重复以上步骤我们得到最终结果（1 1+1 1 = 1 1，1 1+0 1 = 0 1，0 1 + 1 0 = 1 1）：
  1 1
  因此校验成功，数据没有发生传输错误
  ```

### 4、可靠传输原理及协议：

我们希望可靠的数据是，不错、不丢、不乱的。由于信道的不可靠特性（传输的物理介质易被干扰，传输过程中会有丢失，过多的传输使得链路带宽被占满等等）使得传输层想要解决可靠的传输变得十分困难。由此我们来从简到烦的介绍可靠数据传输协议（rdt）。

<a href="https://sm.ms/image/fC57eWEtVcDSr8P" target="_blank"><img src="https://i.loli.net/2020/05/28/fC57eWEtVcDSr8P.png" width = 600px    ></a>

#### 渐进性的学习可靠数据传输协议：



下面我们会根据情况的复杂度，依次学习rdt中发送方与接收方是如何被设计的， 并且我们会利用状态机（FSM）来刻画传输协议。

##### Rdt 1.0：可靠信道上的可靠数据传输

Rdt1.0**假设**底层信道是完全可靠的（不会发生错误，不会丢失分组，不会乱序）。由于底层信道的可靠性，因此发送方和接收方不需要相互交换控制信息，所以发送方和接收方相互独立。

Rdt1.0的FSM如下图：

<a href="https://sm.ms/image/sT8YfebuvyGpPEW" target="_blank"><img src="https://i.loli.net/2020/05/28/sT8YfebuvyGpPEW.png" width = 600px    ></a>

对于发送方（sender）来说，发送方只有一个状态：等待上层的调用，当上层调用时，会产生调用rdt_send(data)这样的事件（其中的data表示上层要向Rdt交付的数据），紧接着Rdt收到数据后会采取创建分组的活动（make_pkt(data)）,然后调用信道上的udt_send(packet)，将分组发送出去（这里的udt_send并不是udt协议，就是这么起了个名而已），因为假设信道是可靠的，因此发送方也不需要再次确认发送的数据是否无误准确的到达了接收方。

对与接收方（receiver）来说，接收方只有一个状态：等待下层的调用，当下层调用时，会产生调用rdt_rcv（packet）这样的事件（其中packet是下层传递过来的一个分组），紧接着Rdt收到分组后会做一个提取动作（extract），将分组中的数据提取出来并交付（deliver_data）给上层。由于传输信道是可靠的，因此接收方也不需要验证接收到的数据是否有误。

<font color = "red">Rdt 1.0的缺陷：</font>底层信道是不可能完全可靠的，因此Rdt 1.0完全就不合实际。

##### Rdt 2.0：产生位错误的信道

Rdt2.0**假设**底层信道**只**会产生**位错误**（比如将某一bit位反转成1或0），它不会产生分组丢失，并且是按照顺序到达的。因此对于接收方，接收方需要得知它所收到的数据是否有位错误，并且当接收方得知有错误后，接收方需要通知发送方，它们需要共同的纠正这个错误。

1、我们需要考虑<font color = "red">如何辨别数据发生位错误</font>：

- 我们可以利用<font color = "red">校验和</font>检测位错误；（上面UDP有介绍）

2、当我们有了辨别位错误的手段，那么我们就需要考虑如何<font color = "red">从错误中恢复错误</font>:

​	对于发送方来说，发送方不可能主动知道自己发送的数据是否无误的到达接收方，因此这就需要接收方校验后	主动通知接收方

- 引入<font color = "red">确认机制(Acknowledgements,ACK)</font>:接收方需要再校验完成后显示的通知发送方分组已被正确接收；
- <font color = "red">NAK</font>:接收方需要再校验完成后显示的通知发送方分组在传输中发生错误；
- 当发送方受到NAK后，<font color = "red">重传</font>分组。对于基于这种重传机制的rdt协议也被称为ARQ（Atomatic Repeat reQuest）协议
- 当发送方受到ACK后，什么都不用做。

因此Rdt 2.0对于Rdt 1.0引入了，**差错检测、接收方反馈控制消息（ACK/NAK）、发送方重传**的机制。

<a href="https://sm.ms/image/Yma1Ql7CRiXoj9E" target="_blank"><img src="https://i.loli.net/2020/05/28/Yma1Ql7CRiXoj9E.png" width = 500px    ></a>

对于发送方，发送方含有**等待上层调用**和**等待ACK或NAK信号**两个状态，正因为等待信号的这个状态，Rdt2.0也被称为<font color = "red">停—等</font>协议。当发送方处于等待上层调用的状态时，上层若要调用它，会产生调用rdt_send(data)这样的事件，之后发送方会产生make_packet(data,checksum)这样的动作（较1.0增加了对分组增加校验合的动作），然后调用udt_send(sndpkt)将分组发送出去。当发送完毕后，发送方不知道分组是否无误的到达接收方，因此发送方进入等待信号（Wait for ACK for NAK）的状态，此状态中如果收到了来自接受方的消息（rdt_rcv(rcvpkt)）并且该消息是NAK(isNAK(rcvpkt))那么接收方需要重新发送刚刚已经发送的分组（udt_send(sndpkt)）,并再次进入等待信号状态，直到接收到来自接受方的消息并且该消息是ACK（isACK（rcvpkt）），发送方才再次进入等待上层调用的状态。

对于接收方，接受方仍然还是只有一个等待下层调用的状态，如果接收方收到了一个来自发送方的分组并且接收方进行校验判断发现该分组有错误（rdt_rcv(rcvpkt)&corrupt(rcvpkt)），那么接收方需要向发送方发送一个NAK同时丢弃掉错误的分组，如果该分组检验后没有错误，接收方对分组进行数据提取并交付给上层，最后向发送方发送一个ACK信息。

<font color = "red">Rdt 2.0的缺陷：</font>对于Rdt2.0我们引入了控制信号机制（ACK与NAK）。这种由接收方发送控制消息的机制本身就存在着问题，如ACK/NAK消息也可能发生错误，这样就可能会使得发送方受到被破坏的ACK/NAK后不知道接收方发生了什么，这样就发生了死锁。

**Rdt 2.1：对Rdt 2.0缺陷的改进**

考虑Rdt 2.0有着控制信息交换时会产生错误的弊端，我们应该加以改进，如果发送方收到了来自接收方错误的ACK/NAK，即使发送方不知道接收方表达的意思，那么发送方为了保险起见也会对刚刚发送但未确认的分组进行重传。但是如果接收方本意发送的是ACK呢？发送方就会产生发送**重复分组**的行为。那么如何解决重复分组的行为？发送方需要对每个发送的分组增加一个<font color = "red">序列号</font>，接收方丢弃收到具有重复序列号的分组。Rdt 2.1就是这么做的。

<a href="https://sm.ms/image/CU9uqQfkeR5Z8hI" target="_blank"><img src="https://i.loli.net/2020/05/28/CU9uqQfkeR5Z8hI.png" width = 400px    ></a>

<a href="https://sm.ms/image/O3GlUDdoP4RTZLB" target="_blank"><img src="https://i.loli.net/2020/05/28/O3GlUDdoP4RTZLB.png" width = 600px    ></a>

对于发送方，仍然还是遵循2.0的<font color = "red">停—等协议</font>,对于分组的序列号我们只划分为0和1两种序列号（两种序列号就足够标明自己发送的分组了），当发送方处于等待上层调用的状态，当上层调用时，发送方的Rdt 2.1会对数据进行分组同时添加校验合与分组序号0（make_pkt(0,data,checksum)），随后调用低层（udt_send（sndpkt））发送出去，此时进入等待信号状态，如果发送方收到来自接收方的控制信号，该信号是NAK或者是发送方识别不出来的信号，那么发送方会对刚刚发送的分组进行重发（make_pkt(0,data,checksum)，序列号仍然是0），直到收到了来自接收方正确的ACK（rdt_rcv(rcvpkt)&&notcorrupt(rcvpkt)&&isACK(rrcvpkt)）发送方才进入等待上层调用的状态（只不过这次再被调用会发送序列号为1的分组），之后的过程与上面一致，只不过是发送的分组序列号应该为1。

对于接收方：如果接收方收到了分组，并且该分组有错误，那么就向发送方发送NAK（make_pkt(NAK,chksum)）    	，如果收到了分组，并且该分组没有错误，但是并不是接收方所期望得到的分组（假设上一次收到的是0，并且0分组没有问题已经成功交付给了上层，那么这次应该期望的分组是1），那么接收方丢弃该分组并且向发送方发送ACK，如果接收方收到了分组，并且分组没问题且序号是接收方期望的那个，接收方进行数据提取并交付给上层，同时改变自己的状态，变为下次期望0分组的状态。

<font color = "red">Rdt 2.1的缺陷：</font>在Rdt 2.0 与 Rdt 2.1中我们有ACK和NAK确认消息，特别是Rdt 2.1中，这两种消息使得Rdt 2.1的状态翻了一倍，并且还要有针对不同情况的分支变化，这显然是有些复杂的。

##### Rdt 2.2：无NAK消息协议：

事实上，我们根本不需要接受方发送NAK来告知发送方重传。Rdt 2.2中只使用ACK就做到了与Rdt 2.1相同的功能。Rdt 2.2使接收方通过ACK（<font color = "red">在ACK消息中显示地假如被确认分组的序号</font>）向发送方告知最后一个被正确接收的分组。发送方再收到重复ACK或是收到不能识别的信号之后会重新发送刚刚发送的分组。

<a href="https://sm.ms/image/MUg3CYVenyKfsHw" target="_blank"><img src="https://i.loli.net/2020/05/28/MUg3CYVenyKfsHw.png" width = 500px    ></a>

上图中关于发送与接受序号为1的给省略掉了

发送方：和2.1有很多相同之处，开始时处在等待调用状态（如果被调用此时发送序号为0的分组），被调用后发送序号为0的分组，当收到的是带有0序号ACK，代表发送成功进入下一个等待调用状态（如果被调用此时发送序号为1的分组）。若收到的是是带有1序号的ACK，代表发送失败，接收方还停留在成功接受序号1分组的状态，发送重传。如果收到的信号无法识别，同样重传。

接收方：开始是在等待接受序号为0的分组状态（代表上次接受到的分组序号是1），如果收到的是校验有错误的分组，那么就向发送方发送带有序列号为1的ACK。如果收到序列号为1的分组，直接丢弃掉，并且向发送方发送带有序列号为1的ACK。直到接收到正确无误的序号为0的分组，再对分组进行提取数据交付给上层，并转换为等待序号为1的分组的状态。（该处简写了，与上面2.0，2.1的介绍过程冗余）

<font color = "red">Rdt 2.2的缺陷：</font>与Rdt 1.0同样，都是假定信道为良好的条件下假想设计的一种协议，不能够实际应用。

##### Rdt 3.0：应对分组丢失

对于Rdt前面的版本来说，我们仅仅假设信道只可能发生位错误，但实际情况中要复杂的多，例如分组可能会丢失，分组一旦丢失发送方或接收方只能一直处在盲等状态，造成系统的死锁。在Rdt 3.0中，我们假设信道既可能出现位错误也可能出现丢失分组的情况。在Rdt 3.0中我们增加了<font color = "red">定时器</font>的功能，来保证当发送方/接收方发送分组/ACK后，通过等待<font color = "red">合理</font>的时间来解决分组丢失的问题，当发送方/接收方超过该时间仍未收到信息，那么就对分组/ACK进行重传。

<a href="https://sm.ms/image/Ct7LlKRFW1Yy2nI" target="_blank"><img src="https://i.loli.net/2020/05/29/Ct7LlKRFW1Yy2nI.png" width = 500px    ></a>

发送方：在Rdt 2.2基础上添加了定时器，当发送方发送一个分组之后，会启动一个定时器（start_timer），并进入等待ACK状态。当定时器耗尽时间后，发送方会对刚刚发送的分组重传，并将该定时器重置。如果发送方收到了ACK，那么发送方将停止定时器，并进入等待上层调用的状态。

接收方：和Rdt 2.2是一模一样的。

**下图是Rdt 3.0的场景描述图：**

<a href="https://sm.ms/image/ByhEmVskDoIxKur" target="_blank"><img src="https://i.loli.net/2020/05/29/ByhEmVskDoIxKur.png" width = 600px    ></a>

<a href="https://sm.ms/image/P4gzdUFn83h2sxO" target="_blank"><img src="https://i.loli.net/2020/05/29/P4gzdUFn83h2sxO.png" width = 600px    ></a>

由上图四可知，这就是一种计时器设置过短的情况，如果图四的情况一直持续下去，会导致发送方总会发送重复的分组，但仍然能够正常的工作。

**Rdt 3.0的性能分析：**

假如，对于1Gbps的链路，15ms端到端的传播延时，发送方每次发送1KB（8Kb，1B = 8bit）分组。

发送一个分组到网络上的所要的时间为T = L/R = 8kb/10<sup>9</sup>b/s = 8μs

发送方利用率：U = （L/R）/ （RTT +（L/R）） = 0.008/ 15 + 15 + 0.008 = 0.00027

<a href="https://sm.ms/image/9Y6fhEm2W4TGlVJ" target="_blank"><img src="https://i.loli.net/2020/05/29/9Y6fhEm2W4TGlVJ.png" width = 600px    ></a>

可知在1Gbps的链路上每30毫秒才发送一个分组，才33KB/s，还不包括出错后的各种处理，这样的网络协议(主要由停等操作引起的)限制了物理资源的利用。因此在协议的选择上面，我们需要遵循计算机中的“软硬件匹配”原则。

<font color = "red">Rdt 3.0的缺点:</font>由停等协议引起的性能很差，不能够充分利用硬件资源。

#### 流水线机制与滑动窗口协议：

Rdt 3.0对资源利用率较低，其根本原因是其协议的<font color ="red">停—等</font>这样的操作。解决停—等造成的问题，其中一种解决的办法就是在发送方在等待的过程中可以发送其它的分组，通过这样的方式将停等协议打破。这样具体的实现就是下面要介绍的流水线机制与滑动窗口协议。

**流水线机制：**对于发送方，本应在每个RTT中只会发送一个分组，变为在每个RTT中发送多个分组。

<a href="https://sm.ms/image/Do2bwKCENkzQanm" target="_blank"><img src="https://i.loli.net/2020/05/29/Do2bwKCENkzQanm.png" width = 600px    ></a>

##### 流水线协议：

允许发送方在收到ACK之前连续发送多个分组，这就需要对接收方与发送方之间的交互变得更为复杂（如如何确认分组是否到达，分组到达的顺序如果乱序怎么办）。因此，我们需要<font color = "red">更大的序列范围</font>，发送方/接受方需要更大的存储空间来进行缓存分组。

下图为停等协议与流水线协议的对比：

<a href="https://sm.ms/image/WF32BIu5gSrcv7D" target="_blank"><img src="https://i.loli.net/2020/05/29/WF32BIu5gSrcv7D.png" width = 600px    ></a>

流水线协议中发送方不停的发送分组，同时接收方也在不同的发送确认ACK。

**滑动窗口协议(Sliding-window protocol)：**

为了实现上面的流水线协议，我们首先需要解决序列号与ACK确认机制的问题，因此我们需要先实现滑动窗口协议。目前具有代表性的话哦的那个窗口协议包括：GBN、SR。

对于滑动窗口协议，需要明确下面两个概念：

- 窗口：

  - 窗口代表允许使用的序列号范围（比如分组的头部共包含k个bit的序列号，那么允许使用的序列号范围为2<sup>k</sup>），窗口的尺寸代表最多能有多少个等待确认的消息；

- 滑动窗口：

  - 随着协议的运行，窗口在序列号空间中向前滑动；

  <a href="https://sm.ms/image/kN4pAKoUZ9xlP3q" target="_blank"><img src="https://i.loli.net/2020/05/29/kN4pAKoUZ9xlP3q.png" width = 500px height = auto   ></a>

  如上图，绿色部分代表已经发送并且确认完毕的分组，黄色部分代表已经发送但未确认的分组，蓝色部分代表还可以使用的序列号，白色部分代表还不能使用的序列号。当最黄色部分左端的分组被确认后，该窗口就可以向前（右）挪动，这时会占用一个白色部分的序列号供发送分组使用，当发送方发送一个分组后会占用蓝色部分（按照从左向右的顺序占用），当蓝色部分全部被用光时，就必须要等待黄色部分被确认后，窗口向右移动占用白色部分，将还不能使用的序列号变为可以使用的序列号后再进行发送。

##### GBN（Go-Back-N）协议：

**GBN发送方：**

GBN采用一种**累计确认**的机制，这代表当发送方接收到包含确认序号n的ACK时，前面发送确认到序号n（包含n）的分组均已被正确的接收。同时GBN协议也是根据rdt3.0改造的，因此对于分组的传输错误以及丢失，GBN中的发送方同样要像Rdt 3.0那样为发送出去的某一个（具体是哪个下面有说，我们现在只假设该分组的序号大于n）分组设置**一个**计时器（当某一个序号大于等于n的分组发生超时事件后，发送方重传序列号大于等于n，还未收到ACK的所有分组，这同时也会造成资源的浪费）。

<a href="https://sm.ms/image/HPUVL73GKk1E5ae" target="_blank"><img src="https://i.loli.net/2020/05/29/HPUVL73GKk1E5ae.png" width = 600px    ></a>

如上图为GBN中发送方的FSM

初始时，base = 1，nextseqnum = 1，这代表起始的序列号为1。当上层发生调用时（rdt_send），如果窗口的序列号还没有用光（if（nextseqnum<base + N））,我们就利用nextseqnum来制作一个分组（make_pkt(nextseqnum,data,chksum)）然后将这个分组发送出去，并且如果刚刚发送分组的序号等于窗口序号的边界值base，那么开启计时器，同时nextseqnum++，如果窗口的序列号用光了，那么发送方对上层的调用可以拒绝处理（refuse）。如果发送方发生了timeout事件，发送方重启计时器，并且要将刚刚发送过的分组（序列号大于等于base但小于nextseqnum的分组）全部重新发送一遍。如果发送方收到了ACK确认消息，这就代表发送方发送的小于该ACK携带序号的所有分组都已经被正确接收了，那么此时窗口向前滑动（base = getacknum（rcvpkt）+ 1），并且如果当发送的分组全部都被确认了(就意味着收到的ACK的序号等于nextseqnum - 1，base = nextseqnum)，停止计时，否则重启计时。

**GBN接收方：**

接收方发送ACK的机制为：接收方发送拥有最高序列号、已被正确接收的分组的ACK。如果接收方收到了乱序到达的分组（如，接收方目前确认了序号为20的分组，期待下一个序号为21的分组。本来到达顺序应该为21，22，23结果变为23，21，22），那么接收方会对乱序（不被期待的分组序号，比如23）的分组丢弃。由此可见，接收方需要知道自己期望下一个分组的序号。

<a href="https://sm.ms/image/bGoeKZB3lx5fyQm" target="_blank"><img src="https://i.loli.net/2020/05/29/bGoeKZB3lx5fyQm.png" width = 600px  ></a>

对于接收方来说，初始时接收方所期待的分组序列号为1。当接收方收到了一个分组，并且该分组的序号是接收方所期待的，那么接收方对该分组进行数据提取并交给上层，同时发送一个关于该分组序号的ACK，并对下个期望分组序号加1。如果接收方收到了并不是它所期待的分组（代表由于流水线的机制而导致的乱序到达），那么接收方直接丢弃该分组，并向发送方重新发送一个关于确认序列号最大的、按顺序到达分组的ACK（比如现在期待的是5，但是收到了7，那么应该再次发送序号为4的ACK）。

**GBN互动示例：**

<a href="https://sm.ms/image/7ouFKmQbEJ2pyjY" target="_blank"><img src="https://i.loli.net/2020/05/29/7ouFKmQbEJ2pyjY.png" width = 400px  ></a>

如上图，sender流水线连续发送序号为0，1，2，3的分组，此时sender为0号分组开了个计时器，但在途中2号分组丢失了，0和1成功送达了，接收方在接收到0分组和一分组后发送两个ACK代表确认。当发送方收到0分组的ACK后窗口向前移动一个，并且重启计时器为1计时，当收到分组1的ACK后窗口再次向又移动，重启计时器为2计时与此同时也不停的发送4和5的分组。由于到达接收方的2分组丢了，对于接收方来说之后到达的分组都是乱序的，因此也一直只会发送序号为1的ACK。一段时间后发送方迟迟不见序号为2的ACK，此时计时器耗尽时间，发送方将2到5的分组全部再重新发送一遍。

<font color = "red">GBN的缺陷：</font>由于GBN的累计确认机制，可能会导致网络上有大量的重复分组，浪费了硬件资源。

##### SR（Selective Repeat）协议：

对于SR协议，接收方再收到分组后，即使这些分组是乱序到达的，接收方也不会对收到的分组进行丢弃，而是设置缓存处理机制对乱序到达的分组进行缓存，并且对收到的每个分组都进行单独的确认。发送方只会重传那些没有收到ACK的分组。在SR协议之中，发送方仍然遵循窗口协议来限制已发送但未确认的分组，接收方也增加了滑动窗口机制。

<a href="https://sm.ms/image/CtiSEhDmgAl6FPw" target="_blank"><img src="https://i.loli.net/2020/05/29/CtiSEhDmgAl6FPw.png" width = 600px  ></a>

如上图，对于发送方的滑动窗口除了对每一个发送的分组都设置一个定时器，并且不会采用累计确认机制来重新发送所有的分组以外与GBN的基本一致。对于接收方，左边的白色部分代表已经接收完毕的分组，灰色部分指期望接收到的分组，粉色部分代表乱序到达的分组，蓝色部分代表可以接受序列号的范围，右边白色部分代表还不可以使用的序列号。对于发送方与接收方的窗口，两者并不同步，彼此不知道对方目前所处的状态。

对于发送方：

- 被上层调用时，如果在窗口中有可用的序列号，那么发送方发送序列号为n的分组，并对该分组进行计时。
- 如果分组n的计时器耗尽时间，那么发送方重新发送序列号为n的分组，并对计时器重置。
- 如果发送方收到了关于n分组的ACK，那么发送方对n分组进行标记并标明n分组已经被正确接收了。并且如果收到的ACK的序号n是这个窗口中序号最小的那个，标记完毕后窗口向前滑动一个位置。

对于接收方：

- 收到了一个分组m，并且如果m的大小在接收方的窗口之内（不管是否乱序），那么接收方发送确认序列号ACK（m）。如果该序号m是乱序到达的，接收方会利用缓存技术先将该分组缓冲器起来，如果是按照顺序到达的（对于接收方所期望收到的分组序号，以从小到大的顺序进行接收），接收方会将该顺序到达的分组与后面能够与该分组相连（比如期待收到1，2，3但先收到了2，随之收到了1，那么1，2共同交付给上层）的分组一起交付给上层，并且接收方窗口也向前滑动。
- 如果接收方收到的m并不在接收方的窗口范围之内，这代表传给发送方的确认ACK（m）丢失了，此时接收方仍应发送一个ACK（m）并且将该分组丢弃。

**SR协议示例：**

<a href="https://sm.ms/image/VYw5q8zCGKebZBh" target="_blank"><img src="https://i.loli.net/2020/05/29/VYw5q8zCGKebZBh.png" width = 600px  ></a>

**SR协议的困境：**

在SR协议中，如果发送方与接收方的窗口尺寸太大，而序列号的范围却太小，并且当有分组丢失时就会产生下面的问题。

<a href="https://sm.ms/image/NjGwKbvism3Y7t5" target="_blank"><img src="https://i.loli.net/2020/05/29/NjGwKbvism3Y7t5.png" width = 300px  ></a>

解决这种困境的方法就是要求，<font color = "red">发送方窗口大小+接收方窗口大小 <= 2<sup>k</sup></font>,其中k代表分组序号所占的bit长度。

### 5、TCP：

TCP是一种点对点（含有一个发送方，一个接收方），面向连接，通过字节流的传输的基于Internet IP协议之上的传输协议。

**其具有以下特点：**

- 点对点的通信机制：只含有一个发送方一个接收方
- 使用可靠的、按序的字节流传输机制（因为TCP是基于连接的特性，每次发送数据肯定都来源于同一个主机的，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些并加上自己的头部后构成自己的报文段再传送。如果应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去）
- 使用流水线机制，充分利用硬件资源，提高性能
- 因为流水线机制，发送方/接受方都有缓存，与SR协议类似
- 传输的数据流是**全双工**的（同一连接中能够传输双向数据流）
- TCP是面向连接的
  - 通信双方在发送数据之前必须先建立连接
  - 连接状态只在连接的两端中维护，在沿途节点并不维护状态
  - TCP连接时要维护的包括：两台主机上的缓存、连接状态变量、socket等
- 具有拥塞控制机制

**TCP段结构：**

<a href="https://sm.ms/image/T2XQYn51b8hRxul" target="_blank"><img src="https://i.loli.net/2020/05/29/T2XQYn51b8hRxul.png" width = 400px  ></a>

关于TCP段结构，我们需要知道以下几点：

- **Sequence number（序列号）：**TCP中分组的序列号，不是段的编号而是利用数据的字节数来计数。
  - 序列号是指segment中**数据部分的**第一个字节的编号与**首次连接确认的初始序号**之**合**，而不是segment的编号（比如，目前有1KB的数据，拆成了两个segement，第二个segment的序列号不是1也不是2（假如序列号是从0或1开始的，但其实初始序列号是在TCP连接时随机定的），而是500或501（根据字节编号），这是因为TCP所传输的数据的编号不是以报文段来进行编号的，而是将整个传输数据分成单个的字节流，并将每个字节流进行编号，一个TCP数据报中包括多个字节流的数据，而且每个TCP数据报中的数据大小并不一样。TCP每次传送的报文段中的序号字段值表示所要传送本报文中的第一个字节的序号）
  - 建立TCP连接时，双方随机选择序列号（原因是为了避免上次已断开的连接，还存在网络中延迟到达的TCP报文段的序号与当前连接中等待报文段的序号相同，以至于认为是这一次连接的包，发生错误，并且在连接完毕之后，双方会交换自己所选择序列号的信息）
- **acknowledgement number（ACKs）：**希望接收的下一个字节的序列号（至于为什么不是报文段序号而是字节序号，上面的序列号已经提及了）。累计确认机制，该确认字节号前的数据均一正确接收。
  - 在TCP中，接收方对乱序到达的Segment如何处理是没有该规定的，这得由TCP的实现者做出决定。
- 对于UAPRSF这几个选项：
  - U代表urgent（紧急），紧急数据，一般不会使用，有效就为1
  - A是一个标志为，来指定确认号字段是否有效，有效就为1
  - P代表push，指示接收方应该尽快将这个报文段交给应用层而不用等待缓冲区装满。
  - RST为1表示出现严重差错。可能需要重新创建TCP连接。还可以用于拒绝非法的报文段和拒绝连接请求。
  - SYN为1表示这是连接请求或是连接接受请求，用于创建连接和使顺序号同步。
  - FIN为1表示发送方没有数据要传输了，要求释放连接。
- Receive window：接收窗口的大小，代表的是所愿意接受的字节的数目，因此可以用来进行流量控制。
- checksum：校验合。

##### TCP中的发送与确认机制：

TCP所传输的数据包的序列号不是以报文段来进行编号的，而是将整个传输数据分成单个的字节流，并将每个字节流进行编号。一个TCP数据包中包括多个字节流的数据，而且每个TCP数据报中的数据大小并不一样。在建立TCP连接的三次握手过程中，通信双方各自已随机确定了初始的序号x和y,TCP每次传送的报文段中的序号字段值表示所要传送本报文中的第一个字节的序号。
TCP的确认是对接收到的数据的最高序号的确认，并向发送端返回一个下次期望收到的第一个数据字节的序号。例如，主机A发送的当前数据序号是400，数据长度是100,则接收端收到后会返回一个确认号是501的确认号给主机A。
TCP提供的确认机制，可以在通信过程中可以不对每一个TCP数据包发出单独的确认包，而是在传送数据时，顺便把确认信息传出，这样可以大大提高网络的利用率和传输效率。同时，TCP的确认机制，也可以一次确认多个数据报，例如，接收方收到了201，301，401的数据报，则只需要对401的数据包进行确认即可，对401的数据包的确认也意味着401之前的所有数据包都已经确认，这样也可以提高系统的效率。
若发送方在规定时间内没有收到接收方的确认信息，就要将未被确认的数据包重新发送。接收方如果收到一个有差错的报文，则丢弃此报文，并不向发送方发送确认信息。因此，TCP报文的重传机制是由设置的超时定时器来决定的，在定时的时间内没有收到确认信息，则进行重传。这个定时的时间值的设定比较重要，太大会使包重传的延时比较大，太小则可能没有来得及收到对方的确认包发送方就再次重传，会使网络陷入无休止的重传过程中。
接收方如果收到了重复的报文，将会丢弃重复的报文，但是必须发回确认信息，否则对方会再次发送。
那么，如果接受方接到的数据是非按序排列的该怎么办呢，那就要看接受方的TCP协议实现者自己去决定：是丢弃还是存储再排序。



**例子：**

<a href="https://sm.ms/image/T3BpLxaHFq6jMIE" target="_blank"><img src="https://i.loli.net/2020/05/29/T3BpLxaHFq6jMIE.png" width = 300px  ></a>

如上图，我们有两台主机，我们希望能够运行一个telnet（远程登陆，主机A按下一个字符发送给主机B后，主机B会回传一个相同的字符）的应用。

当主机A输入一个字符C的时候，发送给主机B的段序号为42，期望收到的下一个字节的序列号为79（这两个数字为建立TCP连接时，双方随机选择序列号，在这里将连接部分给省略掉了）

主机B在收到主机A的报文段后进行回传，返回一个报文段，其报文段序号为79，ACK为43（这是因为‘C’字符只占一个字节，所以ACK为42+1，表示接收方下一次期望收到的字节初始号为43，并且与此同时字节号为43之前的字节已经全部验收成功）

主机A再接收到主机B发送的消息后，再返回一个确认消息序列号为43，ACK为80。

#### TCP的可靠数据传输：

**TCP可靠数据传输概述：**

- TCP是在IP层提供的不可靠服务基础上实现可靠数据传输服务；
- TCP采用流水线机制；在SR和GBN中都有所提及，在SR与GBN中为流水线机制设定的窗口，TCP也有“窗口”，但不同的是TCP的窗口序号是由字节编号来计算的，而且其窗口的实现就是利用了字节缓冲区技术。
- TCP采用累计确认机制；这与GBN很相似
- TCP使用单一重传定时器；
- 对TCP来说会触发其重传的事件为，计时器超时或收到重复ACK
- 对流量和拥塞会有一定的控制

 **RTT与超时：**TCP使用超时重传机制，正如Rdt 3.0一样，计时器的时间设置是必须合理的，如果计时器设置的时间过大，那么就会对段丢失时间反应慢，如果计时器设置的时间过短，那么就会造成不必要的重传。那么如何合理的设置定时器的时间？我们可以利用RTT作为参考指标，但在网络中RTT是会变化的，因此在TCP中发送方需要对RTT进行边测量边对历史测量过的RTT求一个平均值作为一个参考参数EstimatedRTT，然后根据实时的传播记录刚刚测量的SimpleRTT，最终通过指数加权移动平均的方法得到最终估计值：<font color = red>EstimatedRTT = (1 - α)\*EstimatedRTT + α\*SampleRTT(α是一个参数，典型值：0.125)</font>，最终我们对计时器的设置的时间应该为<font color = "red">EstimatedRTT + “网络边界值”</font>，当RTT变化较大时，代表网络不稳定，网络边界值就需要设置的大一些，相反的如果网络稳定，那么就可以将网络边界值小一些。那么如何计算网络边界值呢？我们仍然要用指数加权移动平均的方法来计算SampleRTT与EstimatedRTT的差值：<font color = "red">DevRTT = (1 - β)\*DevRTT + β\*|SampleRTT - EstimatedRTT|（β典型值为0.25），“网络边界值 = 4\*DevRTT”</font>。因此，最终我们得出结论：<font color = "red">TimeoutInterval = EstimatedRTT + 4\*DevRTT</font>。

**TCP发送方事件：**TCP在从应用层收到数据之后创建Segment（序列号是Segment第一个字节的编号），如果计时器现在没有计时，TCP开启计时器（TimeOutInterval）。如果Segment发生了超时现象，TCP会重传引起超时的Segment并重启定时器。当TCP发送方收到了ACK后，如果确认的是此前没有确认的Segment那么就执行滑动窗口，如果窗口中还有未被确认的分组，那么就重启一个定时器。

以下是TCP发送端程序的伪代码：

```
NextSeqNum = InitialSeqNum  //初始化NextSeqNum与SendBase

loop(true){
  switch(event)				//根据情况来做相应的动作
  
  event：data received from application above  //如果是上层调用让TCP发送数据
  		create TCP segment with sequence number NexteqNum // TCP将数据分组并加TCP头变为段
  		if(timer currently not running)			//如果计时器现在没有计时，那么就进行计时
  			start timer
  		pass segment to IP			//将段发送给下层的IP协议
  		NextSeqNum = NextSeqNum+length（data）  //更新NextSeqNum
  
  event：timer timeout		//计时器超时，没有收到ACK
  		retransmit not-yet-acknowledged segment with //重传还没有被确认的最小序列号的Segement
  			smallest sequence number  
  		start timer   //重启计时器
  		
  event：ACK received，with ACK field value of y		//收到了对序号为y的段的确认
  		if（y > SendBase）{				//如果y大于SendBase，那么移动窗口（根据累计确认机制，
  			SendBase = y				 //收到的确认ACK代表之前的所有分组全部正确传输完成）
  			if(there are currently not-yet-acknowledged segments)
  				start timers
  		}else{								//快速重传机制，下面会介绍
  			increment count of dup ACKs received for y //累计计算该ACK重复的收到了多少次
  			if(count of dup ACKs received for y = 3) //如果收到了3次
  			{
  				resend segment with sequence number y  //立刻重传
  			}
  		}
}
```

**TCP接收方事件：**

| 接收方遭遇的事件                                             | 接收方对事件做出的反应                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| Segment是按序到达的，并且是被接收方所期待的。同时所有之前的按照顺序到达的Segment都已经被ACK了。 | 延迟发送ACK。等待一段时间（如500mas），看看还有没有下一个按序到达的Segment。如果没有那么就发送ACK。 |
| Segment是按序到达的，并且是被接收方所期待的。同时有之前到达的另一个Segment正在等待被ACK。 | 立刻发送一个累计确认的ACK（确认序号为按序到达段的最大序号+其字节长度，标明接收方期待的下一个字节序号） |
| Segment不是按顺序到达的，序列号大于接收方所期待的序列号。    | 立刻重复发送刚刚发送的ACK                                    |
| 不是按序到达的Segment部分或者全部的填充了接收方窗口的空白    | 立刻发送累计确认的ACK                                        |

下图是TCP重传的示例：

<a href="https://sm.ms/image/shSKNWqvC3aeHbj" target="_blank"><img src="https://i.loli.net/2020/05/30/shSKNWqvC3aeHbj.png" width = 600px  ></a>

<a href="https://sm.ms/image/juAQRq16zGsHhew" target="_blank"><img src="https://i.loli.net/2020/05/30/juAQRq16zGsHhew.png" width = 400px  ></a>

**TCP的快速重传机制：**TCP使用超时重传机制，这就会使某个段在超时后，发送方对其重新发送并重置计时器（这就意味着将超时时间间隔加倍，在重发丢失的分组之前要等待很长的时间）。为了解决这个问题，TCP引入了快速重传机制，即通过重复ACK检测分组是否丢失，由于发送方会“背靠背”的发送多个分组，如果某个分组丢失了，那么就可能会引起多个重复的ACK，如果发送方收到3个重复的ACK，就假定该数据之后的段已经丢失了，就会在定时器超时之前将该段重复发送出去。

**TCP流量控制：**

TCP流量控制本质上是一种速度匹配机制，接收方会为TCP连接分配缓冲区，如果上层接收数据的速度过慢，而TCP接收方接收数据过快，就会使得接收的数据累计过多而淹没缓冲区（buffer溢出）。

解决的办法是，接收方通过在Segment的头部字段（RcvWindow）将自己还能够接收多少个字节告诉发送方，发送方会根据这个数值，限制自己已经发送的但还未收到的ACK的数据，不让它们超过接收方的空闲缓存。当接收方的RecWindow = 0时，发送方也应该发送极小的报文，来实时确认接收方的RcvWindow来避免死锁。

#### TCP的连接管理（连接）：

TCP是一种面向连接的传输协议，TCP在传输数据之前要进行连接的建立，在传输数据结束之后要进行连接的拆除。

在C/S结构中，连接的发起者一般都是客户端`Socket socket=new Socket("hostname","port number") `   		而服务器一般都会等待客户连接的请求`Socket connectionSocket = welcomeSocket.accept()` 双方在开始连接时进行初始化TCP变量（如，SeqNum、Buffer和流量控制信息）。

**TCP连接的三个阶段（三次握手）：**TCP在连接过程中分为三个阶段

- 第一阶段：客户主机向服务器发送SYN报文段
  - SYN报文段不携带任何数据的，SYN标志位要置1，同时要传递客户机所选择的初始序列号（SeqNum是根据一些机制，比如Hash等算法来随机选择的）
- 第二阶段：服务器收到SYN报文段，如果同意建立连接会答复一个SYNACK报文段
  - 该报文段的SYN标志位要置1
  - 服务器会为该连接分配一定的资源
  - 服务器会选择自己初始的序列号并通过SYNACK告知客户端自己接收这个连接请求
- 第三阶段：客户机收到了来自服务器的SYNACK报文段后，会答复一个ACK报文段。
  - 该报文段中的SYN不再置1了、
  - 该报文段是可以包含数据的

**为什么要进行三次握手？为什么不是两次？**

第三次握手的目的是：“为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。”，比如在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放（此时客户端的连接请求关闭了）以后的某个时间才到达server。本来这是一个早已失效的报文段。当server收到此失效的连接请求报文段后，就误认为是client发出的一个连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送ack包，同时Server向Client发送的任何报文也都会被丢弃。（除此之外，一旦服务器的第二握手的报文传丢了，这样服务器会认为连接建立完成了，而客户端会认为建立没完成，也同样会发生上面那种浪费服务器资源的现象）因此TCP的服务端需要第三次握手来确认客户端也知道自己同意进行连接并做好发送/接收数据的准备下才会正式建立连接（三次握手中的第二次握手服务器会分配资源一段时间，但并不会长时间分配，当服务器认为不会再收到ACK确认了，会释放掉资源）。

下图是TCP连接的过程：

<a href="https://sm.ms/image/Xr5Wp9BndRi7ISM" target="_blank"><img src="https://i.loli.net/2020/05/30/Xr5Wp9BndRi7ISM.png" width = 400px ></a>

#### TCP连接管理（关闭）：

在TCP连接中，双方都可以提出关闭连接的请求，C/S结构中，多数都为客户端主动发起关闭请求`clientSocket.close()`。

**TCP关闭连接的四个阶段（四次挥手）：**

- 第一阶段：client向server发送FIN（和SYN一样都是特定标志位）控制报文段
- 第二阶段：server收到client发送的FIN控制报文段，会回复ACK。关闭连接，发送FIN
- 第三阶段：client收到FIN，回复ACK。
  - client此时进入等待状态，如果在这个过程中client重复收到了FIN报文段，那么就重新发送ACK（代表client发送的ACK传丢了）
- 第四阶段：server收到ACK，连接真正关闭

<a href="https://sm.ms/image/ov9WhBlSdDzmUi2" target="_blank"><img src="https://i.loli.net/2020/05/30/ov9WhBlSdDzmUi2.png" width = 300px  ></a>

**下图表示TCP中客户端与服务端的生命周期：**

<a href="https://sm.ms/image/OrqG9UXiQeSzj1N" target="_blank"><img src="https://i.loli.net/2020/05/30/OrqG9UXiQeSzj1N.png" width = 400px ></a>

开始时TCP客户端处于关闭状态，上层应用需要发起一个TCP连接时，TCP会尝试建立连接并发送SYN报文段，此时客户端会进入SYN已发送的状态并等待SYNACK，当收到SYNACK之后会发送ACK并进入已经建立连接的状态，此状态下可以进行发送数据，当上层应用使用完毕并表示自己想要关闭这个连接，客户端会发送FIN报文段并进入FIN_WAIT_1状态，此时如果收到ACK会进入FIN_WAIT_2状态，并等待服务器发来的FIN报文段，当收到了FIN报文段后进入等待状态（TIME_WAIT）等待30秒，在这个过程中如果再次收到了FIN，那么就重复发送ACK，否则这个连接就关闭了。

<a href="https://sm.ms/image/jpBbZkngU9eJuN8" target="_blank"><img src="https://i.loli.net/2020/05/30/jpBbZkngU9eJuN8.png" width = 400px  ></a>

开始时TCP服务端处于关闭状态，上层应用建立一个ServerSocket并通过ServerSocket.accept()进入监听状态，当收到了一个SYN请求报文段后服务端会发送一个SYNACK报文段并进入等待客户端确认的的状态（SYN_RCVD），当收到客户端发来的ACK会进入连接状态，此时可以发送数据或接收数据，直到收到了FIN控制报文段后会发送一个ACK进行确认并进入等待关闭状态，在转换为该状态后发送一个FIN控制报文段进入等待最后的ACK的状态（LAST_ACK），如果没等到ACK服务端会继续重新发送FIN，如果收到了ACK就会进入关闭状态。

#### 拥塞控制原理：

在网络当中也会出现现实生活中的“堵车”现象，其原因为：“太多发送的主机发送了太多数据或者发送速度太快，以至网络无法处理”。

##### 拥塞的主要表现为分组的丢失和分组的延迟：

- **分组的丢失：**当发送方发送的分组过快，这些分组再到达某一个路由器上时，路由器因链路带宽被占满而导致到达的各个分组不能够及时的发送并只好存放在路由器的缓存中去，当所有分组的大小都超出路由器的缓存容量后，后到达的分组只好被丢弃。
- **分组的延迟：**同样是由于路由要发送的分组太多了，带宽越占越满，发送速度越来越慢，发送过来的分组只好排队等待输出链路可用，等待的时间按拥塞程度来定。如果对拥塞不加以控制，那么网络只会越来越慢，最终瘫痪。

TCP不仅仅要解决端到端的可靠数据传输（比如分组丢失再重传），也同样要解决整个网络拥塞的问题（各个用户做出一定的牺牲，等待拥塞程度不那么高了再进行大量的数据传输）。

**拥塞的成因与代价：**

**场景1：**分组的延迟

我们假定有两个发送方A、B和两个接收方C、D，它们共用一条输入链路（带宽无限大），一条输出链路（带宽为C），一个路由器（假设路由器的缓存是无限的）

<a href="https://sm.ms/image/YWbeTuzX87KLdOf" target="_blank"><img src="https://i.loli.net/2020/05/30/YWbeTuzX87KLdOf.png" width = 500px  ></a>

当主机A,B共同发送数据时并且发送的速率（λin）小于C/2时，目的主机收到的速率（λout）会与发送的速率几乎相同，此时路由器几乎是收到分组就立刻转发出去，因此从发送到接收几乎也没有多少时延。但是当A,B发送的速率逐渐增大并且突破C/2时，路由器由于输出链路带宽限制的原因只能将不能够及时发送的分组缓存起来，越缓存越多，以至于后来输入到路由器中的分组要一直排队等待，延迟最终接近无限大。

<a href="https://sm.ms/image/B5aOMfznUTHdmjq" target="_blank"><img src="https://i.loli.net/2020/05/30/B5aOMfznUTHdmjq.png" width = 500px  ></a>

**场景2：**分组的丢失

与上面同样的场景，但这次路由器的缓存是有限的，输出链路的带宽为R，由于路由器缓存有限，必然会丢失分组，那么我们将λ<sub>in</sub><sup>，</sup>设为原始要发送的数据加上要重传的数据。

<a href="https://sm.ms/image/2zXHcBPqkUao1KT" target="_blank"><img src="https://i.loli.net/2020/05/30/2zXHcBPqkUao1KT.png" width = 500px  ></a>

<a href="https://sm.ms/image/mo6pyAKWr5GYdeC" target="_blank"><img src="https://i.loli.net/2020/05/30/mo6pyAKWr5GYdeC.png" width = 500px ></a>

- 情况a：Sender能够通过某种机制获知路由器buffer信息，**有空闲才发**；这种情况下，显然sender不会因发送的速度过快而产生分组丢失，因此λ<sub>in</sub><sup>，</sup> = λ<sub>in</sub>，并且在λ<sub>in</sub><sup>，</sup><R/2时，λ<sub>in</sub><sup>，</sup> = λ<sub>out</sub>，同样的λ<sub>in</sub><sup>，</sup>也不可能超过R/2。
- 情况b：发送方不能够获知路由器缓存区的情况，发送方在确定分组丢失后才会进行重发，此时λ<sub>in</sub><sup>，</sup>>λ<sub>out</sub>；并且λ<sub>out</sub>由于丢失分组的原因，接收的速率会小于R/2。

由以上可知，由于TCP的重传机制加上不控制输入速率使得我们不能够充分的利用输出链路带宽，造成了硬件资源的浪费（情况a虽然受到了输出链路的限制，但起码充分的利用带宽，情况b则非常糟糕）。况且由于在情况a，b中我们没有加上TCP的定时器机制，只是根据确认最终确认来判断是否重传，因此实际情况重传的分组会比b多更多，更加糟糕。

**场景三：**多跳与更多发送方造成的网络崩溃

由场景二可知，虽然我们没能充分的利用带宽，但起码不会造成网络的崩溃。那么在下面更加真实的场景中，我们会深刻的领悟到拥塞是如何造成网络崩溃的。

如图，我们加入了四个发送方，并且分组的传输是在多个路由器上跳转的，同时发送方对分组使用超时/重传机制。

<a href="https://sm.ms/image/mpznI9MDFLfal41" target="_blank"><img src="https://i.loli.net/2020/05/30/mpznI9MDFLfal41.png" width = 500px  ></a>

主机A向主机C发送数据（红线）与主机D向主机B发送数据（绿线）共同抢占路由器R2的资源，对于主机A向C发送的过程来说，主机A的某个分组成功到达R2之前要先经过上一个路由（多跳），该分组可能在成功到达上一个路由之前可能经历过丢失，那么假设该分组在到达R2的时候丢失了，那么主机A又要重新发送该分组，这样的过程可能会反反复复，直到整个网络全部瘫痪。

因此在多跳的网络条件下，**阻塞的另一个代价**就产生了：当分组被丢弃时，任何用于该分组的“上游”传输能力全部都被浪费掉。

**拥塞控制的方法：**需要有某种方式能够控制发送方发送数据的速率

- 端到端的拥塞控制
  - 网络层（这里指的是路由器，路由器最高只支持到网络层）不需要显式的提供支持。
  - 端系统通过观察分组的丢失与延迟的现象来判断网络是否发生拥塞，如果端系统认为发生拥塞，那么就会限制自己的发送速率。
  - TCP采取的就是这种方法。
- 网络辅助的拥塞控制
  - 网络层提供支持，路由器会向发送方显式地反馈网络的拥塞信息。端系统根据该信息来调整自己的发送速率。

##### TCP拥塞控制的基本原理：

- 我们如何改变TCP发送方的发送速率：在这里我们引入了一个变量CongWin（拥塞控制窗口），发送方要保证LastByteSent - LastByteAcked <= CongWin(最后发送的字节号减去最后确认的字节号小于拥塞控制窗口大小)，基于这样的原理我们可以通过根据拥塞程度来改变CongWin的大小来达到限制发送方发送速率（速率：rate ≈ CongWin/RTT （Bytes/sec））的目的。

- 我们怎么样来判断网络拥塞：当发送方发送的分组出现超时或收到3个重复的ACK后，发送方会认为网络拥塞了。

- 我们应该如何合理的调整发送速率：

  - 使用加性增——乘性减：AIMD机制

    - 原理：发送方采取一种谨慎的态度，发送方**逐渐**增加发送速率，谨慎探测可用带宽，直至发生拥塞现象（加性增），一旦发生了拥塞现象，发送方**快速**将发送速率降下来（乘性减）。

    - 方法AIMD

      - Additive Increase：每个RTT都将CongWin增大一个MSS（最大报文段长度）来避免拥塞；
      - Multiplicative Decrease：发生拥塞现象后将CongWin减半来快速的降低速度；

      <a href="https://sm.ms/image/NoKu5QRTnGytwIf" target="_blank"><img src="https://i.loli.net/2020/05/30/NoKu5QRTnGytwIf.png" width = 500px  ></a>

  - 使用慢启动：SS机制

    - 原理：当TCP连接开始时，初始速率很慢，但随之呈指数型增长，快速提高发送速度。

    - 方法SS

      - 每个RTT将CongWin翻倍，CongWin指数增长
      - 收到每个ACK都进行翻倍操作
      - 初始速率很慢，但是快速会急剧攀升

      <a href="https://sm.ms/image/2gExTA7tPDJejsI" target="_blank"><img src="https://i.loli.net/2020/05/30/2gExTA7tPDJejsI.png" width = 300px  ></a>

    - 为了避免拥塞，设定变量Threshold（阈值，大小为发生Loss事件前CongWin的1/2），当指数增长达到Threshold的时候，它再自动转变为线性增长。如果发送端的分组发生了Timeout事件时，CongWin直接降为初始值并且直到达到新Threshold前都进行指数增长，如果发送端收到了3个重复的ACK时，CongWin直接变为一半（与新Threshold相同）并且进行线性增长。（因为3个重复ACKs表示网络链路中还能够再传输一些segment，而timeout事件表示拥塞更为严重）
    
      <a href="https://sm.ms/image/JqtugjSTvpdYBLf" target="_blank"><img src="https://i.loli.net/2020/05/30/JqtugjSTvpdYBLf.png" width = 500px  ></a>
    
    - SS机制算法：
    
      ```
      Th = ? //为Threshold设定初始值
      CongWin = 1 MSS //CongWin设定的初始值为1
      while（buffer of sender is not empty）{ //只要Sender还想传输数据就一直进行
      	while(No Packet Loss and CongWin<Th){	//没有达到Threshold，ConWin指数增长
      		send CongWin TCP segments
      		for each ACK increase CongWin by 1
      	}
      	While(No PacketLoss){					//达到Threshold进行线性增长	
      		send CongWin TCP segments
      		for CongWin ACKS,increase CongWin by 1
      	}
      	Th = CongWin/2							//发生了Loss事件
      	if(3 Dup ACKs){							//如果该Loss事件是重复收到ACK来的知的
      		CongWin = Th	
      	}else{									//如果是超时引起的
      		CongWin = 1
      	}
      	
      }
      ```

通过这样的控制拥塞的逻辑，我们再对TCP的拥塞控制做一个**简单的性能评价：**

假如每个Segment有1500个byte，RTT是100ms，希望获得10Gbps的吞吐率，请评价丢包率与吞吐率的关系。

throughput = W\*MSS\*8/RTT，则 W = throughput\*RTT/(MSS\*8)，根据throughput=10Gbps，我们得出窗口大小为83333。

接着CongWin从W/2增加至W时出现第一个丢包，那么期间一共发送的分组为W/2+(W/2+1)+(W/2+2)+...+W = 3W<sup>2</sup>/8 + 3W/4。由于W很大，因此totalPacketNum = 3W<sup>2</sup>/8。

那么丢包率为8/3W<sup>2</sup> ≈ 2.10<sup>-10</sup>，丢包率非常的低，甚至可以忽略。正因该数值与实际相差非常之大严重不符，证明了现今网络下，TCP的一些设计已经过时了。

## <a name="第四章">第四章：网络层服务</a>

**网络层简述：**网络层负责将发送主机的数据段封装到数据报中并通过转发与路由的方式将该数据报发送到接收主机中并向上层交付数据段。再该过程中每个主机和路由器都运行网络层协议，路由器会检验所有穿越它的IP数据报的头部域并做出相应的决策处理。

### 1、网络层的核心功能：

- **路由与转发：**

  网络层的核心功能为<font color = "red">路由与转发</font>，网络中的路由器需要将源主机托送给它的数据报进行正确的选择传播路径后通过转发的方式将其送往目的主机。

  - **转发：**路由器根据路由器内置的转发表和IP数据报中的目的地址将分组从路由器的输入端口转移到合适的输出端口；
  - **路由：**路由器根据网络层协议中的路由算法来确定分组从源到目的经过的路径；

  <a href="https://sm.ms/image/3evqNd5claVBuoh" target="_blank"><img src="https://i.loli.net/2020/06/01/3evqNd5claVBuoh.png" width = 300px  ></a>

- **连接建立：**

  对于网络层上的连接建立**并不都是针对所有的网络**而言的，有些网络需要（如ATM网络），有些则不需要（如Internet网络）。与传输层的连接不同，传输层连接是两个应用进程之间的连接（对中间网络设备透明），而网络层连接是针对两个主机之间包括通信路径上的路由器与网络设备的连接，并且只有在这些网络设备建立连接完毕后，两端主机才能够进行数据分组的传输。

  <a href="https://sm.ms/image/EekSj5bfswW6xhv" target="_blank"><img src="https://i.loli.net/2020/06/01/EekSj5bfswW6xhv.png" width = 300px  ></a>

### **2、网络层服务模型：**

对于网络层服务模型粗略的可以分为以下两大类：

- **无连接服务：**
  - 不事先为系列分组的传输确定传输路径
  - 每个分组独立确定传输路径
  - 不同分组可能传输的路径不同，因此可能会乱序到达目的主机
  - 具有代表性的网络为**数据报网络**
- **连接服务：**
  - 为系列分组的传输**确定**从源到目的经过的路径（建立连接）
  - 确定完毕后，沿该路径传输系列分组
  - 所有的系列分组传输的路径相同
  - 传输结束后拆除连接
  - 具有代表性的网络为**虚电路网络**

#### 虚电路网络：

虚电路网络是一种典型的分组交换网络，同时也是一种有连接的网络（为主机到主机提供服务）。虚电路网络是从电路交换网络（在第一章网络的种类中有所提及）中借用过来的一种策略，通过确认一条从源主机到目的主机的路径，然后沿着这条路径建立逻辑上的连接。当源与目的之间经过的路径确认并连接后，路径上的设备需要共同完成并维护虚电路网络上的功能。虚电路网络与电路交换网络不同在于，虚电路网络利用的是分组交换技术来提高网络利用率与实现链路共享，发送分组时会利用链路上的**全部带宽**，而电路网络是通过用户建立连接后通过占用公共链路上的**部分带宽**（如频分复用，时分复用等）来收发数据和实现复用。

**虚电路网络的通信过程：**

- 呼叫建立→数据传输→拆除呼叫
- 传输时，每个分组携带该虚电路标识（VCID），而不是目的主机地址，当携带相同VCID的分组就会沿着该虚电路确定的路径从源主机传输到目的主机
- 虚电路经过的**每个**网络设备（比如路由器），维护**每条**经过它的虚电路连接状态。

虚电路网络结合了电路交换和分组网络的优点，它可以借鉴电路网络的特点来面向虚电路网络来进行资源的预分配，因此它可以达到一些预期的性能保障（如ATM网络提供的CBR服务）。

#### 虚电路网络的具体实现：

**对于虚电路网络来说，每条虚电路网络包括：**

**1、** **从源主机到目的主机的一条路径**

**2、**为每条虚电路路径**确立虚电路号VCID**（某条路径上允许建立虚电路的数量取决于它本身的链路带宽，因此每一段链路上所支持的虚电路数量也不同，因此虚电路号采用一种局部管理的方式，即每一段本属于同一虚电路连接的路径链路上所确定的虚电路号是不同的）

**3、**由于每一段链路上所表明的虚电路号可能是不同的，因此路径中的每个设备（如路由器）都需要参与这条连接链路上的路径关系，因此要**利用转发表记录经过的每条虚电路**。

那么如何让每个虚电路中的分组能够沿该虚电路确定的路径进行传播呢？首先要进行虚电路传播的分组要携带对应虚电路的VCID，当路由器转发该分组时要依据虚电路连接关系的转发表来改写/替换虚电路号（因为本属于同一条虚电路上的链路，会因为物理上的原因对虚电路所支持的情况有所不同，某些链路上的VCID会有所不同）。

虚电路转发表示例：

<a href="https://sm.ms/image/BPxt1hGoFgwAyb4" target="_blank"><img src="https://i.loli.net/2020/06/01/BPxt1hGoFgwAyb4.png" width = 500px  ></a>

路由器R1的VC转发表：

| 输入接口 | 输入VC# | 输出接口 | 输出VC# |
| -------- | ------- | -------- | ------- |
| 1        | 12      | 3        | 22      |
| ...      | ...     | ...      | ...     |

当虚电路网络连接时，R1路由器会与它的前序节点达成共识，确定在某一虚电路线路中前序节点会向它的1端口进行输入VC号是12的报文段，并且与与后续节点达成共识，将VC号是12的报文段改写为VC号为22的报文段并通过3接口转发到后续节点。依次类推，所有参与虚电路的节点都会有这样一个VC转发表来记录所有经过它的虚电路网络的路径，并对该表进行维护，对接收到的VC分组进行转发。

**虚电路信令协议（signaling protocols）：**该协议要对虚电路进行建立（包括路径选择，因此也需要进行路由，但该路由是连接时确立的，是**一次性的路由**，以后的虚电路数据报都会根据这次路由的路径进行转发）、维护与拆除。该协议在ATM、帧中继网络中被使用。

<a href="https://sm.ms/image/R8OcDonmNAaHCWq" target="_blank"><img src="https://i.loli.net/2020/06/01/R8OcDonmNAaHCWq.png" width = 500px  ></a>

源主机通过虚电路信令协议对目的主机进行一次连接呼叫（第一次连接呼叫的路径是不确定的，因此仍要进行路由器间的转发与路由来进行路径选择，选择路径通过的各个网络设备得知这是一个虚电路呼叫后会暂存该链路中与前序后续节点之间的关系（就像火车一样，每节车厢只要知道前面与后面的车厢是谁就能够建立一个完整的火车）），连接呼叫到达目的主机后，目的主机如果接收呼叫那么会沿刚刚信号过来的路径反向进行一次确认，该路径上所有的网络设备接收到该确认信号后都会一直都会在虚电路转发表中保留着该路径的关系直到接收到路径拆除的信号。源主机对要发送分组进行编写初始VC号，并通过该虚电路路径上各个节点中的VC转发表来发送分组给目的主机。当数据发送完毕后，源主机也要发送路径拆除信号来拆除路径。

#### 数据报网络：

数据报网络是一种典型的分组交换网络，同时是**无连接**的网络，因此每个分组都应该携带目的地址，并且各个路由器要根据分组的目的地址来转发分组，最终将分组送往正确的目的地。数据报网络中的路由器为了实现根据分组的目的地址实现转发，那么它必须包含一个基于路由协议/算法构建的转发表，通过检索转发表来对接收来的分组进行转发，并且由于这个转发表是实时更新的，因此对于每个带有相同目的地址的数据报都是单独选路的，未必都会通过同一条路径（虚电路网络实际上开始进行连接时也是通过这一种方式来确定VC路径的，但是虚电路网络在确定路径后就不变了，以后的分组根据VC号来在已经确定的线路上进行传输）。

<a href="https://sm.ms/image/WxSZmUMct7s6Eyr" target="_blank"><img src="https://i.loli.net/2020/06/01/WxSZmUMct7s6Eyr.png" width = 500px  ></a>

我们知道，源主机发送的分组所携带的地址是目的主机的IP地址，这个IP地址的基数是庞大的（IPv4共有32位，总共数目可达上亿级别），如果过路由器要根据地址来维护检索这样的千亿条记录的转发表显然是不可行的，那么如何解决这样的问题呢？

转发表不应该针对某一条具体的IP地址来进行路由和转发，而是应该针对**地址范围**，转发表对符合某一特征的IP地址进行分类，对符合转发表上某一地址范围的数据报进行选择输出链路。

<a href="https://sm.ms/image/rLHM1ganTSRBxpA" target="_blank"><img src="https://i.loli.net/2020/06/01/rLHM1ganTSRBxpA.png" width = 500px  ></a>

如：转发表对地址的划分

| 目的地址范围                                                 | 链路接口 |
| ------------------------------------------------------------ | -------- |
| 11001000 00010111 00010000 00000000到11001000 00010111 00010111 11111111 | 0        |
| 11001000 00010111 00011000 00000000到11001000 00010111 00011011 11111111 | 1        |
| 11001000 00010111 00011100 00000000到11001000 00010111 00011111 11111111 | 2        |
| 其他                                                         | 3        |

因此对于网络中路由器来说，接口上连接的链路必须要与IP地址范围对应（也就是IP地址的分配必须履行某种规定），下图是一个地址划分非常明确，并且连续的示例

<a href="https://sm.ms/image/TqN36XydBSnKwap" target="_blank"><img src="https://i.loli.net/2020/06/01/TqN36XydBSnKwap.png" width = 500px  ></a>

但不是每个路由器都能非常明确的划分地址范围，如：

| 目的地址范围                                   | 链路接口 |
| ---------------------------------------------- | -------- |
| 11001000 00010111 00010\*\*\* \*\*\*\*\*\*\*\* | 0        |
| 11001000 00010111 00011000 \*\*\*\*\*\*\*\*    | 1        |
| 11001000 00010111 00011\*\*\* \*\*\*\*\*\*\*\* | 2        |
| 其他                                           | 3        |

此时有一个目的地址为11001000 00010111 00011000 10011001的分组到达该路由器，那么应该从接口1转发还是接口2呢？事实上转发表会有一个**最长前缀匹配优先原则**（在检索转发表时，优先选择与分组目的地址匹配前缀最长的入口），会优先从接口1来进行转发。

### 3、Internet网络层：

主机、路由器在网络层主要的功能：

<a href="https://sm.ms/image/kQth4zJZu3jf6wK" target="_blank"><img src="https://i.loli.net/2020/06/01/kQth4zJZu3jf6wK.png" width = 500px  ></a>

IP协议是网络层的核心协议，也是TCP/IP协议族中的核心协议，所有该族的传输层协议（如TCP、UDP）的数据都通过IP数据报传输，它提供了一种尽力而为、无连接的数据报交互协议。它在Internet网络中位所有设备相互通信提供了一套规则。其中的寻址规约要依赖于路由器中的转发表，而转发表需要由路由协议来完成，ICMP协议在一定程度上可以看作为IP协议的伴随协议，实行IP协议一般就要实行ICMP协议来检测IP协议中分组的错误。

#### IP协议：

##### IP数据报：

IP数据报由首部和数据两部分构成，其中首部分为固定部分（20个字节）与可变部分，数据为传输层协议交付给IP协议的数据段（segment）。

<a href="https://sm.ms/image/phy4HwRVxS5iTkP" target="_blank"><img src="https://i.loli.net/2020/06/01/phy4HwRVxS5iTkP.png" width = 500px  ></a>

下面来介绍IP数据报的头部各个字段的属性及含义：

- 版本号：占用4bit，如果是IPv4，对应的4bit为4，如果是IPv6，对应的4bit为6；
- 首部长度：占用4bit，表示整个IP分组的首部长度。由于是4个bit，换算成十进制，最多只能够表示15，这对于正常的IP数据报头部都是远远不够的，因此该部分换算成十进制后，以4字节为单位。（如0101换算为5，代表5\*4 = 20个字节）；
- 服务类型：占用8bit，表示期望利用该字段指示IP分组在网络传输过程中期望传输什么样的服务。该字段只有在网络真正提供区分服务时才有效（因此一般情况下，该字段的值都为00H）；
- 总长度：占用16bit，表示IP分组的总字节数（首部+数据）。因此最大IP分组的长度为（2<sup>16</sup>-1 = 65535）个字节，去掉最小头部20个字节后，能够封装的最大数据为65515个字节。
- 标识：占16bit，IP协议利用一个计数器，每产生IP分组计数器加1，通过该标识位与源/目的IP地址来唯一的标识一个分组。**所有分片的数据报的标识必须要和原数据报的标识相同**。假如一个数据报的标识是12345，可能由于这个数据报过大，分片后将它分为3个小的数据报，这3个较小的数据报的标识也必须是12345，可以理解这3个数据报是一个家族的。**相同的标识字段的值可以使分片后的各个数据报最后能正确的重装成原来的数据报**；（在下面会说IP分片，这里可以暂时忽略掉）
- 标志位：占3个bit，目前只有后两位有意义；（在下面会说IP分片，这里可以暂时忽略掉）
  -  最低位即第3位记为**MF**（More Fragment），意思是**是否还有更多分片**。当值为1时，表示该分片不是最后一片，后面还有分片，当值为0时，表示这是原数据报分片后的最后一片数据报（也可能是未被分片），后面已经没有更多的分片了
  - 中间位即第2位记为**DF**（Don't Fragment），意思是原数据报**能否分片**。当值为1时，表示该数据报不允许分片，当值为0时，表示该数据报允许分片
- 片偏移：占13bit，其表示较长分组分片后，被分片的分组在原分组中的相对偏移量，也就是说相对于**上层交付数据字段的起点**。根据该字段，目的主机就能够将这些分片进行排序重组为原始分组。在IPv4中，片偏移量的值是以8字节为单位的，因此在IP分组分片的过曾中除了最后一片，前面的所有分片封装的数据字节数一定是8的倍数；（在下面会说IP分片，这里可以暂时忽略掉）
- 生存时间（TTL）：占8位，IP分组在网络中可以通过的路由器数（也称跳步数），当该分组被路由器每次转发时，TTL都会减1，如果TTL = 0，那么路由器就丢弃该IP分组并向源主机发送ICMP的报文；
- 协议：占8个bit，指示IP分组封装的是哪个协议的数据包，通过该字段可以让IP协议知道它所封装的是上层哪个协议的数据段（如，6为TCP，表示封装的是TCP段、17为UDP，表示封装的是UDP数据报）；
- 首部校验和：占16个bit，实现对IP分组**首部**的差错检测，检验的过程**与上一章UDP的校验合的方式是一模一样的**（进行校验的部分只与IP数据报头部有关，并且由于再次分片或TTL等一系列数值的变化，数据报的每次转发都一定是要重新校验的）；
- 源IP地址、目的IP地址：各占32bit，分别标识发送分组的源主机/路由器和接受分组的目的主机/路由器的IP地址；
- 选项字段：长度不一定，范围在1到40字节之间，用来进行网络的探测或者是度量，可以携带安全、源选路径（在发送数据报的时候，就已经选定好了发送路径，让中间路由器按照这个路径进行转发）、时间戳和路由记录等内容；
- 填充域：长度可变，目的是为了补齐整个首部，符合32位对齐，保证首部长度是4字节的倍数（范围在0—3字节之间，因为首部长度域是以4字节为单位的）；

##### IP分片：

在了解IP分片之前，我们先学习一个概念：**最大传输单元**

在IP协议将上层的数据段封装处理好以后，要将这个数据报送往链路层，链路层要对该数据报再次封装为数据帧。但是链路层对封装的上层数据是有最大限制的，这个限制就称为MTU（最大传输单元）（比如在以太网中MTU为1500个字节）。这个**封装限制在不同链路中的大小也是不同的**。

那么当**面对传输路径上的两个对MTU要求不同的链路**怎么办？

- 大IP分组向较小的MTU链路转发时，<font color = "red">可以</font>（具体能否分片要看DF标志位）被（再次）“分片”。
- IP分片在到达目的主机后进行重组合。（分片到达最终目的主机后，主机再进行重组，而路由器只分不装（要不然装完还要再分，浪费资源））
- 因此为了还原IP分组，IP首部的相关字段（上面已经介绍过了）要用于标识分片以及确定分片的相对顺序。
- 如果目的主机收到的分片不全，它会等待一段时间，如果等不到就会将这些分片丢弃。

<a href="https://sm.ms/image/gnp3ckCUPARHXEF" target="_blank"><img src="https://i.loli.net/2020/06/01/gnp3ckCUPARHXEF.png" width = 300px  ></a>

**IP分片过程：**

- 假设原IP分组总长度为L，待转发链路的MTU为M
- 若L>M且DF = 0，那么此时需要分片并且可以进行分片
- 分片时每个分片的标识复制为原IP分组的标识
- 通常分片时，除最后一个分片外，其他分片均分为MTU允许的最大分片（且字节数为8的倍数）
- 一个最大分片封装的数据应该是8的倍数，因此，一个最大分片可封装的数据为（假如头部就20个字节）：     d = （（M - 20）/ 8）向下取整\*8
- 需要的总片数为：n = （（L - 20）/d）向上取整
- 每片的片偏移字段的取值为：Fi = （d/8）\*(i - 1),    1 <=i <= n
- 每片的总长度字段为：
  - Li = d + 20, 当1<=i<n时
  - Li = L - （n - 1）\*d , 当 i = n时
- 每片的MF标志位为：
  - 1, 当1<=i<n时
  - 0 , 当 i = n时

<a href="https://sm.ms/image/pO1hJUonLjXCNxs" target="_blank"><img src="https://i.loli.net/2020/06/01/pO1hJUonLjXCNxs.png" width = 500px  ></a>

#### IP编址：

在Internet网络中，如果我们要非常清晰的保证IP分组能够从源主机到达目的主机，那么我们对于源主机和目的主机一定要给出它们的目的地址，网络中的中间设备（路由器、交换机）要根据IP数据报上的目的地址最终将该数据报送到目的地址上（这在之前的数据报网络有说明）。这就意味着我们需要对各个参与其中的网络设备进行编址。

由于IP数据报都是由主机或路由器从网络接口（主机/路由器与物理链路的连接）中发出的，因此我们编址的对象为<font color = "red">接口</font>（通常为路由器上的接口（含多个），主机上的接口（通常为一个或两个，有线的以太网接口和无线的802.11接口））。这些被编址的接口一定要实现网络层上的功能，换言之如果这些接口没有**实现网络层上的功能**，那么它们对于网络层就是透明的，我们也无需为这些“透明”的接口进行编址。

<a href="https://sm.ms/image/oybQXYlIZqV3kp1" target="_blank"><img src="https://i.loli.net/2020/06/01/oybQXYlIZqV3kp1.png" width = 350px  ></a>

 **IP地址：**在IPv4中是用一个长度为32的比特串（如，11011111 00000001 00000001 00000001）来标识主机、路由器的接口。为了方便记忆我们将这样的比特串以每8bit变换为十进制并用小数点连接起来（如，223.1.1.1）,该方式被称为**点分十进制IP地址形式**。

**如何为接口分配IP地址？**

如果随意分配IP地址，那么路由器中的转发表会变得非常复杂，因此在IP地址分配和编址的过程中我们不能够随意的去分配和编址，我们需要通过某种策略来达到目的。我们将IP地址分为两个部分，高比特位视为为**网络号**（NetID），**低比特**位视为主机号（HostID），其中网络号用来标识一个IP网络。我们需要保证分配到某一个区域网络中的接口的IP地址，它们的网络号是相同的（相对的主机号是不能相同的）。

- **IP子网：**具有相同网络号的接口构成了IP子网，因此我们可以利用具有相同网络号的接口的集合（IP子网）来描述某一区域的网络。
  - 特点：
    - 对于在相同的IP子网中的接口的IP地址，它们的网络号是相同的。
    - 在同一IP子网中，所有的接口能够不跨越路由器（第三层以及以上的网络设备）就可以彼此物理联通，换言之，如果两台设备连接需要跨越路由器，那么它们就不属于一个IP子网了。
    - 在路由器的转发表中，若要转发数据，通常就不用记录每一个相连主机的具体IP地址了，只需要记录这个区域的IP子网地址就可以了。
    - 我们可以利用一个特殊地址来表示一个一个IP子网的整体，这个表示方式叫做IP子网地址（如，223.1.1.0/24 ）

如下图：

<a href="https://sm.ms/image/8EpTFrbZPm65fAo" target="_blank"><img src="https://i.loli.net/2020/06/01/8EpTFrbZPm65fAo.png" width = 350px  ></a>

因此IP编址需要利用层次化的思想来完成，由网络号→主机号，因此互联网络就是由一个个的IP子网构成的

<a href="https://sm.ms/image/bSAKPxpYkldCGht" target="_blank"><img src="https://i.loli.net/2020/06/01/bSAKPxpYkldCGht.png" width = 350px ></a>

##### 有类IP地址：

在了解什么是IP子网后，我们知道具有相同网络号的接口构成了IP子网。那么如何划分IP地址中网络号与主机号？如何通过特殊的IP地址来辨别在网络层中特殊的设备接口？这需要我们通过IP子网的思想对IP地址有一个明确的划分。

“有类”编址采用二分法，规定了如何将整个IP地址划分成明确的IP子网

- A类地址（50%）：对于32位的IP地址，取前8个比特作为网络号（其中最高的比特位固定是0，这是A类地址规定的，正因如此A类地址直接将整个IP地址进行了二分），对应的点分十进制的IP地址为前面第一个十进制数字。因此对于A类网络实际可以编址的数量为2<sup>7</sup>。剩余的24个比特位作为主机号来使用。整个A类地址范围为：0.0.0.0——127.255.255.255

  <a href="https://sm.ms/image/sFl4zqJV5QfoIEv" target="_blank"><img src="https://i.loli.net/2020/06/01/sFl4zqJV5QfoIEv.png" width = 500px  ></a>

  对于A类地址，能够区分的A类IP子网比较少，但每一个子网中可区分的主机数比较多

- B类地址（25%）：由于A类地址的最高比特位规定是0，因此除去A类剩余的IP地址的最高位应该是1，因为B类地址要将剩余的IP地址再次二分，因此取次高比特位为0。在B类地址中我们规定前16个比特作为网络号，后16个比特作为主机号，由于B类地址的最高与次高比特位固定为**10**，因此B类可以编址的范围为2<sup>14</sup>。同样的B类地址范围为：128.0.0.0——191.255.255.255

  <a href="https://sm.ms/image/dpBAEnXFDJke9qo" target="_blank"><img src="https://i.loli.net/2020/06/01/dpBAEnXFDJke9qo.png" width = 500px ></a>

  对于B类地址，B类子网数和每个子网中可区分的主机数都比较折中

- C类地址（12.5%）：由于最高比特位为0的IP地址已经为A类地址了，最高比特位是1但次高比特位为0的已经为B类地址了，因此C类地址要将剩余地址再次二分，最高的三个比特位应该为110。我们规定在C类地址中IP地址的前24位作为网络号。因此B类可以编址的范围为2<sup>21</sup>。同样的C类网络的地址范围为：192.0.0.0——223.255.255.255

  <a href="https://sm.ms/image/WN3ij7SsdbHLwVr" target="_blank"><img src="https://i.loli.net/2020/06/01/WN3ij7SsdbHLwVr.png" width = 500px ></a>

  对于C类地址，能够区分的C类IP子网比较多，但每一个子网中可区分的主机数比较少

- D类地址(6.25%)：将剩余的IP地址再次二分，前四个比特位为1110，不再区分网络号与主机号。范围为：224.0.0.0——239.255.255.255

- E类地址(6.25%)：前四个比特位为1111，不再区分网络号与主机号。不再区分网络号与主机号。范围为：240.0.0.0——255.255.255.255

  <a href="https://sm.ms/image/tW8HKUj3mAyoRu9" target="_blank"><img src="https://i.loli.net/2020/06/01/tW8HKUj3mAyoRu9.png" width = 500px ></a>

- 对于D类地址，我们用这类地址命名一组主机，这一组主机理论上可以分布在互联网上的任何一个地方。因此这类地址只能够作为IP分组的目的地址，我们通常也为这类地址命名为多播地址，当我们向一个多播地址发送IP一个分组，只要是属于这个多播地址的成员组的主机都会收到该IP分组的一个副本。

  **多播：**多播作为一点对多点的通信，数据的收发仅仅在同一分组中进行，是节省网络带宽的有效方法之一。在网络应用中，当需要将一个节点的信号传送到多个节点时，无论是采用重复点对点通信方式，还是采用广播方式，都会严重浪费网络带宽，只有多播才是最好的选择。多播能使一个或多个多播源只把数据包发送给特定的多播组，而只有加入该多播组的主机才能接收到数据包

  **多播组：**使用同一个 IP 多播地址接收多播数据包的所有主机构成了一个主机组，也称为**多播组**。一个多播组的成员是随时变动的，一台主机可以随时加入或离开多播组，多播组成员的数目和所在的地理位置也不受限制，一台主机也可以属于几个多播组。因此，多播组就像我们日常使用的QQ群，IP多播地址就是QQ群号。

- E类地址供研究使用

- 当我们为某个主机或路由器的接口分配网络地址时，都是从A、B、C类地址中分配的。但有一些地址即便是属于ABC类地址，但这些地址是有特殊意义的，是不能够分配的。以下是对于这种特殊的地址的一个概括：

  - | 网络号 | 主机号               | 作为IP分组源地址 | 作为IP分组的目的地址 | 用途                                                         |
    | ------ | -------------------- | ---------------- | -------------------- | ------------------------------------------------------------ |
    | 全0    | 全0                  | 可以             | 不可以               | 在本网范围内表示主机；在路由表中用于表示默认路由（相当于表示整个Internet网络）一般在本机主机想要利用IP分组来发送数据，但又不知道自己的IP地址 |
    | 全0    | 特定值               | 不可以           | 可以                 | 表示本网内某个特定主机                                       |
    | 全1    | 全1                  | 不可以           | 可以                 | 本网的广播地址（路由器不进行转发）                           |
    | 特定值 | 全0                  | 不可以           | 不可以               | 网络地址，表示一个网络（IP子网）                             |
    | 特定值 | 全1                  | 不可以           | 可以                 | 直接广播地址，对特定网络上的所有主机进行广播（不一定是自己所处的IP子网） |
    | 127    | 非全0或非全1的任何数 | 可以             | 可以                 | 用于本地软件环回测试，称为环回地址                           |

    除了以上是有特殊意义不能分配的IP地址以外，下面还有私有的IP地址，这些地址只用于内部网络，在公共互联网中是无用的：

    | 所占哪类地址 | 所占该类地址的网络号范围  | 所占该类地址的编址数目 |
    | ------------ | ------------------------- | ---------------------- |
    | A            | 10                        | 1                      |
    | B            | 172.16 to 172.31          | 16                     |
    | C            | 192.168.0  to 192.168.255 | 256                    |

    正是因为这些私有IP地址与后面介绍的NAT（网络地址转换）技术使得现在的IPv4即使已经被分配殆尽，但是整个互联网还能够正常运行。

##### IP子网的划分：

对于划分子网，我们知道了通过区分网络号来将IP地址划分成一个个子网，通过固定某些比特位和网络号的长度来确定了有类编址。但有类编址缺乏灵活性，有时我们可能希望被分配一种编址能够正好承载我们的主机数，但有类编址可能不是太大就是太小。这就需要我们对一个IP子网细分为更小的范围。

IP子网划分，通过借用主机号的高比特位到低比特位的一部分来表示为<font color = "red">子网号</font>，对子网进行划分

子网划分的IP地址：<font color = "red">网络号（NetID）、子网号（SubID）、主机号（HostID）</font>

如下图我们希望对一个B类子网进行再次划分，再划分为4个等长的子网：借用主机号的高两位比特作为子网号，分别编址为00、01、10、11：

<a href="https://sm.ms/image/DtsJdNCnTXaprVe" target="_blank"><img src="https://i.loli.net/2020/06/02/DtsJdNCnTXaprVe.png" width = 500px ></a>

**子网掩码：**

当子网进行划分后，路由器怎样才能知道该类网络是否被划分了，以及划分了多少个子网（借用了多少主机号的比特位）

子网掩码行如IP地址，共32个比特，采用点分十进制计法，但对**网络号和子网号全部取1，主机号全部取0**

例如：A网的默认子网掩码为：255.0.0.0

​			B网的默认子网掩码为：255.255.0.0

​			C网的默认子网掩码为：255.255.255.0

​			借用3比特划分子网的B网的子网掩码为：255.255.224.0 （11111111 11111111 **111**00000 00000000）

因此通过**子网地址+子网掩码就能够准确确定子网大小** 

例如：将一个IP编址为201.2.3.0,子网掩码为255.255.255.0的C类子网进行划分为等长的4个子网

- 借用主机号的前两位分别取00，01，10，11，并修改子网掩码为255.255.255.192

  <a href="https://sm.ms/image/WceLgiYjBHMSxt3" target="_blank"><img src="https://i.loli.net/2020/06/02/WceLgiYjBHMSxt3.png" width = 500px ></a>

**子网掩码的应用：**路由器在存储转发表的相关信息的时候除了要存储子网的地址以外，还必须伴随着相应的子网掩码。路由器通过将IP分组的目的IP地址与子网掩码按位与运算来得知子网的地址，如果通过该运算得知的地址与该转发表存储的对应的子网地址相同，那么该目的地址就属于这个子网。

```
例如：目的IP地址：127.32.1.112,子网掩码：255.255.254.0
	 127.32.1.112 = 10101100 00100000 00000001 01110000
	255.255.254.0 = 11111111 11111111 11111110 00000000
			与运算:  10101100 00100000 00000000 00000000		
            点分十进制：172   .  32    .   0    .   0
    因此子网地址为：172.32.0.0(伴随的子网掩码：255.255.254.0)
       该子网中地址范围：10101100 00100000 00000000 00000000(172.32.0.0)
    				  到
    				  10101100 00100000 00000001 11111111(172.32.1.255)共512个地址
    该网中可分配地址范围:10101100 00100000 00000000 00000001(172.32.0.1)(主机全0代表该子网)
    				  到
    				  10101100 00100000 00000001 11111110(172.32.1.254)（主机全1代表广播）
    				  共510个地址
    	该子网的广播地址：172.32.1.255
```

如下是一个C类网络划分子网的举例：

| 子网 | SubID（二进制） | HostID取值范围（二进制）                   | 第4八位组取值范围（十进制） |
| ---- | --------------- | ------------------------------------------ | --------------------------- |
| 1    | 000             | 00000到11111（其中全0和全1不能作为主机ID） | .0 to .31                   |
| 2    | 001             | 00000到11111                               | .32 to .63                  |
| 3    | 001             | 00000到11111                               | .64 to .95                  |
| 4    | 011             | 00000到11111                               | .96 to .127                 |
| 5    | 100             | 00000到11111                               | .128 to .159                |
| 6    | 101             | 00000到11111                               | .160 to .191                |
| 7    | 110             | 00000到11111                               | .192 to .223                |
| 8    | 111             | 00000到11111                               | .224 to .255                |

#### CIDR与聚合路由：

无类域间路由（CIDR：Classless InterDomain Routing）：**消除了传统的A类、B类和C类地址界限**，在CIDR中我们将之前的网络号（NetID）与子网号（SubID）不再区分，统称为网络前缀Network Prefix，并且网络前缀可以是任意长度。这样的将NetID与SubID的融合为子网划分提供了方便。

**CIDR的地址格式：<font color = "red">a.b.c.d/x</font>,其中x为前缀长度**

如：<font color = "red">11001000 00010111 0001000</font>0 00000000 记为：200.23.16.0/<font color = "red">23</font>

​		子网201.2.3.64, 子网掩码255.255.255.192 可记为：201.2.3.64/<font color = "red">26</font>

CIDR的优点：

- 提高IPv4地址空间分配效率

- 提高路由效率：将多个子网聚合为一个较大的子网

- 路由聚合：简化路由表

  | 目的网络     | 接口 |
  | ------------ | ---- |
  | 223.1.0.0/23 | 2    |
  | 223.1.2.0/24 | 2    |
  | 223.1.3.0/24 | 2    |
  | Internet     | 1    |

  可以聚合为：

  | 目的网络     | 接口 |
  | ------------ | ---- |
  | 223.1.0.0/22 | 2    |
  | Internet     | 1    |

  对于CIDR来说，我们可以利用层级编址使得路由通告信息更加有效，各层次中的路由对IP地址逐步细分，高层的路由（相对于发送方来说是高层，其中的转发表对连通的各个子网进行了聚合，而连接的各个子网也是由更小的子网聚合而来的）接收到分组后**利用最长前缀匹配优先原则**将分组一步步送往低层路由，低层路由对IP编址进行了细分（这里的细分指得是，这些低层路由的转发表也是由各个子网聚合而成的，但是被聚合的子网会越来越小直到不可再分）并同上面的步骤一样，最终送到确定的目的主机。

  <a href="https://sm.ms/image/1zEn2U4aF8f7hKs" target="_blank"><img src="https://i.loli.net/2020/06/02/1zEn2U4aF8f7hKs.png" width = 500px ></a>



**如何获得IP地址：**

- 静态配置方式：我们通过询问网络系统管理员来手动配置IP属性，需要输入以下属性

  - IP地址：如223.1.1.1
  - 子网掩码：如255.255.255.128，表识IP地址所处的子网
  - 默认网关：如233.1.1.4，该子网所连接的能够通向其他网络的路由接口的IP地址
  - DNS服务器：如222.1.2.3，该主机的本地域名解析服务器的IP地址

- **DHCP（动态主机配置协议）：**从服务器自动的动态获取IP的相关属性

  - 从服务器动态获取：IP地址、子网掩码、默认网关地址、DNS服务器名称与IP地址

  - 即插即用：如果该主机支持DHCP协议，并且该主机接入的网络中配置DHCP服务器，那么通过客户主机上运行的DHCP协议客户端与DHCP服务器进行**报文交换**就可以完成地址的申请与分配。

    - 发现报文（DHCP discover）：主机通过向接入的子网广播发现报文来确认该子网中是否有DHCP服务器
    - 提供报文（DHCP offer）：当DHCP服务器收到了主机发送的发现报文后，DHCP通过广播的方式向主机表示它可以提供服务（一个子网中有可能有多个DHCP服务器）
    - 请求报文（DHCP request）：当主机收到了DHCP服务器的他提供报文后，主机向其中一个DHCP服务器发送请求报文，请求IP地址
    - 确认报文（DHCP ack）：当DHCP服务器接收到了主机发送的请求报文，DHCP服务器会向主机发送一个确认报文，其中包含分配的**地址信息**与**租借期**

  - 允许地址重用：当一个主机接入网络后，可以通过DHCP服务器**租用**一个IP地址，当主机从网络中断开后，这个IP地址归还给DHCP服务器，DHCP服务器可以将该IP地址再次利用

  - 支持移动用户加入网络

    <a href="https://sm.ms/image/cx5Ow1rILy6KSN2" target="_blank"><img src="https://i.loli.net/2020/06/02/cx5Ow1rILy6KSN2.png" width = 500px ></a>

  **DHCP工作过程：**

  ```
  1、主机DHCP客户端发送发现报文：
  src:0.0.0.0,68		//主机开始时不知道自己的IP地址，用0.0.0.0表示自己，68是DHCP客户端默认端口
  dest:255.255.255,67	//主机通过广播的方式进行发送该分组，255.255.255.255表示该子网的广播地址
  yiaddr:0.0.0.0		//表示your address
  transaction ID:654	//表示一个事物的ID
  2、DHCP服务器发送提供报文（前提是DHCP服务器愿意为客户服务）：
  src:223.1.2.5,67	//DHCP服务器的IP地址	
  dest:255.255.255,68	//广播发送分组，DHCP在服务器上的默认端口为68
  yiaddr:223.1.2.4	//DHCP为主机预分配的IP地址	
  transaction ID:654	//表示与上一个分组是同样的事件
  lifetime:3600 secs  //该IP地址可使用的事件为3600 secs
  3、主机DHCP客户端发送请求报文：
  src:0.0.0.0,68
  dest:255.255.255,67	//通告所有的DHCP服务器，该主机已经找到了合适的DHCP服务器
  yiaddr:223.1.2.4	//向选择向主机提供的DHCP服务器确认被分配的IP地址
  transaction:655
  lifetime:3600 secs
  4、DHCP服务器发送确认报文：
  src:223.1.2.5,67	
  dest:255.255.255,68	
  yiaddr:223.1.2.4	//DHCP服务器为主机分配的IP地址，主机接收到该报文后就可以正式使用该IP地址了	
  transaction ID:655	
  lifetime:3600 secs  
  
  //以上的内容有省略，但是大体就是这样的过程
  //并且DHCP服务是由应用层构建的
  ```

##### 网络地址转换（NAT）：

在IPv4中，除去不能够用于分配的IP地址（D、E类，和A、B、C三类中用于特殊目的的地址），剩余的**能够在公共互联网中使用的IP地址**已经**分配殆尽**了。但是在A、B、C类分配地址中规定了一部分**私有地址**（前面表格中有介绍），为了让这些分配了私有地址的主机能够在互联网中正常使用，NAT技术就是解决这个问题的典型方式。

如下图，本地网络内通信的IP数据报的源与目的IP地址均在子网10.0.0/24内，这些主机在内部相互通信直接就使用这些地址作为源地址与目的地址是没有问题的。但是当这些主机想要与互联网进行数据报交换，就必须进行地址交换（**所有离开本地网络**去往Internet的数据报的源IP地址需替换为相同的NAT IP地址：138.76.29.7以及**不同**的**端口号**）。

<a href="https://sm.ms/image/xnuo4GLsemgZa87" target="_blank"><img src="https://i.loli.net/2020/06/02/xnuo4GLsemgZa87.png" width = 500px  ></a>

使用NAT的动机：

- 只需/能从ISP申请一个IP地址
- 本地网络中的主机全部使用私有地址，本地网络设备IP地址的变更，无需通告外界网络
- 变更ISP时，无需修改内部网络设备IP地址
- 内部网络设备对外界网络是不可见的，即不可直接寻址，具有安全性

**NAT的实现：**

- **替换：**利用（NAT的公共IP地址，新端口号）替换每个**外出IP数据报**的（源头IP地址，源端口号）

- **记录：**将每对（NAT IP地址，新端口号）与（源IP地址，源端口号）的替换信息存储到NAT转换表中

- **替换：**根据NAT转换表，利用（源IP地址，源端口号）替换每个**进入内网IP数据报**的（目的IP地址，目的端口号），即（NAT IP地址，新端口号）

  <a href="https://sm.ms/image/JpmvKLEe57wzFxi" target="_blank"><img src="https://i.loli.net/2020/06/02/JpmvKLEe57wzFxi.png" width = 500px ></a>

**NAT的穿透问题：**

对于外部网络的客户希望能够连接内部网络地址为10.0.0.1的服务器，但客户不能够直接利用10.0.0.1直接访问服务器，因为该地址对于外网来说是不可见的，非法的。这就是NAT的穿透问题。

<a href="https://sm.ms/image/aPcC6v23O54ARNQ" target="_blank"><img src="https://i.loli.net/2020/06/02/aPcC6v23O54ARNQ.png" width = 400px  ></a>

解决方法：

- 静态配置NAT，将特定端口的连接请求转发给服务器（如，（138.76.29.7,2500）总是转发给(10.0.0.1,25000)）

- 利用UPnP互联网网关设备协议来自动配置，其目的和静态配置NAT是一样的

- 中继：NAT内部的客户与中继服务器建立连接，外部客户也与中继服务器建立连接，中继服务器桥接两个连接的分组

  <a href="https://sm.ms/image/3iaoZ4lKF2Wkjb8" target="_blank"><img src="https://i.loli.net/2020/06/02/3iaoZ4lKF2Wkjb8.png" width = 500px ></a>

**ICMP（互联网控制报文协议）：**

ICMP的主要功能是**支持主机或路由器完成差错的报告**以及进行**网络探寻**。IP网络对于接收到的错误的IP数据报的最简单的处理方式是将错误的IP数据报进行丢弃，当发生这种情况后接收方需要对出现IP数据报差错的源主机发送ICMP报文进行差错报告。但是并不是说如果数据报发生差错了就一定会发送ICMP报文，是有一些例外情况的（后面会提）。

两类ICMP报文：

- 差错报告报文
  - 目的不可达
  - 源抑制：最早是用来进行拥塞控制的，当路由器因为自身的缓存被占满不得不丢弃数据报，会向源主机发送该报文，但目前该报文已经不用了
  - 超时/超期：最典型的就是TTL超期，当TTL消减到0时，该数据报被丢弃，向源主机发送该报文
  - 参数问题：如果路由器或目的主机认为数据报的参数有问题会向源主机发送该报文
  - 重定向：当某网关路由器收到了认为本不应该是由自己转发数据报时，该路由器会向源主机发送该报文并标明源主机应该向哪个网关路由器发送该报文
- 网络探寻报文
  - 回声（Echo）请求与应答报文（Reply）：探测源主机到某一主机的网络是否通达，通过发送回声请求报文并通过应答报文来探测是否通达，如ping
  - 时间戳请求与应答报文：通过发送时间戳请求，并通过时间戳应答来实现对时间戳的获取

| 类型 | 编码 | 描述                          |
| ---- | ---- | ----------------------------- |
| 0    | 0    | 回声应答（如ping）            |
| 3    | 0    | 目的网络不可达                |
| 3    | 1    | 目的主机不可达                |
| 3    | 2    | 目的协议不可达                |
| 3    | 3    | 目的端口不可达                |
| 3    | 6    | 目的网络未知                  |
| 3    | 7    | 目的主机未知                  |
| 4    | 0    | 源抑制（用来拥塞控制-不用了） |
| 8    | 0    | 回声请求（ping）              |
| 9    | 0    | 路由通告（已经不用了）        |
| 10   | 0    | 路由发现（已经不用了）        |
| 11   | 0    | TTL超期                       |
| 12   | 0    | IP首部描述                    |

几种不发送ICMP差错报告报文的特殊情况：

- 对ICMP差错报告报文不再发送ICMP差错报告报文
- 除第一个IP数据报分片外，对所有后续分片均不发送ICMP差错报告报文
- 对所有多播IP数据报均不发送ICMP差错报告报文
- 对具有**特殊地址**（127.0.0.0或0.0.0.0）的IP数据报不发送ICMP差错报告报文

**ICMP报文格式：**ICMP报文封装到IP数据报中进行传输

<a href="https://sm.ms/image/WOJRSKMDj6PkfTa" target="_blank"><img src="https://i.loli.net/2020/06/02/WOJRSKMDj6PkfTa.png" width = 400px  ></a>

<a href="https://sm.ms/image/pEnv1VxKWTtUX9o" target="_blank"><img src="https://i.loli.net/2020/06/02/pEnv1VxKWTtUX9o.png" width = 400px  ></a>

特别说明一下上图中蓝色部分的8个字节表示为源主机传输层协议封装的头部信息（对于UDP前8个字节为完整的头部，对于TCP前8个字节为源端口号，目的端口号和段序号）

##### IPv6简介：

IPv6相比IPv4能够支持更多的地址空间，并且改动了首部格式（为了实现快速处理/转发数据报）

IPv6数据报格式：

- 有一个固定长度为40个字节的基本头

- 通过扩展首部来支持各种选项（也叫选项首部），路由器不需要对扩展首部进行处理

- 不允许分片（源主机分片，目的主机组装，路由器不能够分片 ）

  <a href="https://sm.ms/image/D5pB9SZsogxNeiq" target="_blank"><img src="https://i.loli.net/2020/06/02/D5pB9SZsogxNeiq.png" width = 400px></a>

  <a href="https://sm.ms/image/1fm2xARyOV6rXiK" target="_blank"><img src="https://i.loli.net/2020/06/02/1fm2xARyOV6rXiK.png" width = 400px  ></a>

- 基本首部的字段：

  - 基本首部：占4个bit，和IPv4相同，标识自己的版本号
  - 优先级：占8个bit，主要目的是为了区分数据报的优先级，以便IPv6网络区分对待不同类型的数据报，类似IPv4的服务类型字段
  - 流标签：标识一个一系列的数据报流（流的概念为，从一个特定的主机出发到达一个特定的目的一系列的数据报被称作为流）
  - 载荷长度：包括扩展首部以及数据的长度，理论上最大长度为65535个字节
  - 下一个首部：如果IPv6有扩展首部，那么该字段指向的就是第一个扩展首部，每一个扩展首部都包含下一个首部这样的字段，如果是最后一个首部，那么该字段就指向传输层（比如TCP或UDP段）的首部
  - 跳步限制：对应IPv4的TTL，规定该数据报在网络中能够经过最多的路由器
  - 源地址、目的地址：和IPv4相同，但进行了扩展共有128个比特，所支持的地址空间十分庞大

IPv6**删除了校验合**，以减少每跳处理的时间，将IPv4的选项字段移出并定义多个选项首部。伴随着IPv6的诞生，对应的互联网控制报文ICMPv6也诞生了，其主要更新的一个功能是处理被丢弃的分片，当路由器转发源主机的分片时，如果该分片过大超出了链路的MTU，路由器将其丢弃并向源主机发送一个ICMPv6报文，让源主机决定如何进行分片。

##### IPv6地址表示形式：

IPv6的地址空间十分庞大，多到可以为空气中的尘埃都可以分配一个唯一的地址空间，因此IPv6的地址格式再次沿用IPv4的点分十进制的格式是不合适的。IPv6改用冒号分隔的16进制的地址表示形式：将128个bit的IPv6地址按每16个比特一组分为8组，每8组中的16比特转换为对应的十六进制数，最后用冒号连接起来（如，1080:0FF:0:8:800:200C:417A）

由于IPv6的比特长度太大，因此中间会有很多比特位为0，如FF01:0:0:0:0:0:0:43，面对这种情况为了更方便书写，IPv6地址格式支持**压缩形式**，将连续的几个0用::的形式来表示（只允许有一个::符号，否则无法得知IPv6忽略了多少个0），如FF01::43

由于IPv6会与IPv4长期共存，因此必须要让IPv6向下兼容IPv4的地址格式，因此采用了**IPv4嵌入格式**来保证了兼容性，如<font color = "red">0:0:0:0:0:FFFF:</font>13.1.68.3(压缩格式为<font color = "red">::FFFF:</font>13.1.68.3)，其中红色部分为固定格式占用96个字节，后32个字节为IPv4的地址

IPv6不再使用子网掩码，全部利用CIDR形式来表示子网(2002:43C:476B::/48)

IPv6的冒号会在URL表示中（: 端口号）产生歧义，因此在URL中通常会用中括号将IPv6地址括起来（http://[3FFE::1:800:200C:417A]:8000）

##### IPv6基本地址类型：

单播地址：通常就是用来表示参与网络层功能的接口，可以表示为目的地址和源地址，用于一对一通信

多播地址：和IPv4的D类地址的目的是一样的，但是有更大的地址空间，只能表示为目的地址，用于一对多通信，在IPv6中不再有广播地址，原本的广播地址被多播地址替代（为一个子网中所有的接口都定义为同属于一个多播组）

任意播：这是IPv6新加的地址类型，其通信方式为一对组之一

**IPv4向IPv6过渡与共存：**

**隧道技术：**当IPv6的数据报在传输过程中要穿越一个IPv4的网络，IPv6的数据报作为IPv4数据报的载荷进行封装，穿越IPv4数据报，在穿越完成后再进行卸载IPv4首部。

<a href="https://sm.ms/image/V79aTzdNB2XZqCH" target="_blank"><img src="https://i.loli.net/2020/06/02/V79aTzdNB2XZqCH.png" width = 400px ></a>

<a href="https://sm.ms/image/5e73k19YaBOXAGc" target="_blank"><img src="https://i.loli.net/2020/06/02/5e73k19YaBOXAGc.png" width = 400px  ></a>

### 4、路由与转发：

#### 路由算法：

网络层的核心功能是路由和转发，路由器需要**根据转发表**将一个到达的数据报成功的转发到一个输出接口上再把数据报发送出去，而转发表需要根据**路由算法**来计算路由信息并将这些信息存储，最后根据这些存储的路由信息将数据报转发。因此路由算法是网络核心中必不可少的功能。

##### 图：

在了解路由算法之前，我们先了解一下图的概念：

<a href="https://sm.ms/image/QbOSF7tZCXPdpiG" target="_blank"><img src="https://i.loli.net/2020/06/03/QbOSF7tZCXPdpiG.png" width = 400px  ></a>

图是由边和节点构成的拓扑结构。在路由算法中路由器会被抽象成图中的一个个节点，路由器之间的链路会被抽象成图中节点相连的各个边。

G = （N,E）

N = 路由集合 = {u,v,w,x,y,z}

E = 链路集合 = {(u,v),(u,x),(v,x),(v,w),(x,w),(x,y),(w,y),(w,z),(y,z)}

边上的权代表两路由器之间的链路的费用/代价（可以是指距离，也可以是贷款的倒数或拥塞程度，甚至可以是经济上的费用等。具体情况具体分析）

对于路径上的费用，一般都以越小越好的方式进行取值，因此在抽象图中关键问题就转化成了：**源到目的（如u到z）的最小费用路径是什么？**

**路由算法的目的**就是在一个抽象的网络图中去**寻找最小费用路径的算法**



##### 路由算法的分类方式：

- 是否动态？
  - 静态路由：
    - 静态路由算法由人工设置路由转发表
    - 路由表的更新，必须有人为干预
    - 路由器在跳转时首选人工方式，优先级更高
  - 动态路由：
    - 定期更新，根据动态路由算法动态更新转发表
    - 及时响应链路费用或网络拓扑变化
- 进行路由计算时是否需要掌握全局信息？
  - 基于全局信息：
    - 所有路由器需要掌握完整的网络拓扑和链路费用信息
    - **链路状态（LS）路由算法**是基于全局网络信息的代表算法
  - 基于分散信息：
    - 路由器只掌握物理相邻的邻居以及链路费用
    - 通过邻居路由器之间的信息交换和多次迭代计算以后来找到一个到达目的网络最佳的路由信息、
    - **距离向量（DV）路由算法**是基于分散网络信息的代表算法



#### 链路状态路由算法：

链路状态路由算法首先需要掌握整个网络拓扑以及链路费用，再利用<font color = "red">Dijkstra算法</font>(一种求最短路径的算法)来求最短路径。

**如何让所有节点（路由器）掌握整个网络拓扑和链路费用以及如何计算最短路径？**

1. 链路状态路由算法要求所有路由器都构造一个**链路状态分组**（包括与这个路由器相邻的所有结点的IP地址，以及与这个路由器相邻节点之间的链路费用，这些信息是可以通过探测的方式得到的）并将其**广播**出去（广播的方式类似于泛洪，该节点将信息转发到邻居，邻居再将信息转发给邻居的邻居，当然这样的一个过程会有一定的限制）；
2. 当所有的节点都收到了这个网络中所有节点扩散的链路状态分组，所有节点都能够通过这些链路状态分组来构造出来整个网络的完整拓扑以及费用信息（此时所有节点都拥有相同的信息）；
3. 当所有节点都拥有该网络完整的拓扑信息及链路信息之后，这些节点就可以利用Dijkstra算法来计算最短路径了；

##### Dijkstra算法：

符号：

- c(x,y)：表示节点x到节点y链路费用，如果x和y不直接连接，那么c(x,y) = ∞；
- D(v)：从源到目的v的当前路径费用值（这里的当前路径不一定是最短路径）；
- p(v)：沿从源到v的当前路径，v的前序节点；
- N'：已经找到最小费用路径节点的集合；

算法：

```
// 以节点u为例，该网络中其他节点与该节点是一样的
// 以下的过程都建立在该节点u己以获得了所处网络中的所有节点的拓扑信息及链路费用信息之后
初始化的过程：
N' = {u}   //开始时为最小费用路径节点的集合初始化，集合中只有该节点u
for 所有节点v	//遍历该网络中的所有节点
	if v毗邻u
		then D(v) = c(u,v)	//如果u与v相邻，目前u到v的费用暂定为u直接到v的费用
	else D(v) = ∞			//如果u与v不相邻，目前u到v的费用暂定为不可达，链路费用是无穷的
正式搜寻u到其他节点v的最短路径：
while 所有节点的集合减去N'后不为空
	找出不在N'中的w，并且满足D(w)最小 //找到某一没被加入到N'的节点w，并且w到u的距离在目前剩余节点中最短
	将w加入N'					 	//将这一节点加入到N'中
	更新w的所有不在N'中的邻居v的D(v): //由于新节点的加入，u就可以把新节点w当作跳板寻找与其他节点的更短的	D(v) = min(D(v),D(w)+c(w,v))   //距离，因此该算法能够保证每次加入到N'中的节点都是距离u最短的那个
```

<a href="https://sm.ms/image/IBJWzRepHhG8n15" target="_blank"><img src="https://i.loli.net/2020/06/03/IBJWzRepHhG8n15.png" width = 400px ></a>

如上图，就是Dijkstra算法过程，每当节点u使用Dijkstra算法将一个新的节点加入到N'后，u只需知道它是根据哪个节点（也可能是它本身）作为跳板最终以最短路径的方式到达目的节点的就好，最终u将这些信息记录在转发表上。

<a href="https://sm.ms/image/Hn4dsDFBaIx1GUk" target="_blank"><img src="https://i.loli.net/2020/06/03/Hn4dsDFBaIx1GUk.png" width = 400px ></a>

在链路状态路由算法中，可能存在**震荡问题**，因此需要考虑延迟更新转发表等措施来解决震荡问题。

#### 距离向量路由算法：

距离向量路由算法基于动态规划思想，在距离向量路由算法中我们规定**d<sub>x</sub>(y) = 从x到y最短路径的费用** ，         **c(x,y) = x到邻居v的费用**，那么<font color = "red">**d<sub>x</sub>(y) = min{c(x,v) + d<sub>v</sub>(y)}**</font>

**动态规划举例：**

<a href="https://sm.ms/image/AJpcX7ZFbou6Wax" target="_blank"><img src="https://i.loli.net/2020/06/04/AJpcX7ZFbou6Wax.png" width = 400px  ></a>

在某一规划的过程中我们已经知道了节点u的所有邻居到达节点z的最短距离d<sub>v</sub>(z) = 5,d<sub>x</sub>(z) = 3,d<sub>w</sub>(z) = 3,根据动态规划方程我们可以得知u到达z的最短距离应该为：d<sub>u</sub>(z) = min{c(u,v) + d<sub>v</sub>(z), c(u,x) + d<sub>x</sub>(z), c(u,w) + d<sub>w</sub>(z)} = 4。因此在动态规划的思想中，各个节点不需要知道整个网络拓扑结构，只需知道与其相邻节点的信息就可以了。

##### 距离向量路由算法的思想：

对于动态规划d<sub>x</sub>(y)，这样的最小费用的结果是要经过一次次迭代得出的，因此在迭代过程中我们只能对节点x到y的最小费用先进行估计，随着各个节点的迭代进行，估计值也会最终收敛于实际的最小值。

设**D<sub>x</sub>(y) = 从节点x到节点y的最小费用估计**

节点x需要知道到达每个邻居的费用c(x,v)，同时节点x需要维护其所有邻居的距离估计向量D<sub>v</sub> = [D<sub>v</sub>(y):y∈N]

每个节点不定时地将其自身的DV估计发送给邻居

当x接收到邻居道德新DV估计时，依据动态规划方程更新其自身的距离向量估计:D<sub>x</sub>(y) = min{c(x,y) + D<sub>v</sub>(y)}

当x更新完毕后再告知邻居，邻居再进行DV更新

最终通过这样的迭代过程D<sub>x</sub>(y)会收敛于实际的最小费用d<sub>x</sub>(y)

##### 因此对于距离向量路由算法中的每个节点的迭代过程可以简单描述为：

- 等待过程
- 如果本地局部链路费用有变化或收到邻居的DV更新
- 重新计算DV估计
- 如果DV中到达任一目的距离发生改变，通告所有邻居
- 依此类推，多次迭代

<a href="https://sm.ms/image/qz9SGA6NVrKmPtl" target="_blank"><img src="https://i.loli.net/2020/06/04/qz9SGA6NVrKmPtl.png" width = 500px  ></a>

距离向量路由算法可能会出现**无穷计数问题**（和链路状态路由算法的震荡相似，发送的报文会在网络中的路由器之间反复横跳，进入一个死循环("乒乓环路")），因此其中一个解决办法是定义一个**最大度量**，当从某一结点到另一结点之间允许的最大跳步数，如果跳步数小于最大度量值就认为是有效可达的，否则认为是不可达的。



#### 层次路由：

对于上面两种路由算法在小规模的网络中是可行的，但对于像Internet这样庞大的网络，各个路由节点将其抽象成一张图就过于理想化了，因此仅仅包含这样简单的算法在实际的网络中显然是不可行的，由此我们需要为网络中的路由分层。

**层次化路由**将一个区域内或一个组织内的路由器聚合为一个区域（称为**自治系统**AS，在同样一个AS区域内的路由可以运行相同的路由协议（算法），不同自治系统内的路由器也可以运行不同的AS内部路由协议），不同的自治系统的连接要通过**网关路由器**（位于自治系统“边缘”，通过链路连接其他自治系统的网关路由器，网关路由器不仅要知道自治系统内部的路由算法也需要自治系统之间的路由算法）。当一个数据报要跨越自治系统才能送达目的地时，这一送达过程要通过AS内部路由算法和AS间路由算法共同决定。

<a href="https://sm.ms/image/ZzUfvkhyB2KQSi7" target="_blank"><img src="https://i.loli.net/2020/06/04/ZzUfvkhyB2KQSi7.png" width = 400px  ></a>

以AS1为例，AS1中的某路由器为了将数据报送往AS1之外的目的网络，AS1必须：

- 学习到哪些目的网络可以通过AS2到达，哪些可以通过AS3到达
- 将这些网络可达性信息传播给AS1内部路由器

<a href="https://sm.ms/image/eQlI96k82BxsCtq" target="_blank"><img src="https://i.loli.net/2020/06/04/eQlI96k82BxsCtq.png" width = 400px  ></a>

##### 例：

以上图为例，假设AS1通过AS间路由协议学习到：子网x可以通过AS3（网关1c）到达，但**不能通过AS2的到达**。那么这样一条关于子网x要通过网关路由1c到达的信息会通过AS间路由协议告知AS1中所有内部路由器。当AS1中的1d想要将一个报文传输给子网x，1d知道要将该报文传输给网关路由1c。1d传给1c的过程就由AS1内部的路由算法来决定如何传输，1c收到报文后再转给AS3的网关路由3a。一直重复这个过程，直到该报文最终被送达子网x。

如果AS1学习到子网x不但可以由AS3（网关1c）到达，也可以由AS2（网关1b）到达，那么目前纠结于将报文发送给1c还是1d的路由器就会遵循一种**“热土豆路由”**的方式**将该分组发送给最新的网关路由器**。

**如图为热土豆路由：**

<a href="https://sm.ms/image/beqPVs24LExwAua" target="_blank"><img src="https://i.loli.net/2020/06/04/beqPVs24LExwAua.png" width = 500px  ></a>



#### RIP(路由信息)协议：

RIP(Routing Information Protocol)协议是Internet网络中AS内部路由协议(也被称为IGP)中的一种，使用**距离向量路由算法**来计算到达目的地的最佳路线。

**RIP中的距离向量路由算法：**

- 距离度量：跳步数（max = 15 hops，设置的最大度量为15个跳步，目的是为避免无穷技术问题，但是同样也限制了使用RIP协议的AS的规模），每条链路为1个跳步

- 每隔30秒，邻居之间交换一次DV，成为通告

- 如果180秒没有收到通告就认为邻居链路失效了，此时经过该邻居的路由都不可用，需要重新计算路由并向其他邻居发送新的通告，邻居收到通告后再依次向外发送通告（如果邻居的转发表改变就通告，否则不用通告）

- 每次通告最多包含25个目的子网（IP地址形式）

  如下图为RIP的示例

  <a href="https://sm.ms/image/g6fP5zWxmGAlQKX" target="_blank"><img src="https://i.loli.net/2020/06/04/g6fP5zWxmGAlQKX.png" width = 400px  ></a>

**RIP路由表的处理：**

- RIP路由表是利用一个称作route-d（daemon）的<font color = "green">应用层</font>进程进行管理

  - **在网络层次划分中，各层次是按照功能进行划分的**，路由表属于网络层的功能，这和路由表是由应用层产生和维护的没有关系，路由器中同样可以包含TCP/UDP等传输层的协议，但这些协议都只是为了完成网络层的功能而已

- 通告报文周期性地通过UDP数据报发送

  <a href="https://sm.ms/image/cjfvXFd8Dk6CJIx" target="_blank"><img src="https://i.loli.net/2020/06/04/cjfvXFd8Dk6CJIx.png" width = 400px  ></a>



#### OSPF(开放最短路径优先)协议：

OSPF(Open Shortest Path First)协议是Internet网络中AS内部路由协议)中的一种，采用**链路状态路由算法**来计算到达目的地的最佳路线。OSPF协议可以看做为RIP协议的改进，相比RIP协议，OSPF有很多的优点。

**OSPF中的链路状态路由算法：**

- OSPF通告（链路状态分组）在整个AS范围内泛洪
  - OSPF的通告是直接封装到IP数据报中的，这与RIP不同（RIP要先将报文封装到UDP中）
- 每个路由器构造完整的网络(AS范围内)拓扑图
- 利用Dijkstra算法计算路由

**OSPF相比RIP的优点：**

- 具有安全性：所有的OSPF报文都可以被认证(预防恶意入侵，构造虚假的链路状态分组)

- OSPF允许使用多条相同费用的路径，可以实现负载/流量的均衡，而RIP只能选择一条

- 对于每条链路，可以针对不同的**服务类型**来设置多个不同的费用度量以实现不同数据类型分组的分流

- 集成单播路由与多播路由，两种路由都可以使用相同的网络拓扑数据

- OSPF支持对**大规模AS分层路由**，对AS再次进行分层(局部区和主干区)。这种分层思想与分层路由的思想是相同的，每个区域以内的路由器只需要掌握所在区的详细拓扑，且只需知道去往其他区网络的“方向”（最短路径）就可以了，如下图：

  - 标为1的路由器：**局部区内路由器**只需要掌握所在区的详细拓扑，且只需知道去往其他区网络的“方向”

  - 标为2的路由器：**区边界路由器**(Area Border Routers)既可以与所在区的区内路由器进行交换链路状态分组并构造所在区的网络拓扑，也可以在主干区内进行网络拓扑并计算如何到达主干区内的其他路由，因此去边界路由器具有两重身份

  - 标为3的路由器：**主干路由器**(Backbone Routers)和局部区的内部路由器功能一样，只是它在主干区进行网络拓扑

  - 标为4的路由器：**AS边界路由器**(AS boundary routers)与区边界路由器职责相同，负责连接其他AS，并且对主干区内的路由进行拓扑

    <a href="https://sm.ms/image/ilIaD6WLc9jNd2Y" target="_blank"><img src="https://i.loli.net/2020/06/04/ilIaD6WLc9jNd2Y.png" width = 400px  ></a>



#### BGP(边界网关)协议简介：

BGP(Border Gateway Protocol)是Internet中AS间路由协议的一种，BGP目前已经成为了事实上的标准域间路由协议，它是将Internet“粘合”为一个整体的关键。BGP为每个AS提供了一种手段：**eBGP**（从邻居AS获取子网可达性信息）、**iBGP**（向所有AS内部路由器传播子网可达性信息），基于可达性信息和策略，各个路由器确定到达其他网络的“好”路径。

#### BGP基础：

BGP协议的工作过程都是通过在路由器之间交换一些**BGP报文**来完成的，在两个路由器之间建立连接以后交换报文的过程被称为**BGP会话**。BGP会话中报文交换是基于**半永久TCP连接**(连接建立后很长的时间都不拆除)的，换言之BGP会话是由应用进程实现的。

**BGP报文：**对等路由之间通过交换报文来实现相互通告去往不同目的**前缀**(这里的前缀就是代表IP子网，如CIDR就是利用前缀来代表某一个子网的)的**路径**(到达目的网络的自治系统的完整路径)

- OPEN：与对等路由器(peer)建立TCP连接，并认证发送方
- UPDATE：通告新路径（或撤销原路径），通告可达子网前缀并会在通告中**聚合**(CIDR中讲过)网络前缀
- KEEPALIVE：在无UPDATE时，保活连接；也用于对OPEN请求的确认
- NOTIFICATION：报告先前报文的差错；也用于关闭连接，终止BGP会话

**BGP通告过程：**



<a href="https://sm.ms/image/Yy578boxM49BSzA" target="_blank"><img src="https://i.loli.net/2020/06/04/Yy578boxM49BSzA.png" width = 400px  ></a>

1. 在3a与1c之间，AS3利用eBGP会话向AS1中的网关路由器1c发送前缀可达性信息
2. 1c利用iBGP向AS1内的所有路由器分发新的前缀可达性信息
3. 1b可以（也可能不会）进一步通过1b到2a的eBGP会话，向AS2通告新的可达性信息
4. 当路由器获得新的前缀可达性时，即在其转发表中增加关于该前缀的入口(路由项)

**BGP协议所分发的路径信息包含的内容：**

- 通告的前缀信息
- BGP的一些属性，这里举出两个重要的属性：
  - AS-PATH(AS属性)：包含前缀通告所经过的AS序列，如：AS67,AS17,...
  - NEXT-HOP(下一跳)：开始一个AS-PATH的路由器接口，指向下一跳  AS

<a href="https://sm.ms/image/s7QStPwpB2ogVEN" target="_blank"><img src="https://i.loli.net/2020/06/04/s7QStPwpB2ogVEN.png" width = 400px ></a>



**基于策略路由：**当某一个AS的网关路由接受到对端的AS网关路由发送的通告后，该网关路由会根据其**输入策略**决策接受/拒绝该路由(比如通告的某些途径经过的自治系统是该自治系统不希望接触的)。同时路由器可能获知到达某目的AS的多条路由，它会基于以下准则选择：

- **本地偏好值属性**：在BGP协议中，会人为的为某些AS路径设置一些不同的偏好值，这个偏好值越大就代表首选，越小就代表次选
- 如果没有偏好值或偏好值相同，会首选**最短**路径(AS-PATH的数目)。发送数据报的过程中所经过的自治系统越少越好
- **最近**NEXT-HOP（下一跳）路由器：根据热土豆路由原则
- 也可以根据实际情况附加一些其它的准则

## <a name="第五章">第五章：数据链路层</a>

### 1、数据链路层概述：

**数据链路层**负责通过一条链路从一个**节点**(主机和路由器在链路层中统称为节点)向另一个物理链路相邻节点传送数据报(这些网络层数据报被封装到链路层中的**帧**中)。

**链路层要服务的内容：**

- 组帧(framing)：
  - 链路层要将上传的IP数据报构成**数据帧**，加首部(包含链路层的一些信息)与尾部(差错编码的一些信息)
  - 实现**帧同步**。由于数据链路层的数据帧在物理层上传输方式为一系列的比特，一个节点发送这样的一系列比特，另一个接收节点要能够识别出来一个个数据帧。通常链路层要在组帧以后要在帧的**首位加上帧定界符**(可以是特殊字符，也可以是特殊的比特串)
- 链路接入(link access)：
  - 如果物理链路是共享介质，需要解决信道接入，防止多个节点同时接入造成相互的干扰
  - 解决链路层的寻址，帧首部中的"MAC"地址(也叫物理地址)，用于标识帧的源和目的
    - 和IP地址不同，IP地址是网络层上的，而MAC地址是物理层面上的
- 相邻节点可靠交付：
  - 在传输层中的一些协议(如TCP)都能够保证数据的可靠传输，但有时链路层也要实现数据的可靠传输，具体要根据传输的介质决定
- 相邻节点间的流量控制：
  - 协调相邻的发送节点和接收节点
- 差错检测：
  - 信号衰减和噪声引起的差错
  - 接收端检测到差错会通知发送端重传或直接丢弃帧率(根据是否是可靠性链路传输)
- 差错纠正：
  - 有些链路层协议支持在接收端直接纠正比特差错
- 控制链路上的通信方式：
  - 全双工：链路两端节点同时双向传输
  - 半双工：链路两端节点交替双向传输



**链路层通信：**链路层在“适配器”（即网络接口卡-NIC）中实现，网卡由硬件、软件与固件组成。因此链路层通信即网卡间通信。

- 发送端：将数据封装成帧，增加差错检测比特，实现可靠数据传输和流量控制等

- 接收端：对数据进行差错检测，实现可靠数据传输和流量控制并提取数据报，交付上层协议实体

  <a href="https://sm.ms/image/3l75utMTcrXjpFo" target="_blank"><img src="https://i.loli.net/2020/06/05/3l75utMTcrXjpFo.png" width = 500px  ></a>



### 2、数据链路层次链路层服务：

#### 链路层差错编码：

在数据链路层提供服务中，一个重要的服务是在数据链路层实现差错的检测，甚至是进行差错的纠正。差错检测与差错纠正的重要基础就是要实现差错编码。

**差错编码的基本原理：**

差错编码的基本原理就是在数据基础上增加一些冗余信息，这个冗余信息建立起位与位(比特与比特)之间原本不存在的关联关系，作为编码的结果我们将冗余与数据信息一起发送给接收端，接收端收到以后去判断这样的关联关系是否存在。

<a href="https://sm.ms/image/phZ9CHo7fv4Dcnq" target="_blank"><img src="https://i.loli.net/2020/06/05/phZ9CHo7fv4Dcnq.png" width = 400px  ></a>

如上图，发送段对上传来的数据D按照某种算法/映射对数据D进行处理后得出冗余比特R，通常会将得到的冗余比特附着到数据D后面，这样的DR传输到接收端后，接收端再利用与发送端相同的算法/映射来检测D和R是否还存在关系，如果这样的关系仍然存在就认为是没有差错的，否则会针对出现差错的数据进行一些相应的策略。但<font color = "red">即使D和R的关系存在也不能就完全表明数据是完全正确没有差错的</font>。

**差错编码的检错能力：**差错编码可分为<font color = "red">检错码</font>和<font color = "red">纠错码</font>

​	汉明距离：两个码不同的数的个数，如1010和1001共有两位不同，因此它俩的汉明距离为2

​	编码集的汉明距离：一个编码集中任意两个码相组合，这个组合中最小的汉明距离就为编码集的汉明距离

- 检错码：对于检错码，如果编码集的汉明距离d<sub>s</sub>=r+1,则该差错编码可以检测r位的差错
  - 原因很简单，在这个编码集中任意两个码字之间的汉明距离(不同位数)一定是大于等于r+1的，如果有一个码字出现差错且这个差错的位数是为r的，那么该差错码字与编码集中的其他所有码字的都必定有大于等于1位的不同，因此该差错编码不可能错成其他编码，也就可以被检测出来了。
  - 例如，编码集{0000,0101,1010,1111}的汉明距离为2，可以100%的检查出1比特的差错
- 纠错码：对于纠错码，如果编码集的汉明距离d<sub>s</sub>=2r+1,则该差错编码可以纠正r位的差错
  - 原因同样很好理解，在该编码集中，任意两个码字之间的汉明距离一定是大于等于2r+1的，当某一编码出现了r位的差错，那么该差错编码与编码集中除原编码以外的汉明距离一定大于等于r+1，而与原编码的汉明距离为r，因此按照概率最大化的原则该出错编码会被纠正成原编码(因此概率纠正会出现错误)。因此纠错码的原则是将一个无效的码字纠正位距离它最近的有效码字。
  - 例如，编码集{000000,010101,101010,111111}的汉明距离为3，可以纠正一位比特差错，如100010纠正为101010。 

**奇偶校验码：**奇偶校验码中最常见的就是1比特奇偶校验，在要检查数据之后加上一位比特校验位。如果是奇校验就在校验位填0或1让编码后的数据加上校验码的1的个数为奇数个，如果为偶校验就在校验位填0或1让编码后的数据加上校验码的1的个数为偶数个。例如1100010增加偶校验后为11000101，如果接收方收到的字节奇偶校验结果不正确，就可以知道传输中发生了错误，但源码**必须错了奇数个比特位**，才能校验出来，否则不能(如果错了偶数个，判断结果仍然还是满足偶校验，这样就检查不出来了)。

**Internet校验合(Checksum):**该处在UDP校验合一节有完整的的叙述。

**循环冗余(CRC)：**循环冗余校验的方式广泛应用于实际网络，它是一种检错能力非常强大的差错编码，其原理为：

- 将数据比特，D，视为一个二进制数

- 选择一个r+1位的比特模式G(生成比特模式)

- 发送端选择r位的CRC比特，R满足：

  - <D,R>刚好可以被G整除(模2除)，等同于D左移r位后与R进行异或，这样的数值要等于n倍的G                                     **D\*2<sup>r</sup> XOR R = nG**

  - 上面公式等同于**D\*2<sup>r</sup>  = nG XOR R**，再次变形等同于<font color = "red">**R = 余式[D\*2<sup>r</sup>/G]**</font>

    如：

    <a href="https://sm.ms/image/wHymL76ZA1otnlu" target="_blank"><img src="https://i.loli.net/2020/06/06/wHymL76ZA1otnlu.png" width = 300px  ></a>

- 接收端检错，利用接收到的<D,R>去除G(模2除)，如果余式全为0，无错误；否则，有错！

- CRC编码只要能够找到一个优良的比特模式G，它的检错能力将会是非常强大的，可以检测所有突发长度小于r+1位的差错。



#### 多路访问控制(MAC)协议：

在网络链路中，共分为两类“链路”，一种为点对点链路(拨号接入的PPP，以太网交换机与主机间的点对点链路，一种独享的链路)，另一种是**广播链路**（早期的总线以太网，802.11无线局域网，共享介质实现的共享链路）。而在广播链路中，如果对连入的节点不加以控制的话，多个连入节点同时传输数据，这些属于不同节点的数据信号就会在共享链路上产生**冲突**，这些冲突就会导致接收节点同时接收到多个信号，最终导致传输失败。因此多路访问控制协议为广播链路提供一种协调来控制与其连接的网络设备(谁在什么时候什么情况下能够使用这种介质)，让这些节点能够在共享介质中传播数据并且互不干扰。

##### MAC协议分类：

- 信道划分MAC协议：
  - **使用多路复用技术**，将信道资源划分成各个资源片分配给不同节点去使用，各个节点在通信过程中只占用自己的通信资源
  - TDMA,FDMA,CDMA,WDMA**(在第一章有介绍)**等
- 随机访问MAC协议：
  - 信道不划分，任意节点要传输就可以使用该信道的全部带宽，由于任意节点随时都可能占用信道，因此会产生冲突
  - 由于信道中会产生冲突，因此要采用冲突的“恢复”机制(各节点要通过一种机制来判断出自己发送的数据是否产生了冲突，如果产生了冲突就要对冲突的数据重新发送)
  - 典型的随机访问MAC协议：
    - 时隙ALOHA、ALOHA、CSMA、CSMA/CD(应用于以太网)、CSMA/CA(应用于802.11无线局域网)
- 轮转MAC协议：
  - 节点轮流使用信道，为各个节点划分使用信道时间片段避免冲突，且每次节点要使用信道时仍能够使用信道的全部带宽
  - 主节点轮询、令牌环网(应用于蓝牙)



#### 随机访问MAC协议：

当节点要发送分组时会利用信道全部速率R发送分组，且各个节点没有实现的协调，当两个或多个节点同时传输数据时会产生冲突，因此随机访问MAC协议要具有**冲突检测机制**，当检测到冲突后应该具备能够将冲突的影响化解的机制(最简单的机制就是检测到冲突后，推迟一段时间后再重复发送刚刚冲突的数据帧)。

**时隙ALOHA协议：**

时隙ALOHA协议中有如下规定：

- 所有帧大小相同

- 事件被划分为等长的时隙(每个时隙中可以传输1个帧)

- 节点只能在时隙开始时刻发送帧

- 节点间时钟同步

- 如果2个或2个以上节点再同一时刻发送帧，节点即检测到冲突

- 当节点有新的帧时，会再下一个时隙发送

  - 如果节点在发送帧时没有检测到冲突，那么该节点可以在下一个时隙继续发送新的帧

  - 如果节点在发送帧时检测到了冲突，那么该节点在下一个时隙以概率P重传该帧，直至成功

    <a href="https://sm.ms/image/jMLiVaUsywPfHgq" target="_blank"><img src="https://i.loli.net/2020/06/06/jMLiVaUsywPfHgq.png" width = 400px  ></a>

优点：

- 单个节点活动时，可以连续以信道全部速率传输数据
- 高度分散，只需要同步间隙
- 实现方式简单

缺点：

- 当出现冲突时，冲突的时隙就被浪费掉了
- 各个节点由于按照概率来重发帧，会造成很多空闲时隙
- 各个节点也许能够以远小于分组传输时间来检测冲突，如果能够提前检测到冲突，那么后续的发送帧也就没有意义了，时隙ALOHA协议没有一个能够终止后续传输的机制
- 所有节点必须要时钟同步
- 信道利用率低



**ALOHA协议：**

ALOHA协议也被称为非时隙ALOHA协议，该协议对时隙不进行划分，各个节点之间也无需进行时钟同步。当有新的帧生成时，ALOHA协议规定节点立刻将构成的帧发送出去。也正因这样的无时隙划分与随时立刻传输帧，使得ALOHA协议的冲突可能性比时隙ALOHA协议还要大，信道利用率更低。

<a href="https://sm.ms/image/GoQ79Is8ULPAB2x" target="_blank"><img src="https://i.loli.net/2020/06/06/GoQ79Is8ULPAB2x.png" width = 400px  ></a>



**CSMA协议：**

CSMA(carrier sense multiple access 载波监听多路访问)协议，它是对ALOHA协议的改进。ALOHA协议中，各个节点常常因为不能够提前检测到信道冲突并终止传输，使得在发生冲突的某一段时间中信道完全不能被利用。而CSMA协议规定发送帧之前，监听信道是否空闲，并根据监听的结果选择是否发送数据。

CSMA协议中有如下规定：

- 在发送节点发送帧之前，监听信道
  - 如果信道空闲，发送节点立刻发送完整帧
  - 如果信道忙，根据不同的策略选择推迟一段时间后再进行发送帧
    - 1-坚持CSMA：一直监听信道，一旦发现信道空闲，立刻发送数据帧
    - 非坚持CSMA：随机等待一段时间后再监听信道，如果信道空闲，立刻发送数据帧
    - P-坚持CSMA：以概率P监听信道，以概率1-P随机等待一段时间后再监听信道，如果信道空闲，立刻发送数据帧

即便如此，CSMA协议仍然会造成信道的冲突：

- A,B两节点同时在检测信道，信道一旦空闲，两节点同时发送数据

- 信号的传输有延迟，某一结点发送的数据信号已在信道中传输了，但是由于信道传输的速度问题，该信号还没有到达另一结点，另一结点也就没法监听到该信道是有数据信号的，另一结点要发送数据就会产生冲突

  如：

  <a href="https://sm.ms/image/pMzN2RSUJsEyVog" target="_blank"><img src="https://i.loli.net/2020/06/06/pMzN2RSUJsEyVog.png" width = 300px  ></a>

  在t1时刻，B发送的信号没有到达D，此时D无法监听到B的信号，因此D认为信道是空闲的并发送了D的数据，就这样B和D的数据信号叠加在了一起造成了信道资源的浪费。此时就需要有某种机制，让B和D发送数据的同时也能够进行监听，当D与B发现自己的信号被叠加了，两种都应该立刻停止继续发送数据，拥有这样机制的协议就是下面要介绍的CSMA/CD协议。



**CSMA/CD协议：**

带有冲突检测(Collision Detection)的CSMA协议，它与CSMA协议的最大不同之处就是CSMA/CD协议能够边发送数据边检测冲突，而不发送数据就不进行监听冲突（“先听后发，变法边听，冲突不发”），一旦发现了冲突后续数据传输中止，减少信道资源的浪费。

<a href="https://sm.ms/image/9WQhpYlODrqPS62" target="_blank"><img src="https://i.loli.net/2020/06/06/9WQhpYlODrqPS62.png" width = 300px ></a>

这种边发送边检测冲突的机制在有线局域网中易于实现(通过检测信号强度，比较发射信号与接收信号)，但在无线局域网中却很难实现(接收信号强度会淹没在本地发射信号强度下)。

CSMA/CD的特点就是**“先听后发，变法边听，冲突不发”**，因此如果在同一信道的两个节点如果相距太远且数据帧太短，节点A与节点B同时发送数据，节点A发送完毕后停止监听(此时节点B的信号已经发送出来但是还未到达节点A)，但之后节点A的信号将会与节点B的信号冲突，这样节点A的数据将会被破坏，并且节点A因为不知道数据被破坏也就不可能重传。因此我们必须保证在任何情况下，只要节点在发送数据的过程之中，它就一定能够在发送数据的过程时间中监听到任意其他节点的冲突，而这就意味着我们需要**保证节点发送数据帧的长度的最小值**。

设L为数据帧的最小长度，R为网络带宽，V为信号传播的速度，d为该信道上相距最远的两节点的距离：

**L/R  >= 2d<sub>max</sub>/v**

CSMA/CD的信号利用率比ALOHA协议的信道利用率高很多。

#### 轮转访问MAC协议：

对于信号划分MAC协议，当网络负载重时，共享信道效率高，且公平，而网络负载轻时，共享信道效率低。对于随机访问MAC协议，当网络负载轻时，共享信道效率高，单个节点可以利用信道的全部带宽，但当网络负载重时，会产生冲突开销。轮转访问MAC协议能够综合两者的优点。

**轮询方式方式实现：**

规定一个主节点，主节点轮流“邀请”从属节点发送数据，如果从属节点没有收到“邀请”就不能发送数据，如果从属节点本身就没有数据要发送也不发送数据，这种轮询的方式可以避免冲突的发生。

轮询的问题：主节点对从属节点进行轮询时要进行一定的开销，并且各个从属节点如果要发送数据必须要等待轮询到它才能发送数据，这就会有一定的延迟。如果主节点宕机，那么整个链路都不能够使用。

**令牌传递方式实现：**

网络中有且只有一个令牌，该令牌代表共享介质的使用权，本质上是一种特殊帧，令牌依次从一个节点传递到下一个节点。在令牌网络中，通常各个节点会构成一个环形网络，如果节点发送完数据或不需要发送数据时就将数据还给该网络，如果某一结点有数据要发送就会捕获该令牌并发送数据。

令牌传递的问题：令牌本身会产生一定的开销，各个节点想要发送数据数据必须要等待令牌的获取，如果某一持有令牌的节点宕掉了不能够归还令牌，整个链路上的节点都不能够发送数据（对于令牌的丢失也可以有相应的解决办法，如该链路中有一定时间没有出现过令牌且该链路上也没有数据在传输，那么就可以再制造一个令牌）。



#### ARP(地址解析)协议：

**MAC地址：**

MAC地址用于局域网内标识一个帧从哪个接口发出，到达哪个物理相连的其他接口。MAC地址为48比特长度，固化在网卡的ROM中(每一块网卡中的MAC地址都是唯一的，一个局域网内不允许出现两块MAC地址相同的网卡)，有时也可以通过软件设置。MAC地址对长度进行了划分，共6个字节，每个字节用十六进制书写，各个字节由“-”进行连接，如：1A-2F-BB-76-01-AD。

<a href="https://sm.ms/image/ZjQNpGyLbBwoHck" target="_blank"><img src="https://i.loli.net/2020/06/06/ZjQNpGyLbBwoHck.png" width = 500px  ></a>

MAC地址由IEEE统一管理和分配，网卡厂商要在IEEE购买MAC地址空间(前24比特)，后24个比特由网卡厂商生产网卡时依次进行编号，这就保证了在全球的任意地方购买的正规网卡的MAC地址都是不一样的。

MAC地址与IP地址的差别可以类比成现实中的身份证号和邮政地址(含有层次和归属关系)，因此MAC地址是一种“平面”地址，在这个平面上任意的两个MAC地址是不同的，并且是可以携带到任意地区的，而IP地址是层次关系，IP地址依赖于节点连接到哪个子网，然后才是子网中对应的哪个接口。并且IP地址是关于IP数据报的，而MAC地址是关于数据帧的。





**ARP表：**结点间相互访问需要知道对方的IP地址，将IP数据报封装好后送到链路层封装成帧，而数据帧的发送与接收需要的是MAC地址。因此为了得到IP地址与MAC地址的映射关系，各个结点都需要维护这样一个存储了IP地址与MAC地址映射关系的表<IP地址；MAC地址；TTL>，其中TTL代表这个映射关系生效的时间。

<a href="https://sm.ms/image/vKVEFWMJstbGI68" target="_blank"><img src="https://i.loli.net/2020/06/06/vKVEFWMJstbGI68.png" width = 500px  ></a>



同一局域网内的ARP协议工作流程：

1. A想要给同一局域网内的B发送数据报
   - 此时B的MAC地址不再A的ARP表中
2. A广播ARP查询分组，其中包含B的IP地址
   - 在局域网内的所有结点都会接收到这样的ARP查询
3. B接收到了ARP查询，IP地址匹配相同，利用单播帧率向A进行应答，表明自己的MAC地址
4. A在其ARP表中，缓存接收到B的IP-MAC地址对，直至超时
   - 如果超时了，就再次刷新



在不同局域网内的ARP协议工作流程：

1. A构造数据报，其中源IP地址是A的IP地址，目的IP地址是B的IP地址
2. A构造链路层，其中源MAC地址是A的MAC地址，目的MAC地址是R(左)接口的MAC地址，封装A到B的IP数据报
3. 帧从A发送至R
4. R接收帧，提取IP数据报，传递给上传IP协议
5. R转发IP数据报
6. R创建链路层帧，其中源MAC地址是R(右)接口的MAC地址，目的MAC地址是B的MAC地址，封装A到B的IP数据报
7. 帧从R发送到B

<a href="https://sm.ms/image/ZOLWFDg4dVaKb6U" target="_blank"><img src="https://i.loli.net/2020/06/06/ZOLWFDg4dVaKb6U.png" width = 500px  ></a>



### 3、局域网：

#### 以太网：

以太网是全球使用最广泛的局域网技术。以太网有着造价低廉、能够满足网络速率需求，因此成为了应用最广泛的局域网技术。以太网在最初设计时，通过一个共享的广播介质来连接局域网中所有的结点，最初共享的介质被称为以太，也因此被称为以太网。

以下是早期的以太网草图：

<a href="https://sm.ms/image/zYOuf6AIGd7jWSX" target="_blank"><img src="https://i.loli.net/2020/06/07/zYOuf6AIGd7jWSX.png" width = 500px  ></a>

局域网中的每一个节点通过一个触头与共享介质进行接触，通过收发器(TRANSCEWER)实现了在介质上发送和接收信号，收发器又通过接口电缆连接网络接收卡，网络接收卡再通过总线与主机相连接。

**以太网具有以下特点：**

- 无连接：发送帧的网卡与接收帧的网卡间没有“握手”的过程(请不要将TCP中的可靠数据传输与这里搞混了)
- 不可靠：接受网卡不向发送网卡进行确认
  - 差错帧直接丢弃，丢弃帧中的数据恢复依靠高层协议(比如TCP)，否则，发生数据丢失
- 以太网使用的MAC协议：采用**二进制指数退避算法的CSMA/CD**（连续冲突次数越多，平均等待时间越长）
  - 以太网CSMA/CD算法：
    - 以太网网卡(NIC)从网络层接收数据报，创建数据帧
    - NIC监听信道
      - 如果NIC监听到信道空闲，则开始发送数据帧
      - 如果NIC监听到信道忙，则一直等待到信道空闲再发送数据帧
    - NIC发送完整个帧，并且在发送的过程中没有检测到冲突，则NIC确认数据发送成功
    - 如果NIC检测到其他节点传输数据(冲突)，则中止发送，并发送堵塞信号(让网络中的冲突更明显，让其他结点都及时发现冲突)
      - 中止发送后，NIC进入二进制指数退避
        - 假如这是第m次冲突，取n = Min(m,10)
          - NIC从{0,1,2,...,2<sup>n</sup>-1}中随机选择一个数K
          - NIC等待K\*512比特道德传输延迟时间，再返回监听信道的步骤
        - 假如冲突的次数太多，一般是第16次冲突为忍耐极限，NIC就不再尝试发送数据了，直接向上层汇报错误

**以太网的物理拓扑结构：**

- 总线(bus)：这种结构目前已经基本淘汰了，各个结点直接连在同一根共享广播介质中(同轴电缆)
  - 所有节点在同一**冲突域**(任意两个结点同时发送数据就会产生冲突的网络范围就称为冲突域，因此以太网为了解决冲突使用的MAC协议为CSMA/CD协议)
  - 也被称为共享式以太网、广播式以太网
- 星型：目前主流的网络拓扑，利用交换机去连接各个结点构成星型拓扑结构
  - 中心设备为交换机，因此也被称为交换式以太网
  - 每个冲突域中只有一个结点，结点间彼此不冲突

<a href="https://sm.ms/image/pEkTqD9yzvI4Oeb" target="_blank"><img src="https://i.loli.net/2020/06/07/pEkTqD9yzvI4Oeb.png" width = 500px  ></a>

**以太网帧结构：**

<a href="https://sm.ms/image/4kj8Qg2N7OaTD1l" target="_blank"><img src="https://i.loli.net/2020/06/07/4kj8Qg2N7OaTD1l.png" width = 500px  ></a>

- 前导码(Preamble)：占八个字节，前七个字节全部为10101010，第八个字节则为10101011
  - 作用是用于发送网卡和接受网卡的时钟同步的，当比特流变为10101011就代表要发送数据了
- 目的MAC地址、源MAC地址：各占6个字节
  - 如果网卡的MAC地址与收到的帧的目的MAC地址匹配，或者帧的目的MAC地址为广播地址(FF-FF-FF-FF-FF-FF),则网卡**接受**该帧，并将其封装的网络层分组交给相应的网络层协议
  - 否则，网卡**丢弃**(不接受)该帧率
- 类型(Type)：占两个字节，指示帧中封装的是哪种高层协议的分组(如，IP数据报、Novell IPX数据报、AppleTalk数据报等)
- 数据(Data)：46字节到1500字节，如果发送的数据小于46字节(为什么必须大于46字节？请参考CSMA/CD协议)，那么必须进行填充
  - R=10Mbps，RTT<sub>max</sub>=512μs，L<sub>min</sub>/R = RTT<sub>max</sub>
  - L<sub>min</sub> = 512bits = 64B, Data<sub>min</sub> = L<sub>min</sub> - 18 = **46**B
- CRC(4B)：循环冗余校验码
  - 丢弃差错帧

#### 交换机(以太网交换机)：

交换机是一种链路层设备，交换机通过校验收到帧的目的MAC地址，使用CSMA/CD协议有选择性的向一个或等多个输出链路转发帧(交换机的主要功能：**存储和转发**)。交换机一般对各个主机而言是**透明**的，各个主机往往感知不到交换机的存在，由此作为标准的链路层交换机往往都是可以**即插即用**的，并通过**自学习**来实现转发功能，不需要提前配置。

<a href="https://sm.ms/image/ZIBPhWGotzLMYey" target="_blank"><img src="https://i.loli.net/2020/06/07/ZIBPhWGotzLMYey.png" width = 200px  ></a>

**交换机的特点与功能：**

- 多端口间同时传输

  - 主机利用独享链路直接连接交换机
  - 交换机缓存帧
  - 交换机在每段链路上利用CSMA/CD收发帧，但无冲突，且可以全双工
  - 可以并行传输A到A‘与B到B’的传输可以同时进行，没有冲突

- 自学习

  - 每个交换机都会维护一个**交换表**，交换机通过交换表得知通过自身的哪个接口能够到达哪台主机
    - 该交换表中记录着(连接交换机的主机MAC地址，到达主机的接口号，生效生命周期)，如（A，1，60）
  - 交换机通过自学习，获知到达主机的接口信息
    - 当收到帧时，交换机“学习”到发送帧的主机（通过帧的源MAC地址），位于收到该帧的接口所连接的局域网网段
    - 将发送主机MAC地址/接口信息记录到交换表中
    - 如，主机A向A‘发送数据，目的MAC地址为A'，源MAC地址为A，此时主机A连接交换机的接口1，交换机收到该数据后，在交换表中记录帧的源MAC地址A与输入链路接口1(如(A,1,60)。

- 帧过滤/转发

  - 当交换机收到帧时：

    - 记录帧的源MAC地址与输入链路接口（自学习）

    - 利用目的MAC地址检索交换表

    - if 在交换表中检索到与目的MAC地址匹配的入口

      then{

      ​	if 目的主机位于收到帧的网段(接口)

      ​	then 丢弃帧

      ​	else 将帧转发到该入口指向的接口

      }

      else 泛洪转发，向除收到该帧接口以外的所有接口转发

**交换机互联：**

由于接口数量的限制或网络连接距离的需要，我们需要对网络进行扩展，最典型的扩展就是由多交换机互联以后构成一个更大范围的局域网，这种局域网也被称为一个**层级结构**(如S4就是主交换机)。

<a href="https://sm.ms/image/yvGF8suoX9Jjf3E" target="_blank"><img src="https://i.loli.net/2020/06/07/yvGF8suoX9Jjf3E.png" width = 500px  ></a>

对于这种层级结构的交换机，其转发方式与单一交换机结构相同，都是通过自学习的方式来获取MAC地址，如果交换表中没有目的MAC地址，那么就用泛洪的方式进行处理。

<a href="https://sm.ms/image/RTbDF4YXCOLIjy1" target="_blank"><img src="https://i.loli.net/2020/06/07/RTbDF4YXCOLIjy1.png" width = 400px  ></a>

如上图，就是一种非常典型的组织机构网络的组合方式，各个主机与交换机构成层级结构，主交换机与路由器相连使得整个局域网能够与外网相连。

**路由器与交换机的异同：**

- 两者均是存储-转发设备：
  - 但路由器是网络层设备，检测网络层分组首部
  - 而交换机是链路层设备，检测链路层帧的首部
- 两者均使用转发表：
  - 但路由器利用路由算法(路由协议)设置，依据IP地址
  - 而交换机利用自学习、泛洪构建转发表，依据MAC地址

网络设备对比：

|            | 集线器 | 交换机 | 网桥 | 路由器 |
| ---------- | ------ | ------ | ---- | ------ |
| 层次       | 1      | 2      | 2    | 3      |
| 冲突域隔离 | n      | y      | y    | y      |
| 广播域隔离 | n      | n      | n    | y      |
| 即插即用   | y      | y      | y    | n      |
| 优化路由   | n      | n      | n    | y      |
| 直通传输   | y      | y      | y    | n      |



#### 点对点链路控制：

点对点链路中，只有一个发送端、一个接收端、一条链路，因此点对点链路的设计往往比广播链路设计简单很多。它不需要介质访问控制，也不需要明确的MAC寻址(一端发，另一端就要收)。传统的拨号上网就是利用的点对点链路。

**PPP(点对点)协议功能：**

- 组帧：将网络层数据封装到数据链路层帧中
  - 可以向上层实现分用(对多种网络协议的封装，在属于帧中增加一个字段来描述它所封装的是哪个协议的分组)
- 比特透明传输：数据域能够支持承载任何比特模式
- 差错检测：如果检测到数据问题，直接丢弃帧，无需进行差错纠正
- 支持连接活性检测：检测、并向网络层通知链路失效
- 网络层地址协商：端结点可以学习/配置彼此网络地址
- PPP协议不进行差错纠正，不进行流量控制，不存在乱序交付，不支持多点链路

**PPP数据帧：**

- 标志(Flag)：一个字节，首部与尾部分别有01111110这样的字段，实现组帧和帧同步的作用 ，标志一个数据帧的开始与结束，也被称为帧定界符
- 地址(Address)：一个字节，在PPP协议中没什么意义，在PPP目前的协议中全部取1
- 控制字段(Control)：一个字节，同样是无效字段，为未来设计考虑
- 协议(Protocol)：一或两个字节，两端主机可以通过协商来确定使用几个字节，表明封装的是哪个上层协议的分组(如，PPP-LCP,IP,IPCP)
- 信息(info)：封装上层协议分组数据
- 校验(check)：两或四个字节，两端主机可以通过协商来确定使用几个字节，CRC校验，用于差错检测



<a href="https://sm.ms/image/1nMuioT8DIplEyC" target="_blank"><img src="https://i.loli.net/2020/06/07/1nMuioT8DIplEyC.png" width = 400px  ></a>



**字节填充：**

如果数据域中本身就含有01111110这样的字段，PPP协议可能就会将它误认为是一个数据帧的开始或结束，而PPP为了能够满足“比特透明传输”的需求，PPP就必须允许数据域中包含01111110这样的字段，解决问题的方式就是字节填充：

- 发送端对要发送的数据报进行扫描，如果在数据中发现了01111110和01111101，就要在这两种字节前添加填充字节<font color = "red">01111101</font>
- 接收端边接收比特串边进行扫描：
  - 单个字节01111101表示一个填充字节
  - 如果有连续两个字节01111101，丢弃掉第一个，第二个作为数据接收
  - 单个字节01111110表示标志字节



**PPP协议工作流程：**

- 配置PPP链路：物理链路一旦准备就绪(如拨号链路建立成功)，接收发送双方就要进行配置PPP链路

  - 最大帧长
  - 身份认证（包括协商PPP数据帧的各个字段长度）

- 学习/配置网络层信息

  - PPP协议支持多种网络层协议的数据传输，PPP协议要针对不同的网络层协议，使用不同网络层的的控制协议，进行双方网络层信息的一些配置
  - 如IP协议：通过交换IPCP(IP控制)协议报文，完成两端IP地址等等信息的控制

- 传输数据帧

  <a href="https://sm.ms/image/XtV1YWUTJu3ceR2" target="_blank"><img src="https://i.loli.net/2020/06/07/XtV1YWUTJu3ceR2.png" width = 300px  ></a>



#### 无线局域网：

通常我们称之为WIFI，WIFI是IEEE 802.11这一系列标准所规定的无线局域网。

802.11局域网存在很多版本

- 802.11b
  - 物理层上使用为免费(无需授权)的2.4-2.5GHz频段
  - 最高速率为11Mbps
  - 物理层采用直接序列扩频技术(第一章中码分多路复用就是使用的一种直接序列扩频技术)
    - 与直接序列扩频技术不同的是，802.11b中所有主机使用相同的码片序列，因此它仍需要其他的MAC复用协议
- 802.11a
  - 使用5-6GHz频段
  - 最高速率为54Mbps
- 802.11g
  - 2.4-2.5GHz频段
  - 最高速率为54Mbps
- 802.11n
  - 2.4-2.5GHz频段
  - 最高速率为600Mbps

以上的802.11局域网均采用CSMA/CA多路访问控制协议，均采用基础设施(基站)网络模式和特定网(自组网，各种对等的无线主机，动态的构成的网络)网络模式

下图是一种**典型的802.11体系结构：**

<a href="https://sm.ms/image/QfFVvKAOguqdPap" target="_blank"><img src="https://i.loli.net/2020/06/07/QfFVvKAOguqdPap.png" width = 300px  ></a>

- 无线主机与基站(也称访问点，Access Point)通信，这些基站再与网络核心进行连接，最终连接到互联网中
- 基站的覆盖范围也被称为基本服务集BBS(Basic Service Set)
  - 基础设施网络模式包括：基站和无线主机
  - 自组网模式包括：只有无线主机，没有基站



在802.11局域网中，802.11如何去使用它所占用的频率带宽？这里我们以802.11b为例。

802.11b将2.4GHz-2.5GHz(准确是2.4GHz-2.485GHz)频谱划分为11个不同频率的信道，每一个基站(AP)去选择一个频率的信道。由于这11个频率的信道本身在划分时就会有一些频率的重叠，且各个AP在选择信道上时也没用硬性的规定，因此相邻AP之间存在着信号相互干扰的可能(后面会介绍CSMA/CA是如何解决这种干扰的)。

在802.11局域网中，作为主机是怎样与一个AP进行关联？这里我们以802.11b为例。

各个AP如果在某一信道上进行工作，那么这些AP会在该信道上周期性的发送一些**信标帧**(包含这个AP所属的基本服务集的标识符SSID，以及这个AP所使用的MAC地址)。主机通过扫描这11个信道上的信标帧，看看有哪些AP工作在这个信道上。我们选择完一个AP后，主机就会和这个AP进行**关联**(可能要先进行身份认证)，主机与AP关联完成后通过运行DHCP来获取IP地址等信息才算连入了Internet。

**主机与AP关联的两种方式：**

<a href="https://sm.ms/image/UdKX7QOeBv3YiLT" target="_blank"><img src="https://i.loli.net/2020/06/07/UdKX7QOeBv3YiLT.png" width = 400px  ></a>

- 被动扫描模式：
  - 各AP发送信标帧
  - 如果主机处在各个AP的覆盖范围之内时，主机就可以扫描到这些信标帧
  - 主机进行与哪一个AP进行关联
  - 当主机选定了一个AP以后，他就可以向这个AP发送**关联请求帧**
  - AP收到该关联请求帧，如果同意与主机进行关联，AP会向主机发送**关联响应帧**
  - 当主机接收到关联响应帧后，该关联就完成了
- 主动扫描模式：
  - 主机主动广播**探测请求帧**
  - AP接收到了主机广播的**探测请求帧**
  - AP发送**探测响应帧**
  - 主机进行与哪一个AP进行关联
  - 当主机选定了一个AP以后，他就可以向这个AP发送**关联请求帧**
  - AP收到该关联请求帧，如果同意与主机进行关联，AP会向主机发送**关联响应帧**
  - 当主机接收到关联响应帧后，该关联就完成了



**802.11多路访问控制(CSMA/CA)：**

802.11的多路访问控制是基于CSMA之上的，但其不能像CSMA/CD一样，做到边发送、边检测冲突(无线信号会有衰减问题，冲突了也无法检测出来)。因此802.11多路访问的设计目标就是要**避免冲突**，这就是下面要介绍的CSMA/C(collision)A(avoidance)。

如下为802.11发送数据的工作流程：

```
802.11发送方：
if 监听到信道空闲了DIFS时间 then   //检测到信道空闲必须要等待一段时间(DIFS)后才能发送数据
   发送整个帧             		//不会边发送边监听
else 监听到信道忙 then
	 开始随机退避计时   			   //随机选一个时间
    1当信道空闲时，计时倒计时		//如果不空闲，冻结计时器，直到信道空闲才开始计时
	 当计时器超时时，并且信道空闲达到了DIFS时间，那么发送帧
if 没有收到ACK then			//802.11不能够检测冲突，因此采用了停等协议的做法来检测是否发送成功
	增加随机退避间隔时间
	跳到1
else 收到ACK then
	完成本次发送，如果还有数据帧要发送跳到最开始处
802.11接收方：
if 正确接收帧
	延迟SIFS时间后，向发送端发送ACK	//SIFS时间要比DIFS的时间短很多，因此ACK的优先级也要大于数据的发送
```

<a href="https://sm.ms/image/Ph7lgts1cYaJIBX" target="_blank"><img src="https://i.loli.net/2020/06/07/Ph7lgts1cYaJIBX.png" width = 200px  ></a>

**CSMA/CD的基本思想：**

允许发送端“预约”信道，而不是随机发送数据帧，从而避免长数据帧的冲突，

- 发送端在发送数据之前先监听信道，如果信道空闲的时间达到DIFS以后，发送端首先利用CSMA向基站发送一个很短的RTS帧进行请求预约信道
  - 虽然RTS帧仍然是可能有冲突，但是RTS很短，因此对信道造成的影响没有正常收发长数据那么大
- 基站广播一个CTS帧作为对RTS的响应，能够与基站通信的所有结点都会受到这样的一个CTS帧
  - 由于所有结点都能收到CTS帧，因此这些结点也会清楚现在不能征用信道
  - 请求预约的结点收到CTS帧以后，就可以发送数据帧了
  - 其他节点收到CTS帧以后要推迟发送，这个推迟时间在CTS中的一个字段中会给出

因此CSMA/CD是利用了很小的预约帧彻底避免的数据帧的冲突

如图为CSMA/CD通过预约来避免冲突的过程：

<a href="https://sm.ms/image/m9xNAc1F8uiHDQ2" target="_blank"><img src="https://i.loli.net/2020/06/07/m9xNAc1F8uiHDQ2.png" width = 400px></a>



